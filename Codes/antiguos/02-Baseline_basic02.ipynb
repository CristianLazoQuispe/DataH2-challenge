{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904a4a52",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "7092ad2a",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../Src')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from utils.feature_engineering import *\n",
    "from utils.preprocessing import *\n",
    "from utils.analysis import * \n",
    "PATH_DATASET = '../Dataset/'\n",
    "#PATH_DATASET = '../Dataset/datah-m1-challange/'\n",
    "PATH_RESULTS = '../Results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80791839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import pytorch_forecasting\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer,EncoderNormalizer\n",
    "\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb45db57",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "5c9d63fa",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_sales  = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','sales.pkl'))\n",
    "df_items  = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','item.pkl'))\n",
    "df_stores = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','store.pkl'))\n",
    "\n",
    "df_submission_sample = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','submission_sample.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6559c2c7",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6fb605e5",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>S100</th>\n",
       "      <th>I100</th>\n",
       "      <th>C100</th>\n",
       "      <th>C101</th>\n",
       "      <th>QTT</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>0_12_76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>149</td>\n",
       "      <td>3</td>\n",
       "      <td>0_12_149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>0_12_256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>354</td>\n",
       "      <td>3</td>\n",
       "      <td>0_12_354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>0_13_149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  S100  I100  C100  C101  QTT   item_id  date_block_num\n",
       "0 2017-01-08     0     0    12    76    2   0_12_76               0\n",
       "1 2017-01-08     0     0    12   149    3  0_12_149               0\n",
       "2 2017-01-08     0     0    12   256    3  0_12_256               0\n",
       "3 2017-01-08     0     0    12   354    3  0_12_354               0\n",
       "4 2017-01-08     0     0    13   149    2  0_13_149               0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77c461eb",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7e5e116e",
     "kernelId": ""
    }
   },
   "source": [
    "date before 254 2020-03-22 00:00:00\n",
    "date not exists 255\n",
    "date before 254 2020-03-22 00:00:00\n",
    "date not exists 256\n",
    "date before 254 2020-03-22 00:00:00\n",
    "date not exists 257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfacd039",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6dad2396",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-04-19 00:00:00')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('2020-03-29')+ pd.DateOffset(days=7)*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "797cbdf1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c2e5d38d",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-01-08 00:00:00')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales['DATE'].iloc[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "378264aa",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f0f76b7e",
     "kernelId": ""
    }
   },
   "source": [
    "df2 = {'DATE': '2020-03-29', 'S100': 0, 'I100': 0,\"C100\":12,\"C101\":149,\"QTT\":0,\"item_id\":\"0_12_149\"}\n",
    "df_sales = df_sales.append(df2, ignore_index = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed4428b8",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a060aae3",
     "kernelId": ""
    }
   },
   "source": [
    "df2 = {'DATE': '2020-04-05', 'S100': 0, 'I100': 0,\"C100\":12,\"C101\":149,\"QTT\":0,\"item_id\":\"0_12_149\"}\n",
    "df_sales = df_sales.append(df2, ignore_index = True)\n",
    "df2 = {'DATE': '2020-04-12', 'S100': 0, 'I100': 0,\"C100\":12,\"C101\":149,\"QTT\":0,\"item_id\":\"0_12_149\"}\n",
    "df_sales = df_sales.append(df2, ignore_index = True)\n",
    "df2 = {'DATE': '2020-04-19', 'S100': 0, 'I100': 0,\"C100\":12,\"C101\":149,\"QTT\":0,\"item_id\":\"0_12_149\"}\n",
    "df_sales = df_sales.append(df2, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e7412b9",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "df5f0723",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sales = df_sales[df_sales['DATE']>'2020-01-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc6d18",
   "metadata": {},
   "source": [
    "df_2019 = df_sales[(df_sales['DATE'] >= '2019-01-01') & (df_sales['DATE'] < '2020-01-01')].copy()\n",
    "df_2020 = df_sales[(df_sales['DATE'] >= '2020-01-01') & (df_sales['DATE'] < '2020-01-01')].copy()\n",
    "df_2021 = df_sales[(df_sales['DATE'] >= '2021-01-01') & (df_sales['DATE'] < '2022-01-01')].copy()\n",
    "\n",
    "df_sales = pd.concat([df_2019,df_2020,df_2021])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0923cf2b",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "89325948",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "N_submission = df_submission_sample.shape[0]\n",
    "N_sales      = df_sales.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2aaa4ff4",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "effee7be",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_sales = fe_dates(df_sales)\n",
    "df_submission_sample = fe_dates(df_submission_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c22e860",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "dbe9b1e0",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_sales = df_sales.merge(df_items,on=['I100'])\n",
    "df_sales = df_sales.merge(df_stores,on=['S100'])\n",
    "    \n",
    "df_submission_sample = df_submission_sample.merge(df_items,on=['I100'])\n",
    "df_submission_sample = df_submission_sample.merge(df_stores,on=['S100'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab11fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2c5c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_submission = df_submission_sample.shape[0]\n",
    "N_sales      = df_sales.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95ea2760",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "73ebc9b9",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def string_to_categorical(df):\n",
    "    for name in df.columns:\n",
    "        aux = df[name].dtype\n",
    "        if str(aux) in ['str','object']:\n",
    "            df[name] = df[name].astype('category')\n",
    "            print(name,aux,df[name].dtype)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9aa51a74",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "057147f8",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id object category\n",
      "ID object category\n",
      "item_id object category\n"
     ]
    }
   ],
   "source": [
    "df_sales.replace([np.inf, -np.inf, np.nan],0,inplace=True)\n",
    "df_submission_sample.replace([np.inf, -np.inf, np.nan],0,inplace=True)\n",
    "df_sales             = string_to_categorical(df_sales).copy()\n",
    "df_submission_sample = string_to_categorical(df_submission_sample).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0384552",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "f568767d",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>S100</th>\n",
       "      <th>I100</th>\n",
       "      <th>C100</th>\n",
       "      <th>C101</th>\n",
       "      <th>QTT</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>I101</th>\n",
       "      <th>I102</th>\n",
       "      <th>I103</th>\n",
       "      <th>S101</th>\n",
       "      <th>S102</th>\n",
       "      <th>S103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>1_12_76</td>\n",
       "      <td>156</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>1_12_164</td>\n",
       "      <td>156</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>1_12_201</td>\n",
       "      <td>156</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>1_13_76</td>\n",
       "      <td>156</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1_13_128</td>\n",
       "      <td>156</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  S100  I100  C100  C101  QTT   item_id  date_block_num  year  \\\n",
       "0 2020-01-05     0     1    12    76    2   1_12_76             156  2020   \n",
       "1 2020-01-05     0     1    12   164    1  1_12_164             156  2020   \n",
       "2 2020-01-05     0     1    12   201    1  1_12_201             156  2020   \n",
       "3 2020-01-05     0     1    13    76    4   1_13_76             156  2020   \n",
       "4 2020-01-05     0     1    13   128    2  1_13_128             156  2020   \n",
       "\n",
       "   month  ...  is_year_start  is_quarter_start  is_month_start  is_month_end  \\\n",
       "0      1  ...          False             False           False         False   \n",
       "1      1  ...          False             False           False         False   \n",
       "2      1  ...          False             False           False         False   \n",
       "3      1  ...          False             False           False         False   \n",
       "4      1  ...          False             False           False         False   \n",
       "\n",
       "   I101  I102  I103  S101  S102  S103  \n",
       "0     2     1     1     1    17    10  \n",
       "1     2     1     1     1    17    10  \n",
       "2     2     1     1     1    17    10  \n",
       "3     2     1     1     1    17    10  \n",
       "4     2     1     1     1    17    10  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e7f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8067e749",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "a9961c6d",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def categorical_to_numeric(df):\n",
    "    cat_columns = df.select_dtypes(['category']).columns\n",
    "    print(cat_columns)\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    df[cat_columns] = df[cat_columns].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98182bfe",
   "metadata": {
    "gradient": {
     "id": "a6aac4cf",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "faa5ca08",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "43b9aca3",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(733810, 23) (69121, 24)\n",
      "item_id object category\n",
      "Index(['item_id', 'ID'], dtype='object')\n",
      "(733810, 24) (69121, 24)\n"
     ]
    }
   ],
   "source": [
    "print(df_sales.shape,df_submission_sample.shape)\n",
    "df_auxiliar = pd.concat([df_sales,df_submission_sample])\n",
    "df_auxiliar.replace([np.inf, -np.inf, np.nan],0,inplace=True)\n",
    "\n",
    "df_auxiliar = string_to_categorical(df_auxiliar).copy()\n",
    "\n",
    "dates = df_auxiliar['DATE'].unique()\n",
    "\n",
    "date = df_auxiliar['DATE'].min()\n",
    "maxi = df_auxiliar['DATE'].max()\n",
    "\n",
    "dict_dates = {}\n",
    "idx = 0\n",
    "while(True):    \n",
    "    if date>maxi:\n",
    "        break\n",
    "    dict_dates[date]=idx\n",
    "    date = date+ pd.DateOffset(days=7)    \n",
    "    idx = idx+1\n",
    "    \n",
    "df_auxiliar['date_block_num'] = df_auxiliar['DATE'].replace(dict_dates)\n",
    "\n",
    "#df_auxiliar['date_block_num'] = df_auxiliar['year']*12*4+df_auxiliar['month']*4+df_auxiliar['day']//7\n",
    "\n",
    "#df_auxiliar['date_block_num'] = df_auxiliar['date_block_num']-int(df_auxiliar['date_block_num'].min())+100\n",
    "\n",
    "df_auxiliar = categorical_to_numeric(df_auxiliar)\n",
    "\n",
    "df_auxiliar = columns_to_str(df_auxiliar,[\"S101\", \"S102\",\"S103\",\"I100\",\"I101\",\"I102\",\"I103\",\"C100\",\"C101\"])\n",
    "\n",
    "df_sales, df_submission_sample = df_auxiliar[:N_sales], df_auxiliar[N_sales:]\n",
    "print(df_sales.shape,df_submission_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea34ec7f",
   "metadata": {
    "gradient": {
     "id": "0d9d6906",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#'day_of_week', 'day', 'is_month_end', 'day_of_year',  'is_quarter_start', 'year', 'month', 'is_year_start', 'is_month_start'\n",
    "for cat_col in [\"S100\", \"item_id\",\"S101\", \"S102\",\"S103\",\"I100\",\"I101\",\"I102\",\"I103\",\"C100\",\"C101\"]:\n",
    "    df_sales[cat_col]             = (df_sales[cat_col].astype(str) +'_'+ cat_col).astype('category')\n",
    "    df_submission_sample[cat_col] = (df_submission_sample[cat_col].astype(str) +'_'+ cat_col).astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69855103",
   "metadata": {
    "gradient": {
     "id": "588f4713",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "          ..\n",
       "733805    83\n",
       "733806    84\n",
       "733807    86\n",
       "733808    88\n",
       "733809    90\n",
       "Name: date_block_num, Length: 733810, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales['date_block_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d29a0c6",
   "metadata": {
    "gradient": {
     "id": "25f9fc79",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sales.replace(['',np.inf, -np.inf, np.nan],0,inplace=True)\n",
    "df_submission_sample.replace(['',np.inf, -np.inf, np.nan],0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24853943",
   "metadata": {
    "gradient": {
     "id": "6ccf2499",
     "kernelId": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 90\n",
      "date before 11 2020-03-22 00:00:00\n",
      "date not exists 12\n",
      "date before 11 2020-03-22 00:00:00\n",
      "date not exists 13\n",
      "date before 11 2020-03-22 00:00:00\n",
      "date not exists 14\n",
      "date before 11 2020-03-22 00:00:00\n",
      "date not exists 15\n"
     ]
    }
   ],
   "source": [
    "date_block_num_min_sales = df_sales['date_block_num'].min()\n",
    "date_block_num_max_sales = df_sales['date_block_num'].max()\n",
    "print(date_block_num_min_sales,date_block_num_max_sales)\n",
    "\n",
    "aux = df_sales['DATE'].min()\n",
    "id_aux = 0\n",
    "for i in range(date_block_num_min_sales,date_block_num_max_sales+1):\n",
    "    ga = df_sales[df_sales['date_block_num']==i]\n",
    "    if len(ga)>0:\n",
    "        date = ga['DATE'].iloc[0]\n",
    "        #print(date,i)\n",
    "        if date<aux :\n",
    "            print('discontinuidad')\n",
    "            print('before :',aux,id_aux)\n",
    "            print('actual :',date,i)\n",
    "        elif date==aux and id_aux !=0:\n",
    "            print('igualdad')\n",
    "            print('before :',aux,id_aux)\n",
    "            print('actual :',date,i)\n",
    "        else:\n",
    "            pass\n",
    "        aux = date\n",
    "        id_aux =i\n",
    "    else:\n",
    "        print('date before',id_aux,aux)\n",
    "        print('date not exists',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01a96846",
   "metadata": {
    "gradient": {
     "id": "16ced9a3",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 98\n"
     ]
    }
   ],
   "source": [
    "date_block_num_min_sales = df_auxiliar['date_block_num'].min()\n",
    "date_block_num_max_sales = df_auxiliar['date_block_num'].max()\n",
    "print(date_block_num_min_sales,date_block_num_max_sales)\n",
    "\n",
    "aux = df_auxiliar['DATE'].min()\n",
    "id_aux = 0\n",
    "for i in range(date_block_num_min_sales,date_block_num_max_sales+1):\n",
    "    ga = df_auxiliar[df_auxiliar['date_block_num']==i]\n",
    "    if len(ga)>0:\n",
    "        date = ga['DATE'].iloc[0]\n",
    "        #print(date,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1faa32c",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "a62de53a",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_year_start', 'S100', 'month', 'ID', 'year', 'day_of_week', 'is_month_start', 'is_quarter_start', 'I101', 'day_of_year', 'I103', 'I102', 'C101', 'S103', 'C100', 'S102', 'is_month_end', 'I100', 'item_id', 'day', 'S101', 'date_block_num'}\n"
     ]
    }
   ],
   "source": [
    "features_names = set(df_sales.columns)-set(['QTT','DATE'])\n",
    "print(features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37972152",
   "metadata": {
    "gradient": {
     "id": "f9db5e00",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2021-10-03 00:00:00'), Timestamp('2021-11-21 00:00:00'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission_sample['DATE'].min(),df_submission_sample['DATE'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b836d2d3",
   "metadata": {
    "gradient": {
     "id": "0d83df4f",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "features_names = ['DATE','QTT','date_block_num',\"S100\", \"item_id\",\"S101\", \"S102\",\"S103\",\"I100\",\"I101\",\"I102\",\"I103\",\"C100\",\"C101\",'day_of_week', 'day', 'is_month_end', 'day_of_year',  'is_quarter_start', 'year', 'month', 'is_year_start', 'is_month_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "af339992",
   "metadata": {
    "gradient": {
     "id": "f1a8e09b",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sales             = df_sales[features_names]\n",
    "df_submission_sample = df_submission_sample[features_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d22be6f",
   "metadata": {
    "gradient": {
     "id": "7554438c",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "qtt_values = df_sales['QTT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d3b4777",
   "metadata": {
    "gradient": {
     "id": "3dd75117",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sales['QTT'] = qtt_values*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c08efb42",
   "metadata": {
    "gradient": {
     "id": "736991f1",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    4.0\n",
       "4    2.0\n",
       "Name: QTT, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales['QTT'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c991db8",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2002f73c",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#df_sales2 = df_sales[df_sales['QTT']<=15].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a119370c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c505a684",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#df_submission_sample = df_submission_sample[df_submission_sample['S100']==0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b229865",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b3fdc79c",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "X_train      = df_sales[(df_sales['DATE'] >= '2017-01-01') & (df_sales['DATE'] < '2020-10-01')].copy()\n",
    "#X_train = X_train.sample(frac=1).reset_index(drop=True)\n",
    "X_validation = df_sales[(df_sales['DATE'] >= '2020-10-01') & (df_sales['DATE'] < '2021-03-01')].copy()\n",
    "X_test       = df_sales[(df_sales['DATE'] >= '2021-03-01') & (df_sales['DATE'] < '2021-10-03')].copy() "
   ]
  },
  {
   "cell_type": "raw",
   "id": "52672dc1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "14294202",
     "kernelId": ""
    }
   },
   "source": [
    "X_train['item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9ff22",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9dffd066",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a51ccc1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d62683b9",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_sales.drop(df_sales[(df_sales['item_id']==167)].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "011872d5",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fa690834",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE                datetime64[ns]\n",
       "QTT                        float64\n",
       "date_block_num               int64\n",
       "S100                      category\n",
       "item_id                   category\n",
       "S101                      category\n",
       "S102                      category\n",
       "S103                      category\n",
       "I100                      category\n",
       "I101                      category\n",
       "I102                      category\n",
       "I103                      category\n",
       "C100                      category\n",
       "C101                      category\n",
       "day_of_week                  int64\n",
       "day                          int64\n",
       "is_month_end                  bool\n",
       "day_of_year                  int64\n",
       "is_quarter_start              bool\n",
       "year                         int64\n",
       "month                        int64\n",
       "is_year_start                 bool\n",
       "is_month_start                bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b107419",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6efe76a0",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>QTT</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>S100</th>\n",
       "      <th>item_id</th>\n",
       "      <th>S101</th>\n",
       "      <th>S102</th>\n",
       "      <th>S103</th>\n",
       "      <th>I100</th>\n",
       "      <th>I101</th>\n",
       "      <th>...</th>\n",
       "      <th>C101</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_month_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>323_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>319_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>164_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>320_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>201_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>331_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>324_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>128_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  QTT  date_block_num    S100      item_id    S101     S102  \\\n",
       "0 2020-01-05  2.0               0  0_S100  323_item_id  1_S101  17_S102   \n",
       "1 2020-01-05  1.0               0  0_S100  319_item_id  1_S101  17_S102   \n",
       "2 2020-01-05  1.0               0  0_S100  320_item_id  1_S101  17_S102   \n",
       "3 2020-01-05  4.0               0  0_S100  331_item_id  1_S101  17_S102   \n",
       "4 2020-01-05  2.0               0  0_S100  324_item_id  1_S101  17_S102   \n",
       "\n",
       "      S103    I100    I101  ...      C101 day_of_week day is_month_end  \\\n",
       "0  10_S103  1_I100  2_I101  ...   76_C101           6   5        False   \n",
       "1  10_S103  1_I100  2_I101  ...  164_C101           6   5        False   \n",
       "2  10_S103  1_I100  2_I101  ...  201_C101           6   5        False   \n",
       "3  10_S103  1_I100  2_I101  ...   76_C101           6   5        False   \n",
       "4  10_S103  1_I100  2_I101  ...  128_C101           6   5        False   \n",
       "\n",
       "   day_of_year  is_quarter_start  year  month  is_year_start  is_month_start  \n",
       "0            5             False  2020      1          False           False  \n",
       "1            5             False  2020      1          False           False  \n",
       "2            5             False  2020      1          False           False  \n",
       "3            5             False  2020      1          False           False  \n",
       "4            5             False  2020      1          False           False  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d722db9d",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f5333376",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>QTT</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>S100</th>\n",
       "      <th>item_id</th>\n",
       "      <th>S101</th>\n",
       "      <th>S102</th>\n",
       "      <th>S103</th>\n",
       "      <th>I100</th>\n",
       "      <th>I101</th>\n",
       "      <th>...</th>\n",
       "      <th>C101</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_month_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>323_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>319_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>164_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>320_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>201_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>331_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>324_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>128_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733805</th>\n",
       "      <td>2021-08-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733806</th>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>245_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>140_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733807</th>\n",
       "      <td>2021-08-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>241</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733808</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>255</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733809</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>733810 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE  QTT  date_block_num     S100      item_id    S101     S102  \\\n",
       "0      2020-01-05  2.0               0   0_S100  323_item_id  1_S101  17_S102   \n",
       "1      2020-01-05  1.0               0   0_S100  319_item_id  1_S101  17_S102   \n",
       "2      2020-01-05  1.0               0   0_S100  320_item_id  1_S101  17_S102   \n",
       "3      2020-01-05  4.0               0   0_S100  331_item_id  1_S101  17_S102   \n",
       "4      2020-01-05  2.0               0   0_S100  324_item_id  1_S101  17_S102   \n",
       "...           ...  ...             ...      ...          ...     ...      ...   \n",
       "733805 2021-08-08  1.0              83  22_S100  251_item_id  0_S101   0_S102   \n",
       "733806 2021-08-15  1.0              84  22_S100  245_item_id  0_S101   0_S102   \n",
       "733807 2021-08-29  1.0              86  22_S100  251_item_id  0_S101   0_S102   \n",
       "733808 2021-09-12  1.0              88  22_S100  251_item_id  0_S101   0_S102   \n",
       "733809 2021-09-26  1.0              90  22_S100  251_item_id  0_S101   0_S102   \n",
       "\n",
       "           S103     I100    I101  ...      C101 day_of_week day is_month_end  \\\n",
       "0       10_S103   1_I100  2_I101  ...   76_C101           6   5        False   \n",
       "1       10_S103   1_I100  2_I101  ...  164_C101           6   5        False   \n",
       "2       10_S103   1_I100  2_I101  ...  201_C101           6   5        False   \n",
       "3       10_S103   1_I100  2_I101  ...   76_C101           6   5        False   \n",
       "4       10_S103   1_I100  2_I101  ...  128_C101           6   5        False   \n",
       "...         ...      ...     ...  ...       ...         ...  ..          ...   \n",
       "733805  10_S103  18_I100  2_I101  ...   76_C101           6   8        False   \n",
       "733806  10_S103  18_I100  2_I101  ...  140_C101           6  15        False   \n",
       "733807  10_S103  18_I100  2_I101  ...   76_C101           6  29        False   \n",
       "733808  10_S103  18_I100  2_I101  ...   76_C101           6  12        False   \n",
       "733809  10_S103  18_I100  2_I101  ...   76_C101           6  26        False   \n",
       "\n",
       "        day_of_year  is_quarter_start  year  month  is_year_start  \\\n",
       "0                 5             False  2020      1          False   \n",
       "1                 5             False  2020      1          False   \n",
       "2                 5             False  2020      1          False   \n",
       "3                 5             False  2020      1          False   \n",
       "4                 5             False  2020      1          False   \n",
       "...             ...               ...   ...    ...            ...   \n",
       "733805          220             False  2021      8          False   \n",
       "733806          227             False  2021      8          False   \n",
       "733807          241             False  2021      8          False   \n",
       "733808          255             False  2021      9          False   \n",
       "733809          269             False  2021      9          False   \n",
       "\n",
       "        is_month_start  \n",
       "0                False  \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  \n",
       "...                ...  \n",
       "733805           False  \n",
       "733806           False  \n",
       "733807           False  \n",
       "733808           False  \n",
       "733809           False  \n",
       "\n",
       "[733810 rows x 23 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1a35fd3",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a6948f76",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATE', 'QTT', 'date_block_num', 'S100', 'item_id', 'S101', 'S102',\n",
       "       'S103', 'I100', 'I101', 'I102', 'I103', 'C100', 'C101', 'day_of_week',\n",
       "       'day', 'is_month_end', 'day_of_year', 'is_quarter_start', 'year',\n",
       "       'month', 'is_year_start', 'is_month_start'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4be78a53",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "721172c8",
     "kernelId": ""
    }
   },
   "source": [
    "\n",
    "                          \"QTT\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),                          \n",
    "                          \"date_block_num\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b54a3610",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "37645e12",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[91, 92, 93, 94, 95, 96, 97, 98]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_submission_sample['date_block_num'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "30405840",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "00b0123a",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_steps = df_submission_sample['date_block_num'].nunique()\n",
    "prediction_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f3fe52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "990f865b",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ce153354",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#'day_of_week', 'day', 'is_month_end', 'day_of_year',  'is_quarter_start', 'year', 'month', 'is_year_start', 'is_month_start', \n",
    "# 'I103','S103', 'C101','I100' , 'C100', 'ID', 'I102','S102',, 'S101', 'S100', 'item_id', 'date_block_num', 'I101'\n",
    "max_prediction_length = prediction_steps\n",
    "\n",
    "max_encoder_length = 20\n",
    "\n",
    "training_cutoff = df_sales['date_block_num'].max() - max_prediction_length\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    df_sales[lambda x: x['date_block_num'] <= training_cutoff],\n",
    "    time_idx='date_block_num',\n",
    "    target=\"QTT\",\n",
    "    group_ids=[\"S100\", \"item_id\"],\n",
    "    min_encoder_length=0,  \n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    \n",
    "    static_categoricals=[\"S100\", \"item_id\"],\n",
    "    \n",
    "    time_varying_unknown_categoricals=[\"S100\", \"item_id\",\"S101\", \"S102\",\"S103\",\"I100\",\"I101\",\"I102\",\"I103\",\"C100\",\"C101\"],\n",
    "    time_varying_unknown_reals=[\"date_block_num\",\"QTT\",'day_of_week', 'day', 'is_month_end', 'day_of_year',  'is_quarter_start', 'year', 'month', 'is_year_start', 'is_month_start'],\n",
    "    \n",
    "    time_varying_known_reals=['date_block_num'],\n",
    "    time_varying_known_categoricals=[],  \n",
    "       \n",
    "    #target_normalizer=GroupNormalizer(\n",
    "    #    groups=[\"S100\", \"item_id\"], transformation=\"softplus\"\n",
    "    #),  # use softplus and normalize by group    \n",
    "    \n",
    "    categorical_encoders={\"item_id\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "                          \n",
    "                          \"S100\":  pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "                          \"S101\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "                          \"S102\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "                          \"S103\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "                          \"I100\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "                          \"I101\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "                          \"I102\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "                          \"I103\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "                          \"C100\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),                          \n",
    "                          \"C101\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "                         #\"date_block_num\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "                         },\n",
    "    #,\n",
    "    #                      \"item_id\":pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    #                     },\n",
    "    #'day_of_week', 'day', 'is_month_end', 'day_of_year',  'is_quarter_start', 'year', 'month', 'is_year_start', 'is_month_start']},\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65ffde44",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c13f08d1",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "validation = TimeSeriesDataSet.from_dataset(training, df_sales, predict=True, stop_randomization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed4f220b",
   "metadata": {
    "gradient": {
     "execution_count": 48,
     "id": "ffa166ff",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "val_dataloader   = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dfba7303",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e70db99b",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_forecasting.metrics import QuantileLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e9ad67b",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5ea707a9",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_forecasting.metrics import SMAPE, MAE\n",
    "\n",
    "composite_metric = SMAPE() + 1e-4 * MAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dfa1b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.metrics import MultiHorizonMetric\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "class tweedieloss(MultiHorizonMetric):\n",
    "\n",
    "    def __init__(self, reduction=\"mean\", **kwargs):\n",
    "        super().__init__(reduction=reduction, **kwargs)\n",
    "        #self.p_value = tensor(1.1, dtype=torch.float64, device='cuda:0')\n",
    "        #self._device = 'cuda:0'\n",
    "        #self.Par\n",
    "    def loss(self, y_pred: Dict[str, torch.Tensor], target):\n",
    "        p = 1.01\n",
    "        #y_pred = y_pred.to(self._device)\n",
    "        #target = target.to(self._device)\n",
    "\n",
    "        preds = self.to_prediction(y_pred)\n",
    "        #preds = preds.to(self._device)\n",
    "\n",
    "        #p = tensor(1.1, dtype=torch.float64, device='cpu')\n",
    "        \n",
    "        #ax = (1-self.p_value).to(self._device)\n",
    "        #bx = (2-self.p_value).to(self._device)\n",
    "        \n",
    "        a = target*(torch.pow(preds,1-p))/(1-p)\n",
    "        b = torch.pow(preds,2-p)/(2-p)\n",
    "        tweddie = (-a+b)        \n",
    "        \n",
    "        #tweddie = tweddie.to(self._device)\n",
    "        \n",
    "        return tweddie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6351ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "07431a27",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4fed55b8",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 83.2k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=1,  # 7 quantiles by default\n",
    "    \n",
    "    #loss=pytorch_forecasting.metrics.RMSE(),\n",
    "    loss = tweedieloss(),\n",
    "    #loss=SMAPE(),\n",
    "    \n",
    "    \n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0d25cfc7",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "121296d0",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_id': NaNLabelEncoder(add_nan=True),\n",
       " 'S100': NaNLabelEncoder(add_nan=True),\n",
       " 'S101': NaNLabelEncoder(add_nan=True),\n",
       " 'S102': NaNLabelEncoder(add_nan=True),\n",
       " 'S103': NaNLabelEncoder(add_nan=True),\n",
       " 'I100': NaNLabelEncoder(add_nan=True),\n",
       " 'I101': NaNLabelEncoder(add_nan=True),\n",
       " 'I102': NaNLabelEncoder(add_nan=True),\n",
       " 'I103': NaNLabelEncoder(add_nan=True),\n",
       " 'C100': NaNLabelEncoder(add_nan=True),\n",
       " 'C101': NaNLabelEncoder(add_nan=True),\n",
       " '__group_id__S100': NaNLabelEncoder(),\n",
       " '__group_id__item_id': NaNLabelEncoder()}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.categorical_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efdfa70",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "190c4f8e",
     "kernelId": ""
    }
   },
   "source": [
    "tft.requires_grad_ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e8507710",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9bca7641",
     "kernelId": ""
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Global seed set to 42\n",
      "\n",
      "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Finding best initial lr:   1%|          | 1/100 [00:00<00:27,  3.60it/s]\u001b[A\n",
      "Finding best initial lr:   2%|▏         | 2/100 [00:00<00:33,  2.95it/s]\u001b[A\n",
      "Finding best initial lr:   3%|▎         | 3/100 [00:01<00:37,  2.55it/s]\u001b[A\n",
      "Finding best initial lr:   4%|▍         | 4/100 [00:01<00:36,  2.63it/s]\u001b[A\n",
      "Finding best initial lr:   5%|▌         | 5/100 [00:01<00:37,  2.55it/s]\u001b[A\n",
      "Finding best initial lr:   6%|▌         | 6/100 [00:02<00:38,  2.47it/s]\u001b[A\n",
      "Finding best initial lr:   7%|▋         | 7/100 [00:02<00:38,  2.44it/s]\u001b[A\n",
      "Finding best initial lr:   8%|▊         | 8/100 [00:03<00:37,  2.44it/s]\u001b[A\n",
      "Finding best initial lr:   9%|▉         | 9/100 [00:03<00:39,  2.28it/s]\u001b[A\n",
      "Finding best initial lr:  10%|█         | 10/100 [00:04<00:39,  2.30it/s]\u001b[A\n",
      "Finding best initial lr:  11%|█         | 11/100 [00:04<00:37,  2.38it/s]\u001b[A\n",
      "Finding best initial lr:  12%|█▏        | 12/100 [00:04<00:37,  2.37it/s]\u001b[A\n",
      "Finding best initial lr:  13%|█▎        | 13/100 [00:05<00:36,  2.37it/s]\u001b[A\n",
      "Finding best initial lr:  14%|█▍        | 14/100 [00:05<00:35,  2.44it/s]\u001b[A\n",
      "Finding best initial lr:  15%|█▌        | 15/100 [00:06<00:35,  2.38it/s]\u001b[A\n",
      "Finding best initial lr:  16%|█▌        | 16/100 [00:06<00:34,  2.42it/s]\u001b[A\n",
      "Finding best initial lr:  17%|█▋        | 17/100 [00:07<00:35,  2.32it/s]\u001b[A\n",
      "Finding best initial lr:  18%|█▊        | 18/100 [00:07<00:39,  2.09it/s]\u001b[A\n",
      "Finding best initial lr:  19%|█▉        | 19/100 [00:08<00:38,  2.13it/s]\u001b[A\n",
      "Finding best initial lr:  20%|██        | 20/100 [00:08<00:36,  2.18it/s]\u001b[A\n",
      "Finding best initial lr:  21%|██        | 21/100 [00:08<00:34,  2.28it/s]\u001b[A\n",
      "Finding best initial lr:  22%|██▏       | 22/100 [00:09<00:33,  2.34it/s]\u001b[A\n",
      "Finding best initial lr:  23%|██▎       | 23/100 [00:09<00:32,  2.36it/s]\u001b[A\n",
      "Finding best initial lr:  24%|██▍       | 24/100 [00:10<00:32,  2.37it/s]\u001b[A\n",
      "Finding best initial lr:  25%|██▌       | 25/100 [00:10<00:31,  2.37it/s]\u001b[A\n",
      "Finding best initial lr:  26%|██▌       | 26/100 [00:10<00:30,  2.41it/s]\u001b[A\n",
      "Finding best initial lr:  27%|██▋       | 27/100 [00:11<00:31,  2.32it/s]\u001b[A\n",
      "Finding best initial lr:  28%|██▊       | 28/100 [00:11<00:30,  2.35it/s]\u001b[A\n",
      "Finding best initial lr:  29%|██▉       | 29/100 [00:12<00:30,  2.35it/s]\u001b[A\n",
      "Finding best initial lr:  30%|███       | 30/100 [00:12<00:30,  2.28it/s]\u001b[A\n",
      "Finding best initial lr:  31%|███       | 31/100 [00:13<00:29,  2.37it/s]\u001b[A\n",
      "Finding best initial lr:  32%|███▏      | 32/100 [00:13<00:28,  2.35it/s]\u001b[A\n",
      "Finding best initial lr:  33%|███▎      | 33/100 [00:13<00:27,  2.43it/s]\u001b[A\n",
      "Finding best initial lr:  34%|███▍      | 34/100 [00:14<00:26,  2.48it/s]\u001b[A\n",
      "Finding best initial lr:  35%|███▌      | 35/100 [00:14<00:26,  2.46it/s]\u001b[A\n",
      "Finding best initial lr:  36%|███▌      | 36/100 [00:15<00:26,  2.46it/s]\u001b[A\n",
      "Finding best initial lr:  37%|███▋      | 37/100 [00:15<00:25,  2.48it/s]\u001b[A\n",
      "Finding best initial lr:  38%|███▊      | 38/100 [00:15<00:24,  2.53it/s]\u001b[A\n",
      "Finding best initial lr:  39%|███▉      | 39/100 [00:16<00:24,  2.46it/s]\u001b[A\n",
      "Finding best initial lr:  40%|████      | 40/100 [00:16<00:24,  2.42it/s]\u001b[A\n",
      "Finding best initial lr:  41%|████      | 41/100 [00:17<00:23,  2.47it/s]\u001b[A\n",
      "Finding best initial lr:  42%|████▏     | 42/100 [00:17<00:23,  2.47it/s]\u001b[A\n",
      "Finding best initial lr:  43%|████▎     | 43/100 [00:17<00:22,  2.48it/s]\u001b[A\n",
      "Finding best initial lr:  44%|████▍     | 44/100 [00:18<00:22,  2.52it/s]\u001b[A\n",
      "Finding best initial lr:  45%|████▌     | 45/100 [00:18<00:21,  2.58it/s]\u001b[A\n",
      "Finding best initial lr:  46%|████▌     | 46/100 [00:19<00:21,  2.52it/s]\u001b[A\n",
      "Finding best initial lr:  47%|████▋     | 47/100 [00:19<00:21,  2.44it/s]\u001b[A\n",
      "Finding best initial lr:  48%|████▊     | 48/100 [00:19<00:21,  2.39it/s]\u001b[A\n",
      "Finding best initial lr:  49%|████▉     | 49/100 [00:20<00:20,  2.45it/s]\u001b[A\n",
      "Finding best initial lr:  50%|█████     | 50/100 [00:20<00:20,  2.40it/s]\u001b[A\n",
      "Finding best initial lr:  51%|█████     | 51/100 [00:21<00:20,  2.38it/s]\u001b[A\n",
      "Finding best initial lr:  52%|█████▏    | 52/100 [00:21<00:19,  2.45it/s]\u001b[A\n",
      "Finding best initial lr:  53%|█████▎    | 53/100 [00:22<00:19,  2.45it/s]\u001b[A\n",
      "Finding best initial lr:  54%|█████▍    | 54/100 [00:22<00:19,  2.40it/s]\u001b[A\n",
      "Finding best initial lr:  55%|█████▌    | 55/100 [00:22<00:18,  2.45it/s]\u001b[A\n",
      "Finding best initial lr:  56%|█████▌    | 56/100 [00:23<00:17,  2.46it/s]\u001b[A\n",
      "Finding best initial lr:  57%|█████▋    | 57/100 [00:23<00:17,  2.48it/s]\u001b[A\n",
      "Finding best initial lr:  58%|█████▊    | 58/100 [00:24<00:16,  2.50it/s]\u001b[A\n",
      "Finding best initial lr:  59%|█████▉    | 59/100 [00:24<00:16,  2.55it/s]\u001b[A\n",
      "Finding best initial lr:  60%|██████    | 60/100 [00:24<00:16,  2.50it/s]\u001b[A\n",
      "Finding best initial lr:  61%|██████    | 61/100 [00:25<00:15,  2.51it/s]\u001b[A\n",
      "Finding best initial lr:  62%|██████▏   | 62/100 [00:25<00:15,  2.48it/s]\u001b[A\n",
      "Finding best initial lr:  63%|██████▎   | 63/100 [00:25<00:14,  2.55it/s]\u001b[A\n",
      "Finding best initial lr:  64%|██████▍   | 64/100 [00:26<00:14,  2.48it/s]\u001b[A\n",
      "Finding best initial lr:  65%|██████▌   | 65/100 [00:26<00:14,  2.47it/s]\u001b[A\n",
      "Finding best initial lr:  66%|██████▌   | 66/100 [00:27<00:13,  2.46it/s]\u001b[A\n",
      "Finding best initial lr:  67%|██████▋   | 67/100 [00:27<00:13,  2.36it/s]\u001b[A\n",
      "Finding best initial lr:  68%|██████▊   | 68/100 [00:28<00:13,  2.45it/s]\u001b[A\n",
      "Finding best initial lr:  69%|██████▉   | 69/100 [00:28<00:12,  2.41it/s]\u001b[A\n",
      "Finding best initial lr:  70%|███████   | 70/100 [00:28<00:12,  2.44it/s]\u001b[A\n",
      "Finding best initial lr:  71%|███████   | 71/100 [00:29<00:11,  2.49it/s]\u001b[A\n",
      "Finding best initial lr:  72%|███████▏  | 72/100 [00:29<00:11,  2.43it/s]\u001b[A\n",
      "Finding best initial lr:  73%|███████▎  | 73/100 [00:30<00:11,  2.36it/s]\u001b[A\n",
      "Finding best initial lr:  74%|███████▍  | 74/100 [00:30<00:10,  2.39it/s]\u001b[A\n",
      "Finding best initial lr:  75%|███████▌  | 75/100 [00:30<00:10,  2.42it/s]\u001b[A\n",
      "Finding best initial lr:  76%|███████▌  | 76/100 [00:31<00:10,  2.36it/s]\u001b[A\n",
      "Finding best initial lr:  77%|███████▋  | 77/100 [00:31<00:10,  2.29it/s]\u001b[A\n",
      "Finding best initial lr:  78%|███████▊  | 78/100 [00:32<00:09,  2.33it/s]\u001b[A\n",
      "Finding best initial lr:  79%|███████▉  | 79/100 [00:32<00:08,  2.35it/s]\u001b[A\n",
      "Finding best initial lr:  80%|████████  | 80/100 [00:33<00:08,  2.42it/s]\u001b[A\n",
      "Finding best initial lr:  81%|████████  | 81/100 [00:33<00:08,  2.36it/s]\u001b[A\n",
      "Finding best initial lr:  82%|████████▏ | 82/100 [00:33<00:07,  2.40it/s]\u001b[A\n",
      "Finding best initial lr:  83%|████████▎ | 83/100 [00:34<00:07,  2.29it/s]\u001b[A\n",
      "Finding best initial lr:  84%|████████▍ | 84/100 [00:34<00:06,  2.35it/s]\u001b[A\n",
      "Finding best initial lr:  85%|████████▌ | 85/100 [00:35<00:06,  2.47it/s]\u001b[A\n",
      "Finding best initial lr:  86%|████████▌ | 86/100 [00:35<00:05,  2.52it/s]\u001b[A\n",
      "Finding best initial lr:  87%|████████▋ | 87/100 [00:36<00:05,  2.46it/s]\u001b[A\n",
      "Finding best initial lr:  88%|████████▊ | 88/100 [00:36<00:04,  2.43it/s]\u001b[A\n",
      "Finding best initial lr:  89%|████████▉ | 89/100 [00:36<00:04,  2.41it/s]\u001b[A\n",
      "Finding best initial lr:  90%|█████████ | 90/100 [00:37<00:04,  2.37it/s]\u001b[A\n",
      "Finding best initial lr:  91%|█████████ | 91/100 [00:37<00:03,  2.35it/s]\u001b[A\n",
      "Finding best initial lr:  92%|█████████▏| 92/100 [00:38<00:03,  2.44it/s]\u001b[A\n",
      "Finding best initial lr:  93%|█████████▎| 93/100 [00:38<00:02,  2.44it/s]\u001b[A\n",
      "Finding best initial lr:  94%|█████████▍| 94/100 [00:38<00:02,  2.50it/s]\u001b[A\n",
      "Finding best initial lr:  95%|█████████▌| 95/100 [00:39<00:01,  2.52it/s]\u001b[A\n",
      "Finding best initial lr:  96%|█████████▌| 96/100 [00:39<00:01,  2.47it/s]\u001b[A\n",
      "Finding best initial lr:  97%|█████████▋| 97/100 [00:40<00:01,  2.39it/s]\u001b[A\n",
      "Finding best initial lr:  98%|█████████▊| 98/100 [00:40<00:00,  2.36it/s]\u001b[A\n",
      "Finding best initial lr:  99%|█████████▉| 99/100 [00:41<00:00,  2.35it/s]\u001b[A\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:41<00:00,  2.43it/s]\u001b[ARestoring states from the checkpoint path at /notebooks/dataH-kaggle/Codes/lr_find_temp_model_97996139-d0d1-4233-9c2d-94588a7b1dcc.ckpt\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:42<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.0007943282347242817\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=0.1,\n",
    "    min_lr=1e-7,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "77c4cd34",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f93079c2",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 83.2k\n"
     ]
    }
   ],
   "source": [
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=res.suggestion(),\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=1, \n",
    "    #loss=pytorch_forecasting.metrics.RMSE(),\n",
    "    loss = tweedieloss(),\n",
    "    #loss= SMAPE(),\n",
    "    log_interval=10,  \n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "daa04d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-7, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  \n",
    "logger = TensorBoardLogger(\"lightning_logs\") \n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs= 3000,\n",
    "    gpus=1,\n",
    "    weights_summary=\"top\",\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  \n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fa5eb9cd",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "8cdbd395",
     "kernelId": ""
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | tweedieloss                     | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 54.5 K\n",
      "3  | prescalers                         | ModuleDict                      | 240   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 2.1 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 11.4 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 1.2 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 17    \n",
      "----------------------------------------------------------------------------------------\n",
      "83.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "83.2 K    Total params\n",
      "0.333     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  53%|█████▎    | 30/57 [00:14<00:13,  2.06it/s, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  56%|█████▌    | 32/57 [00:18<00:14,  1.70it/s, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:19,  3.20s/it]\u001b[A\n",
      "Epoch 0:  60%|█████▉    | 34/57 [00:23<00:16,  1.43it/s, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:02,  2.72s/it]\u001b[A\n",
      "Epoch 0:  63%|██████▎   | 36/57 [00:28<00:16,  1.27it/s, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:52,  2.48s/it]\u001b[A\n",
      "Epoch 0:  67%|██████▋   | 38/57 [00:32<00:16,  1.16it/s, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:42,  2.26s/it]\u001b[A\n",
      "Epoch 0:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:39,  2.32s/it]\u001b[A\n",
      "Epoch 0:  74%|███████▎  | 42/57 [00:42<00:15,  1.01s/it, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.35s/it]\u001b[A\n",
      "Epoch 0:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:28,  2.23s/it]\u001b[A\n",
      "Epoch 0:  81%|████████  | 46/57 [00:50<00:12,  1.11s/it, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.19s/it]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.27s/it]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 50/57 [00:59<00:08,  1.20s/it, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.24s/it]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.26s/it]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.22s/it]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=232, v_num=92, train_loss_step=269.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.26s/it]\u001b[A\n",
      "Epoch 0: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=232, v_num=92, train_loss_step=269.0, val_loss=206.0]\n",
      "Epoch 1:  53%|█████▎    | 30/57 [00:14<00:12,  2.14it/s, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 32/57 [00:17<00:13,  1.80it/s, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:16,  3.06s/it]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 34/57 [00:22<00:15,  1.50it/s, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.52s/it]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:51,  2.47s/it]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.34s/it]\u001b[A\n",
      "Epoch 1:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:40,  2.39s/it]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:37,  2.52s/it]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:31,  2.43s/it]\u001b[A\n",
      "Epoch 1:  81%|████████  | 46/57 [00:50<00:12,  1.11s/it, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.36s/it]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.27s/it]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 50/57 [00:59<00:08,  1.20s/it, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:17,  2.47s/it]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:12,  2.42s/it]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 54/57 [01:09<00:03,  1.29s/it, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.23s/it]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 56/57 [01:14<00:01,  1.32s/it, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.13s/it]\u001b[A\n",
      "Epoch 1: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=241, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Epoch 2:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:14,  2.99s/it]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 34/57 [00:23<00:15,  1.46it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:02,  2.70s/it]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 36/57 [00:28<00:16,  1.27it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:56,  2.71s/it]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 38/57 [00:33<00:16,  1.13it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:21<00:48,  2.54s/it]\u001b[A\n",
      "Epoch 2:  70%|███████   | 40/57 [00:38<00:16,  1.04it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:26<00:42,  2.51s/it]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 42/57 [00:43<00:15,  1.04s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:31<00:37,  2.49s/it]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 44/57 [00:48<00:14,  1.09s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:36<00:31,  2.42s/it]\u001b[A\n",
      "Epoch 2:  81%|████████  | 46/57 [00:53<00:12,  1.16s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:41<00:26,  2.42s/it]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 48/57 [00:57<00:10,  1.21s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:21,  2.40s/it]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 50/57 [01:02<00:08,  1.25s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:50<00:17,  2.43s/it]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 52/57 [01:07<00:06,  1.30s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:55<00:12,  2.46s/it]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 54/57 [01:12<00:04,  1.34s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  89%|████████▉ | 24/27 [01:00<00:07,  2.50s/it]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 56/57 [01:17<00:01,  1.39s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:05<00:02,  2.30s/it]\u001b[A\n",
      "Epoch 2: 100%|██████████| 57/57 [01:20<00:00,  1.41s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Epoch 3:  53%|█████▎    | 30/57 [00:14<00:13,  2.05it/s, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 32/57 [00:18<00:14,  1.74it/s, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:   7%|▋         | 2/27 [00:05<01:07,  2.70s/it]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 34/57 [00:23<00:15,  1.48it/s, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.50s/it]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:48,  2.32s/it]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 38/57 [00:32<00:16,  1.18it/s, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:47,  2.49s/it]\u001b[A\n",
      "Epoch 3:  70%|███████   | 40/57 [00:37<00:15,  1.08it/s, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:40,  2.40s/it]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 42/57 [00:42<00:15,  1.01s/it, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:36,  2.44s/it]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 44/57 [00:47<00:13,  1.07s/it, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:31,  2.41s/it]\u001b[A\n",
      "Epoch 3:  81%|████████  | 46/57 [00:51<00:12,  1.12s/it, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.28s/it]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 48/57 [00:55<00:10,  1.17s/it, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.27s/it]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.31s/it]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.36s/it]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 54/57 [01:10<00:03,  1.30s/it, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:07,  2.34s/it]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 56/57 [01:15<00:01,  1.34s/it, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.30s/it]\u001b[A\n",
      "Epoch 3: 100%|██████████| 57/57 [01:18<00:00,  1.37s/it, loss=236, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Epoch 4:  53%|█████▎    | 30/57 [00:13<00:12,  2.16it/s, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  56%|█████▌    | 32/57 [00:18<00:14,  1.77it/s, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.94s/it]\u001b[A\n",
      "Epoch 4:  60%|█████▉    | 34/57 [00:22<00:15,  1.50it/s, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:04,  2.79s/it]\u001b[A\n",
      "Epoch 4:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.40s/it]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.34s/it]\u001b[A\n",
      "Epoch 4:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.31s/it]\u001b[A\n",
      "Epoch 4:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:36,  2.42s/it]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.29s/it]\u001b[A\n",
      "Epoch 4:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.24s/it]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:21,  2.36s/it]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 50/57 [01:00<00:08,  1.20s/it, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.33s/it]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 52/57 [01:04<00:06,  1.25s/it, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.37s/it]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 54/57 [01:09<00:03,  1.29s/it, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.33s/it]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.18s/it]\u001b[A\n",
      "Epoch 4: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=240, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 5:  53%|█████▎    | 30/57 [00:14<00:12,  2.11it/s, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  56%|█████▌    | 32/57 [00:17<00:14,  1.78it/s, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.91s/it]\u001b[A\n",
      "Epoch 5:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.49s/it]\u001b[A\n",
      "Epoch 5:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.32s/it]\u001b[A\n",
      "Epoch 5:  67%|██████▋   | 38/57 [00:31<00:15,  1.21it/s, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.22s/it]\u001b[A\n",
      "Epoch 5:  70%|███████   | 40/57 [00:35<00:15,  1.11it/s, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:41,  2.46s/it]\u001b[A\n",
      "Epoch 5:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:36,  2.46s/it]\u001b[A\n",
      "Epoch 5:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.30s/it]\u001b[A\n",
      "Epoch 5:  81%|████████  | 46/57 [00:50<00:11,  1.09s/it, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.32s/it]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.32s/it]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.23s/it]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:12,  2.47s/it]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:07,  2.34s/it]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.27s/it]\u001b[A\n",
      "Epoch 5: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=234, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 6:  53%|█████▎    | 30/57 [00:14<00:13,  2.06it/s, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.96s/it]\u001b[A\n",
      "Epoch 6:  60%|█████▉    | 34/57 [00:22<00:15,  1.48it/s, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:01,  2.68s/it]\u001b[A\n",
      "Epoch 6:  63%|██████▎   | 36/57 [00:27<00:16,  1.29it/s, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:51,  2.45s/it]\u001b[A\n",
      "Epoch 6:  67%|██████▋   | 38/57 [00:32<00:16,  1.16it/s, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:45,  2.42s/it]\u001b[A\n",
      "Epoch 6:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:40,  2.38s/it]\u001b[A\n",
      "Epoch 6:  74%|███████▎  | 42/57 [00:42<00:15,  1.00s/it, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.37s/it]\u001b[A\n",
      "Epoch 6:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.25s/it]\u001b[A\n",
      "Epoch 6:  81%|████████  | 46/57 [00:51<00:12,  1.11s/it, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.26s/it]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:19,  2.18s/it]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:16,  2.29s/it]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 52/57 [01:04<00:06,  1.25s/it, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.22s/it]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.22s/it]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.05s/it]\u001b[A\n",
      "Epoch 6: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=235, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Epoch 7:  53%|█████▎    | 30/57 [00:13<00:12,  2.18it/s, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  56%|█████▌    | 32/57 [00:17<00:13,  1.83it/s, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:17,  3.10s/it]\u001b[A\n",
      "Epoch 7:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.59s/it]\u001b[A\n",
      "Epoch 7:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.42s/it]\u001b[A\n",
      "Epoch 7:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:43,  2.28s/it]\u001b[A\n",
      "Epoch 7:  70%|███████   | 40/57 [00:36<00:15,  1.11it/s, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.29s/it]\u001b[A\n",
      "Epoch 7:  74%|███████▎  | 42/57 [00:40<00:14,  1.04it/s, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.29s/it]\u001b[A\n",
      "Epoch 7:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.27s/it]\u001b[A\n",
      "Epoch 7:  81%|████████  | 46/57 [00:49<00:11,  1.08s/it, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.31s/it]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:23,  2.64s/it]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 50/57 [01:00<00:08,  1.20s/it, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:17,  2.55s/it]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:12,  2.47s/it]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 54/57 [01:09<00:03,  1.29s/it, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:06,  2.31s/it]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 56/57 [01:14<00:01,  1.32s/it, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.20s/it]\u001b[A\n",
      "Epoch 7: 100%|██████████| 57/57 [01:17<00:00,  1.36s/it, loss=233, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Epoch 8:  53%|█████▎    | 30/57 [00:14<00:12,  2.14it/s, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:24,  3.37s/it]\u001b[A\n",
      "Epoch 8:  60%|█████▉    | 34/57 [00:23<00:15,  1.47it/s, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:02,  2.73s/it]\u001b[A\n",
      "Epoch 8:  63%|██████▎   | 36/57 [00:28<00:16,  1.28it/s, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:50,  2.43s/it]\u001b[A\n",
      "Epoch 8:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:46,  2.44s/it]\u001b[A\n",
      "Epoch 8:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:39,  2.32s/it]\u001b[A\n",
      "Epoch 8:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:35,  2.36s/it]\u001b[A\n",
      "Epoch 8:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.25s/it]\u001b[A\n",
      "Epoch 8:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.29s/it]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:21,  2.36s/it]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 50/57 [01:00<00:08,  1.20s/it, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:17,  2.46s/it]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:12,  2.42s/it]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 54/57 [01:10<00:03,  1.30s/it, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:07,  2.35s/it]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 56/57 [01:14<00:01,  1.34s/it, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.23s/it]\u001b[A\n",
      "Epoch 8: 100%|██████████| 57/57 [01:17<00:00,  1.37s/it, loss=238, v_num=92, train_loss_step=309.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Epoch 9:  53%|█████▎    | 30/57 [00:14<00:13,  2.07it/s, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  56%|█████▌    | 32/57 [00:18<00:14,  1.71it/s, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:22,  3.30s/it]\u001b[A\n",
      "Epoch 9:  60%|█████▉    | 34/57 [00:23<00:15,  1.44it/s, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:04,  2.80s/it]\u001b[A\n",
      "Epoch 9:  63%|██████▎   | 36/57 [00:28<00:16,  1.26it/s, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:51,  2.45s/it]\u001b[A\n",
      "Epoch 9:  67%|██████▋   | 38/57 [00:33<00:16,  1.15it/s, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.34s/it]\u001b[A\n",
      "Epoch 9:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:38,  2.29s/it]\u001b[A\n",
      "Epoch 9:  74%|███████▎  | 42/57 [00:42<00:15,  1.00s/it, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.29s/it]\u001b[A\n",
      "Epoch 9:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.26s/it]\u001b[A\n",
      "Epoch 9:  81%|████████  | 46/57 [00:51<00:12,  1.11s/it, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.33s/it]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:21,  2.37s/it]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 50/57 [01:00<00:08,  1.22s/it, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.38s/it]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:12,  2.52s/it]\u001b[A\n",
      "Epoch 9:  95%|█████████▍| 54/57 [01:10<00:03,  1.31s/it, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:07,  2.37s/it]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 56/57 [01:15<00:01,  1.34s/it, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.27s/it]\u001b[A\n",
      "Epoch 9: 100%|██████████| 57/57 [01:18<00:00,  1.37s/it, loss=232, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 10:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:14,  2.97s/it]\u001b[A\n",
      "Epoch 10:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:58,  2.56s/it]\u001b[A\n",
      "Epoch 10:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.32s/it]\u001b[A\n",
      "Epoch 10:  67%|██████▋   | 38/57 [00:32<00:16,  1.19it/s, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.34s/it]\u001b[A\n",
      "Epoch 10:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:41,  2.43s/it]\u001b[A\n",
      "Epoch 10:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:36,  2.44s/it]\u001b[A\n",
      "Epoch 10:  77%|███████▋  | 44/57 [00:46<00:13,  1.07s/it, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.35s/it]\u001b[A\n",
      "Epoch 10:  81%|████████  | 46/57 [00:51<00:12,  1.12s/it, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:26,  2.38s/it]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 48/57 [00:56<00:10,  1.17s/it, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:21,  2.34s/it]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 50/57 [01:00<00:08,  1.22s/it, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.28s/it]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:12,  2.42s/it]\u001b[A\n",
      "Epoch 10:  95%|█████████▍| 54/57 [01:10<00:03,  1.30s/it, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.22s/it]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 56/57 [01:14<00:01,  1.32s/it, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.08s/it]\u001b[A\n",
      "Epoch 10: 100%|██████████| 57/57 [01:17<00:00,  1.35s/it, loss=234, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Epoch 11:  53%|█████▎    | 30/57 [00:14<00:12,  2.12it/s, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  56%|█████▌    | 32/57 [00:18<00:14,  1.74it/s, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:14,  2.97s/it]\u001b[A\n",
      "Epoch 11:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:55,  2.41s/it]\u001b[A\n",
      "Epoch 11:  63%|██████▎   | 36/57 [00:26<00:15,  1.34it/s, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.31s/it]\u001b[A\n",
      "Epoch 11:  67%|██████▋   | 38/57 [00:31<00:15,  1.21it/s, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:44,  2.33s/it]\u001b[A\n",
      "Epoch 11:  70%|███████   | 40/57 [00:36<00:15,  1.11it/s, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.30s/it]\u001b[A\n",
      "Epoch 11:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.40s/it]\u001b[A\n",
      "Epoch 11:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.30s/it]\u001b[A\n",
      "Epoch 11:  81%|████████  | 46/57 [00:49<00:11,  1.09s/it, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:27,  2.48s/it]\u001b[A\n",
      "Epoch 11:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.32s/it]\u001b[A\n",
      "Epoch 11:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.25s/it]\u001b[A\n",
      "Epoch 11:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.28s/it]\u001b[A\n",
      "Epoch 11:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.28s/it]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 56/57 [01:13<00:01,  1.30s/it, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.09s/it]\u001b[A\n",
      "Epoch 11: 100%|██████████| 57/57 [01:15<00:00,  1.33s/it, loss=238, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 12:  53%|█████▎    | 30/57 [00:14<00:12,  2.12it/s, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:15,  3.01s/it]\u001b[A\n",
      "Epoch 12:  60%|█████▉    | 34/57 [00:22<00:15,  1.48it/s, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:58,  2.56s/it]\u001b[A\n",
      "Epoch 12:  63%|██████▎   | 36/57 [00:28<00:16,  1.26it/s, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:54,  2.62s/it]\u001b[A\n",
      "Epoch 12:  67%|██████▋   | 38/57 [00:32<00:16,  1.15it/s, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:45,  2.39s/it]\u001b[A\n",
      "Epoch 12:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:38,  2.26s/it]\u001b[A\n",
      "Epoch 12:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:34,  2.32s/it]\u001b[A\n",
      "Epoch 12:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.29s/it]\u001b[A\n",
      "Epoch 12:  81%|████████  | 46/57 [00:50<00:12,  1.11s/it, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.23s/it]\u001b[A\n",
      "Epoch 12:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.25s/it]\u001b[A\n",
      "Epoch 12:  88%|████████▊ | 50/57 [00:59<00:08,  1.20s/it, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.28s/it]\u001b[A\n",
      "Epoch 12:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.37s/it]\u001b[A\n",
      "Epoch 12:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.25s/it]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.20s/it]\u001b[A\n",
      "Epoch 12: 100%|██████████| 57/57 [01:17<00:00,  1.36s/it, loss=240, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Epoch 13:  53%|█████▎    | 30/57 [00:14<00:13,  2.07it/s, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  56%|█████▌    | 32/57 [00:18<00:14,  1.72it/s, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.94s/it]\u001b[A\n",
      "Epoch 13:  60%|█████▉    | 34/57 [00:23<00:15,  1.47it/s, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.57s/it]\u001b[A\n",
      "Epoch 13:  63%|██████▎   | 36/57 [00:27<00:16,  1.29it/s, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.39s/it]\u001b[A\n",
      "Epoch 13:  67%|██████▋   | 38/57 [00:32<00:16,  1.18it/s, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.31s/it]\u001b[A\n",
      "Epoch 13:  70%|███████   | 40/57 [00:36<00:15,  1.08it/s, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.30s/it]\u001b[A\n",
      "Epoch 13:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.29s/it]\u001b[A\n",
      "Epoch 13:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.29s/it]\u001b[A\n",
      "Epoch 13:  81%|████████  | 46/57 [00:50<00:12,  1.09s/it, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:26,  2.42s/it]\u001b[A\n",
      "Epoch 13:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.32s/it]\u001b[A\n",
      "Epoch 13:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.19s/it]\u001b[A\n",
      "Epoch 13:  91%|█████████ | 52/57 [01:03<00:06,  1.23s/it, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 13:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.28s/it]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.35s/it]\u001b[A\n",
      "Epoch 13: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=244, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Epoch 14:  53%|█████▎    | 30/57 [00:13<00:12,  2.16it/s, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  56%|█████▌    | 32/57 [00:17<00:13,  1.79it/s, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:17,  3.11s/it]\u001b[A\n",
      "Epoch 14:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.58s/it]\u001b[A\n",
      "Epoch 14:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.33s/it]\u001b[A\n",
      "Epoch 14:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:21<00:52,  2.76s/it]\u001b[A\n",
      "Epoch 14:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:42,  2.48s/it]\u001b[A\n",
      "Epoch 14:  74%|███████▎  | 42/57 [00:42<00:15,  1.00s/it, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:35,  2.34s/it]\u001b[A\n",
      "Epoch 14:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.28s/it]\u001b[A\n",
      "Epoch 14:  81%|████████  | 46/57 [00:51<00:12,  1.11s/it, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:24,  2.27s/it]\u001b[A\n",
      "Epoch 14:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.28s/it]\u001b[A\n",
      "Epoch 14:  88%|████████▊ | 50/57 [00:59<00:08,  1.20s/it, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.19s/it]\u001b[A\n",
      "Epoch 14:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 14:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.27s/it]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.33s/it]\u001b[A\n",
      "Epoch 14: 100%|██████████| 57/57 [01:17<00:00,  1.36s/it, loss=237, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Epoch 15:  53%|█████▎    | 30/57 [00:14<00:12,  2.13it/s, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  56%|█████▌    | 32/57 [00:19<00:15,  1.64it/s, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:07<01:26,  3.45s/it]\u001b[A\n",
      "Epoch 15:  60%|█████▉    | 34/57 [00:24<00:16,  1.41it/s, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:00,  2.62s/it]\u001b[A\n",
      "Epoch 15:  63%|██████▎   | 36/57 [00:28<00:16,  1.26it/s, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:52,  2.48s/it]\u001b[A\n",
      "Epoch 15:  67%|██████▋   | 38/57 [00:33<00:16,  1.14it/s, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:21<00:45,  2.39s/it]\u001b[A\n",
      "Epoch 15:  70%|███████   | 40/57 [00:37<00:16,  1.06it/s, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:26<00:40,  2.35s/it]\u001b[A\n",
      "Epoch 15:  74%|███████▎  | 42/57 [00:43<00:15,  1.03s/it, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:31<00:37,  2.50s/it]\u001b[A\n",
      "Epoch 15:  77%|███████▋  | 44/57 [00:48<00:14,  1.09s/it, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:30,  2.35s/it]\u001b[A\n",
      "Epoch 15:  81%|████████  | 46/57 [00:52<00:12,  1.14s/it, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:40<00:25,  2.36s/it]\u001b[A\n",
      "Epoch 15:  84%|████████▍ | 48/57 [00:57<00:10,  1.19s/it, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:20,  2.27s/it]\u001b[A\n",
      "Epoch 15:  88%|████████▊ | 50/57 [01:01<00:08,  1.23s/it, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:16,  2.29s/it]\u001b[A\n",
      "Epoch 15:  91%|█████████ | 52/57 [01:06<00:06,  1.27s/it, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:11,  2.30s/it]\u001b[A\n",
      "Epoch 15:  95%|█████████▍| 54/57 [01:10<00:03,  1.31s/it, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:07,  2.48s/it]\u001b[A\n",
      "Epoch 15:  98%|█████████▊| 56/57 [01:15<00:01,  1.35s/it, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.26s/it]\u001b[A\n",
      "Epoch 15: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=238, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 16:  53%|█████▎    | 30/57 [00:13<00:12,  2.15it/s, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:21,  3.25s/it]\u001b[A\n",
      "Epoch 16:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.44s/it]\u001b[A\n",
      "Epoch 16:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.32s/it]\u001b[A\n",
      "Epoch 16:  67%|██████▋   | 38/57 [00:31<00:15,  1.21it/s, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.23s/it]\u001b[A\n",
      "Epoch 16:  70%|███████   | 40/57 [00:35<00:15,  1.11it/s, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.30s/it]\u001b[A\n",
      "Epoch 16:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.31s/it]\u001b[A\n",
      "Epoch 16:  77%|███████▋  | 44/57 [00:45<00:13,  1.02s/it, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.23s/it]\u001b[A\n",
      "Epoch 16:  81%|████████  | 46/57 [00:49<00:11,  1.08s/it, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.20s/it]\u001b[A\n",
      "Epoch 16:  84%|████████▍ | 48/57 [00:53<00:10,  1.12s/it, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:22,  2.46s/it]\u001b[A\n",
      "Epoch 16:  88%|████████▊ | 50/57 [00:59<00:08,  1.18s/it, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.29s/it]\u001b[A\n",
      "Epoch 16:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:12,  2.40s/it]\u001b[A\n",
      "Epoch 16:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.27s/it]\u001b[A\n",
      "Epoch 16:  98%|█████████▊| 56/57 [01:12<00:01,  1.30s/it, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.25s/it]\u001b[A\n",
      "Epoch 16: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=232, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Epoch 17:  53%|█████▎    | 30/57 [00:14<00:13,  2.02it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  56%|█████▌    | 32/57 [00:18<00:14,  1.70it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:14,  2.97s/it]\u001b[A\n",
      "Epoch 17:  60%|█████▉    | 34/57 [00:24<00:16,  1.42it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.61s/it]\u001b[A\n",
      "Epoch 17:  63%|██████▎   | 36/57 [00:28<00:16,  1.27it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.38s/it]\u001b[A\n",
      "Epoch 17:  67%|██████▋   | 38/57 [00:32<00:16,  1.15it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:43,  2.30s/it]\u001b[A\n",
      "Epoch 17:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.32s/it]\u001b[A\n",
      "Epoch 17:  74%|███████▎  | 42/57 [00:42<00:15,  1.01s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:38,  2.55s/it]\u001b[A\n",
      "Epoch 17:  77%|███████▋  | 44/57 [00:47<00:14,  1.08s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:32,  2.47s/it]\u001b[A\n",
      "Epoch 17:  81%|████████  | 46/57 [00:52<00:12,  1.14s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.32s/it]\u001b[A\n",
      "Epoch 17:  84%|████████▍ | 48/57 [00:56<00:10,  1.18s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.22s/it]\u001b[A\n",
      "Epoch 17:  88%|████████▊ | 50/57 [01:00<00:08,  1.22s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.22s/it]\u001b[A\n",
      "Epoch 17:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.24s/it]\u001b[A\n",
      "Epoch 17:  95%|█████████▍| 54/57 [01:09<00:03,  1.29s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.18s/it]\u001b[A\n",
      "Epoch 17:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.05s/it]\u001b[A\n",
      "Epoch 17: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Epoch 18:  53%|█████▎    | 30/57 [00:14<00:12,  2.11it/s, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  56%|█████▌    | 32/57 [00:18<00:14,  1.77it/s, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:11,  2.86s/it]\u001b[A\n",
      "Epoch 18:  60%|█████▉    | 34/57 [00:22<00:15,  1.50it/s, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.52s/it]\u001b[A\n",
      "Epoch 18:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.35s/it]\u001b[A\n",
      "Epoch 18:  67%|██████▋   | 38/57 [00:32<00:16,  1.16it/s, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:48,  2.53s/it]\u001b[A\n",
      "Epoch 18:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:43,  2.53s/it]\u001b[A\n",
      "Epoch 18:  74%|███████▎  | 42/57 [00:42<00:15,  1.01s/it, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:37,  2.50s/it]\u001b[A\n",
      "Epoch 18:  77%|███████▋  | 44/57 [00:47<00:13,  1.07s/it, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:31,  2.42s/it]\u001b[A\n",
      "Epoch 18:  81%|████████  | 46/57 [00:51<00:12,  1.13s/it, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:40<00:26,  2.41s/it]\u001b[A\n",
      "Epoch 18:  84%|████████▍ | 48/57 [00:56<00:10,  1.18s/it, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:21,  2.39s/it]\u001b[A\n",
      "Epoch 18:  88%|████████▊ | 50/57 [01:01<00:08,  1.23s/it, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:15,  2.28s/it]\u001b[A\n",
      "Epoch 18:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.21s/it]\u001b[A\n",
      "Epoch 18:  95%|█████████▍| 54/57 [01:09<00:03,  1.30s/it, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.17s/it]\u001b[A\n",
      "Epoch 18:  98%|█████████▊| 56/57 [01:14<00:01,  1.33s/it, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.15s/it]\u001b[A\n",
      "Epoch 18: 100%|██████████| 57/57 [01:17<00:00,  1.36s/it, loss=234, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Epoch 19:  53%|█████▎    | 30/57 [00:14<00:13,  2.05it/s, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  56%|█████▌    | 32/57 [00:19<00:14,  1.68it/s, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:21,  3.26s/it]\u001b[A\n",
      "Epoch 19:  60%|█████▉    | 34/57 [00:23<00:16,  1.42it/s, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:12<01:11,  3.09s/it]\u001b[A\n",
      "Epoch 19:  63%|██████▎   | 36/57 [00:29<00:17,  1.22it/s, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:17<00:54,  2.59s/it]\u001b[A\n",
      "Epoch 19:  67%|██████▋   | 38/57 [00:33<00:16,  1.12it/s, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:21<00:45,  2.39s/it]\u001b[A\n",
      "Epoch 19:  70%|███████   | 40/57 [00:38<00:16,  1.04it/s, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:39,  2.30s/it]\u001b[A\n",
      "Epoch 19:  74%|███████▎  | 42/57 [00:43<00:15,  1.03s/it, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:34,  2.31s/it]\u001b[A\n",
      "Epoch 19:  77%|███████▋  | 44/57 [00:47<00:14,  1.08s/it, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:29,  2.30s/it]\u001b[A\n",
      "Epoch 19:  81%|████████  | 46/57 [00:52<00:12,  1.14s/it, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.30s/it]\u001b[A\n",
      "Epoch 19:  84%|████████▍ | 48/57 [00:56<00:10,  1.18s/it, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:19,  2.22s/it]\u001b[A\n",
      "Epoch 19:  88%|████████▊ | 50/57 [01:00<00:08,  1.22s/it, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.28s/it]\u001b[A\n",
      "Epoch 19:  91%|█████████ | 52/57 [01:06<00:06,  1.27s/it, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.34s/it]\u001b[A\n",
      "Epoch 19:  95%|█████████▍| 54/57 [01:10<00:03,  1.31s/it, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:06,  2.30s/it]\u001b[A\n",
      "Epoch 19:  98%|█████████▊| 56/57 [01:15<00:01,  1.34s/it, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.20s/it]\u001b[A\n",
      "Epoch 19: 100%|██████████| 57/57 [01:18<00:00,  1.37s/it, loss=236, v_num=92, train_loss_step=254.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Epoch 20:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:07<01:30,  3.60s/it]\u001b[A\n",
      "Epoch 20:  60%|█████▉    | 34/57 [00:24<00:16,  1.41it/s, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:12<01:03,  2.76s/it]\u001b[A\n",
      "Epoch 20:  63%|██████▎   | 36/57 [00:28<00:16,  1.26it/s, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:50,  2.38s/it]\u001b[A\n",
      "Epoch 20:  67%|██████▋   | 38/57 [00:32<00:16,  1.16it/s, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:42,  2.23s/it]\u001b[A\n",
      "Epoch 20:  70%|███████   | 40/57 [00:37<00:15,  1.08it/s, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:37,  2.21s/it]\u001b[A\n",
      "Epoch 20:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:33,  2.22s/it]\u001b[A\n",
      "Epoch 20:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:28,  2.17s/it]\u001b[A\n",
      "Epoch 20:  81%|████████  | 46/57 [00:49<00:11,  1.09s/it, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:23,  2.09s/it]\u001b[A\n",
      "Epoch 20:  84%|████████▍ | 48/57 [00:54<00:10,  1.13s/it, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.24s/it]\u001b[A\n",
      "Epoch 20:  88%|████████▊ | 50/57 [00:58<00:08,  1.18s/it, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.16s/it]\u001b[A\n",
      "Epoch 20:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.20s/it]\u001b[A\n",
      "Epoch 20:  95%|█████████▍| 54/57 [01:07<00:03,  1.25s/it, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.19s/it]\u001b[A\n",
      "Epoch 20:  98%|█████████▊| 56/57 [01:12<00:01,  1.29s/it, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:59<00:02,  2.11s/it]\u001b[A\n",
      "Epoch 20: 100%|██████████| 57/57 [01:15<00:00,  1.32s/it, loss=236, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 21:  53%|█████▎    | 30/57 [00:13<00:12,  2.14it/s, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:07<01:33,  3.73s/it]\u001b[A\n",
      "Epoch 21:  60%|█████▉    | 34/57 [00:23<00:16,  1.42it/s, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:12<01:03,  2.74s/it]\u001b[A\n",
      "Epoch 21:  63%|██████▎   | 36/57 [00:28<00:16,  1.27it/s, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:50,  2.41s/it]\u001b[A\n",
      "Epoch 21:  67%|██████▋   | 38/57 [00:32<00:16,  1.16it/s, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:42,  2.25s/it]\u001b[A\n",
      "Epoch 21:  70%|███████   | 40/57 [00:36<00:15,  1.08it/s, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:37,  2.20s/it]\u001b[A\n",
      "Epoch 21:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:33,  2.26s/it]\u001b[A\n",
      "Epoch 21:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.29s/it]\u001b[A\n",
      "Epoch 21:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.22s/it]\u001b[A\n",
      "Epoch 21:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.25s/it]\u001b[A\n",
      "Epoch 21:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:16,  2.29s/it]\u001b[A\n",
      "Epoch 21:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.39s/it]\u001b[A\n",
      "Epoch 21:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.32s/it]\u001b[A\n",
      "Epoch 21:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.24s/it]\u001b[A\n",
      "Epoch 21: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=246, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 22:  53%|█████▎    | 30/57 [00:14<00:12,  2.11it/s, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  56%|█████▌    | 32/57 [00:18<00:14,  1.74it/s, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:15,  3.02s/it]\u001b[A\n",
      "Epoch 22:  60%|█████▉    | 34/57 [00:23<00:16,  1.42it/s, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:12<01:05,  2.85s/it]\u001b[A\n",
      "Epoch 22:  63%|██████▎   | 36/57 [00:28<00:16,  1.26it/s, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:52,  2.52s/it]\u001b[A\n",
      "Epoch 22:  67%|██████▋   | 38/57 [00:33<00:16,  1.15it/s, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:21<00:44,  2.33s/it]\u001b[A\n",
      "Epoch 22:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:38,  2.29s/it]\u001b[A\n",
      "Epoch 22:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.27s/it]\u001b[A\n",
      "Epoch 22:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.28s/it]\u001b[A\n",
      "Epoch 22:  81%|████████  | 46/57 [00:50<00:12,  1.11s/it, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.33s/it]\u001b[A\n",
      "Epoch 22:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.32s/it]\u001b[A\n",
      "Epoch 22:  88%|████████▊ | 50/57 [01:00<00:08,  1.20s/it, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.25s/it]\u001b[A\n",
      "Epoch 22:  91%|█████████ | 52/57 [01:05<00:06,  1.25s/it, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.32s/it]\u001b[A\n",
      "Epoch 22:  95%|█████████▍| 54/57 [01:09<00:03,  1.29s/it, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.19s/it]\u001b[A\n",
      "Epoch 22:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.09s/it]\u001b[A\n",
      "Epoch 22: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=241, v_num=92, train_loss_step=239.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Epoch 23:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:15,  3.01s/it]\u001b[A\n",
      "Epoch 23:  60%|█████▉    | 34/57 [00:23<00:15,  1.46it/s, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:12<01:09,  3.02s/it]\u001b[A\n",
      "Epoch 23:  63%|██████▎   | 36/57 [00:28<00:16,  1.25it/s, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:17<00:57,  2.75s/it]\u001b[A\n",
      "Epoch 23:  67%|██████▋   | 38/57 [00:33<00:16,  1.13it/s, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:21<00:46,  2.47s/it]\u001b[A\n",
      "Epoch 23:  70%|███████   | 40/57 [00:38<00:16,  1.04it/s, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:26<00:39,  2.32s/it]\u001b[A\n",
      "Epoch 23:  74%|███████▎  | 42/57 [00:42<00:15,  1.02s/it, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:34,  2.32s/it]\u001b[A\n",
      "Epoch 23:  77%|███████▋  | 44/57 [00:47<00:13,  1.08s/it, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:30,  2.31s/it]\u001b[A\n",
      "Epoch 23:  81%|████████  | 46/57 [00:52<00:12,  1.14s/it, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.30s/it]\u001b[A\n",
      "Epoch 23:  84%|████████▍ | 48/57 [00:56<00:10,  1.18s/it, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:20,  2.31s/it]\u001b[A\n",
      "Epoch 23:  88%|████████▊ | 50/57 [01:01<00:08,  1.23s/it, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:16,  2.33s/it]\u001b[A\n",
      "Epoch 23:  91%|█████████ | 52/57 [01:06<00:06,  1.28s/it, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:11,  2.39s/it]\u001b[A\n",
      "Epoch 23:  95%|█████████▍| 54/57 [01:11<00:03,  1.32s/it, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:07,  2.42s/it]\u001b[A\n",
      "Epoch 23:  98%|█████████▊| 56/57 [01:16<00:01,  1.36s/it, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.30s/it]\u001b[A\n",
      "Epoch 23: 100%|██████████| 57/57 [01:19<00:00,  1.39s/it, loss=243, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Epoch 24:  53%|█████▎    | 30/57 [00:14<00:13,  2.06it/s, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:17,  3.12s/it]\u001b[A\n",
      "Epoch 24:  60%|█████▉    | 34/57 [00:23<00:15,  1.45it/s, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.60s/it]\u001b[A\n",
      "Epoch 24:  63%|██████▎   | 36/57 [00:27<00:16,  1.29it/s, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.42s/it]\u001b[A\n",
      "Epoch 24:  67%|██████▋   | 38/57 [00:33<00:16,  1.13it/s, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:21<00:48,  2.56s/it]\u001b[A\n",
      "Epoch 24:  70%|███████   | 40/57 [00:37<00:16,  1.05it/s, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:39,  2.34s/it]\u001b[A\n",
      "Epoch 24:  74%|███████▎  | 42/57 [00:42<00:15,  1.01s/it, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:34,  2.30s/it]\u001b[A\n",
      "Epoch 24:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:28,  2.21s/it]\u001b[A\n",
      "Epoch 24:  81%|████████  | 46/57 [00:51<00:12,  1.12s/it, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:23,  2.18s/it]\u001b[A\n",
      "Epoch 24:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.27s/it]\u001b[A\n",
      "Epoch 24:  88%|████████▊ | 50/57 [01:00<00:08,  1.20s/it, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.17s/it]\u001b[A\n",
      "Epoch 24:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.21s/it]\u001b[A\n",
      "Epoch 24:  95%|█████████▍| 54/57 [01:08<00:03,  1.28s/it, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.22s/it]\u001b[A\n",
      "Epoch 24:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.19s/it]\u001b[A\n",
      "Epoch 24: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=233, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 25:  53%|█████▎    | 30/57 [00:14<00:13,  2.06it/s, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  56%|█████▌    | 32/57 [00:18<00:14,  1.69it/s, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:17,  3.11s/it]\u001b[A\n",
      "Epoch 25:  60%|█████▉    | 34/57 [00:23<00:15,  1.44it/s, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:58,  2.55s/it]\u001b[A\n",
      "Epoch 25:  63%|██████▎   | 36/57 [00:28<00:16,  1.28it/s, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.35s/it]\u001b[A\n",
      "Epoch 25:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:43,  2.27s/it]\u001b[A\n",
      "Epoch 25:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.24s/it]\u001b[A\n",
      "Epoch 25:  74%|███████▎  | 42/57 [00:42<00:15,  1.02s/it, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:37,  2.50s/it]\u001b[A\n",
      "Epoch 25:  77%|███████▋  | 44/57 [00:47<00:13,  1.08s/it, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.38s/it]\u001b[A\n",
      "Epoch 25:  81%|████████  | 46/57 [00:51<00:12,  1.12s/it, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:26,  2.37s/it]\u001b[A\n",
      "Epoch 25:  84%|████████▍ | 48/57 [00:56<00:10,  1.17s/it, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:21,  2.36s/it]\u001b[A\n",
      "Epoch 25:  88%|████████▊ | 50/57 [01:00<00:08,  1.22s/it, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.20s/it]\u001b[A\n",
      "Epoch 25:  91%|█████████ | 52/57 [01:05<00:06,  1.25s/it, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.26s/it]\u001b[A\n",
      "Epoch 25:  95%|█████████▍| 54/57 [01:09<00:03,  1.29s/it, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.23s/it]\u001b[A\n",
      "Epoch 25:  98%|█████████▊| 56/57 [01:14<00:01,  1.32s/it, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.09s/it]\u001b[A\n",
      "Epoch 25: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=236, v_num=92, train_loss_step=226.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Epoch 26:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  56%|█████▌    | 32/57 [00:18<00:14,  1.72it/s, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:19,  3.19s/it]\u001b[A\n",
      "Epoch 26:  60%|█████▉    | 34/57 [00:23<00:15,  1.47it/s, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.60s/it]\u001b[A\n",
      "Epoch 26:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:52,  2.51s/it]\u001b[A\n",
      "Epoch 26:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:46,  2.46s/it]\u001b[A\n",
      "Epoch 26:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:43,  2.55s/it]\u001b[A\n",
      "Epoch 26:  74%|███████▎  | 42/57 [00:42<00:15,  1.02s/it, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:35,  2.40s/it]\u001b[A\n",
      "Epoch 26:  77%|███████▋  | 44/57 [00:47<00:13,  1.07s/it, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:29,  2.31s/it]\u001b[A\n",
      "Epoch 26:  81%|████████  | 46/57 [00:51<00:12,  1.12s/it, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:40<00:29,  2.69s/it]\u001b[A\n",
      "Epoch 26:  84%|████████▍ | 48/57 [00:57<00:10,  1.20s/it, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:22,  2.53s/it]\u001b[A\n",
      "Epoch 26:  88%|████████▊ | 50/57 [01:02<00:08,  1.25s/it, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:50<00:16,  2.39s/it]\u001b[A\n",
      "Epoch 26:  91%|█████████ | 52/57 [01:06<00:06,  1.29s/it, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:55<00:11,  2.40s/it]\u001b[A\n",
      "Epoch 26:  95%|█████████▍| 54/57 [01:12<00:04,  1.33s/it, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:07,  2.38s/it]\u001b[A\n",
      "Epoch 26:  98%|█████████▊| 56/57 [01:16<00:01,  1.37s/it, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:04<00:02,  2.23s/it]\u001b[A\n",
      "Epoch 26: 100%|██████████| 57/57 [01:19<00:00,  1.40s/it, loss=233, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 27:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:11,  2.87s/it]\u001b[A\n",
      "Epoch 27:  60%|█████▉    | 34/57 [00:22<00:15,  1.50it/s, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:59,  2.59s/it]\u001b[A\n",
      "Epoch 27:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:51,  2.45s/it]\u001b[A\n",
      "Epoch 27:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:46,  2.43s/it]\u001b[A\n",
      "Epoch 27:  70%|███████   | 40/57 [00:36<00:15,  1.08it/s, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.29s/it]\u001b[A\n",
      "Epoch 27:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.34s/it]\u001b[A\n",
      "Epoch 27:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:28,  2.21s/it]\u001b[A\n",
      "Epoch 27:  81%|████████  | 46/57 [00:50<00:12,  1.09s/it, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.35s/it]\u001b[A\n",
      "Epoch 27:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:21,  2.42s/it]\u001b[A\n",
      "Epoch 27:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.39s/it]\u001b[A\n",
      "Epoch 27:  91%|█████████ | 52/57 [01:06<00:06,  1.27s/it, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:13,  2.63s/it]\u001b[A\n",
      "Epoch 27:  95%|█████████▍| 54/57 [01:11<00:03,  1.32s/it, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:07,  2.65s/it]\u001b[A\n",
      "Epoch 27:  98%|█████████▊| 56/57 [01:16<00:01,  1.36s/it, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.39s/it]\u001b[A\n",
      "Epoch 27: 100%|██████████| 57/57 [01:19<00:00,  1.39s/it, loss=243, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Epoch 28:  53%|█████▎    | 30/57 [00:13<00:12,  2.16it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:17,  3.10s/it]\u001b[A\n",
      "Epoch 28:  60%|█████▉    | 34/57 [00:22<00:15,  1.48it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.59s/it]\u001b[A\n",
      "Epoch 28:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.39s/it]\u001b[A\n",
      "Epoch 28:  67%|██████▋   | 38/57 [00:32<00:16,  1.19it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:43,  2.27s/it]\u001b[A\n",
      "Epoch 28:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.29s/it]\u001b[A\n",
      "Epoch 28:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.36s/it]\u001b[A\n",
      "Epoch 28:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.36s/it]\u001b[A\n",
      "Epoch 28:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:26,  2.38s/it]\u001b[A\n",
      "Epoch 28:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.26s/it]\u001b[A\n",
      "Epoch 28:  88%|████████▊ | 50/57 [01:00<00:08,  1.20s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.35s/it]\u001b[A\n",
      "Epoch 28:  91%|█████████ | 52/57 [01:04<00:06,  1.25s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 28:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.26s/it]\u001b[A\n",
      "Epoch 28:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.09s/it]\u001b[A\n",
      "Epoch 28: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Epoch 29:  53%|█████▎    | 30/57 [00:13<00:12,  2.15it/s, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  56%|█████▌    | 32/57 [00:17<00:14,  1.78it/s, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.95s/it]\u001b[A\n",
      "Epoch 29:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.52s/it]\u001b[A\n",
      "Epoch 29:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:51,  2.47s/it]\u001b[A\n",
      "Epoch 29:  67%|██████▋   | 38/57 [00:32<00:16,  1.18it/s, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.34s/it]\u001b[A\n",
      "Epoch 29:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.28s/it]\u001b[A\n",
      "Epoch 29:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.32s/it]\u001b[A\n",
      "Epoch 29:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:31,  2.40s/it]\u001b[A\n",
      "Epoch 29:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.32s/it]\u001b[A\n",
      "Epoch 29:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.30s/it]\u001b[A\n",
      "Epoch 29:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.35s/it]\u001b[A\n",
      "Epoch 29:  91%|█████████ | 52/57 [01:04<00:06,  1.25s/it, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.38s/it]\u001b[A\n",
      "Epoch 29:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.31s/it]\u001b[A\n",
      "Epoch 29:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.16s/it]\u001b[A\n",
      "Epoch 29: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=245, v_num=92, train_loss_step=245.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Epoch 30:  53%|█████▎    | 30/57 [00:13<00:12,  2.17it/s, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:16,  3.07s/it]\u001b[A\n",
      "Epoch 30:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:57,  2.51s/it]\u001b[A\n",
      "Epoch 30:  63%|██████▎   | 36/57 [00:28<00:16,  1.26it/s, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:55,  2.66s/it]\u001b[A\n",
      "Epoch 30:  67%|██████▋   | 38/57 [00:33<00:16,  1.15it/s, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:21<00:46,  2.43s/it]\u001b[A\n",
      "Epoch 30:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:39,  2.31s/it]\u001b[A\n",
      "Epoch 30:  74%|███████▎  | 42/57 [00:42<00:15,  1.00s/it, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:35,  2.34s/it]\u001b[A\n",
      "Epoch 30:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:30,  2.35s/it]\u001b[A\n",
      "Epoch 30:  81%|████████  | 46/57 [00:51<00:12,  1.11s/it, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.30s/it]\u001b[A\n",
      "Epoch 30:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:20,  2.32s/it]\u001b[A\n",
      "Epoch 30:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.22s/it]\u001b[A\n",
      "Epoch 30:  91%|█████████ | 52/57 [01:04<00:06,  1.25s/it, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.23s/it]\u001b[A\n",
      "Epoch 30:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:07,  2.33s/it]\u001b[A\n",
      "Epoch 30:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.20s/it]\u001b[A\n",
      "Epoch 30: 100%|██████████| 57/57 [01:17<00:00,  1.35s/it, loss=245, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Epoch 31:  53%|█████▎    | 30/57 [00:14<00:12,  2.11it/s, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  56%|█████▌    | 32/57 [00:18<00:14,  1.77it/s, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.92s/it]\u001b[A\n",
      "Epoch 31:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.50s/it]\u001b[A\n",
      "Epoch 31:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.40s/it]\u001b[A\n",
      "Epoch 31:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.27s/it]\u001b[A\n",
      "Epoch 31:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.31s/it]\u001b[A\n",
      "Epoch 31:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:33,  2.27s/it]\u001b[A\n",
      "Epoch 31:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:30,  2.33s/it]\u001b[A\n",
      "Epoch 31:  81%|████████  | 46/57 [00:50<00:11,  1.09s/it, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:29,  2.71s/it]\u001b[A\n",
      "Epoch 31:  84%|████████▍ | 48/57 [00:55<00:10,  1.17s/it, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:22,  2.45s/it]\u001b[A\n",
      "Epoch 31:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.28s/it]\u001b[A\n",
      "Epoch 31:  91%|█████████ | 52/57 [01:04<00:06,  1.25s/it, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.35s/it]\u001b[A\n",
      "Epoch 31:  95%|█████████▍| 54/57 [01:09<00:03,  1.29s/it, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:07,  2.39s/it]\u001b[A\n",
      "Epoch 31:  98%|█████████▊| 56/57 [01:14<00:01,  1.33s/it, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.21s/it]\u001b[A\n",
      "Epoch 31: 100%|██████████| 57/57 [01:17<00:00,  1.36s/it, loss=237, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Epoch 32:  53%|█████▎    | 30/57 [00:14<00:13,  2.07it/s, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  56%|█████▌    | 32/57 [00:18<00:14,  1.69it/s, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:16,  3.06s/it]\u001b[A\n",
      "Epoch 32:  60%|█████▉    | 34/57 [00:23<00:15,  1.46it/s, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.45s/it]\u001b[A\n",
      "Epoch 32:  63%|██████▎   | 36/57 [00:27<00:16,  1.29it/s, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.38s/it]\u001b[A\n",
      "Epoch 32:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.33s/it]\u001b[A\n",
      "Epoch 32:  70%|███████   | 40/57 [00:36<00:15,  1.08it/s, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.24s/it]\u001b[A\n",
      "Epoch 32:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.27s/it]\u001b[A\n",
      "Epoch 32:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.27s/it]\u001b[A\n",
      "Epoch 32:  81%|████████  | 46/57 [00:50<00:12,  1.09s/it, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:23,  2.16s/it]\u001b[A\n",
      "Epoch 32:  84%|████████▍ | 48/57 [00:54<00:10,  1.13s/it, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:22,  2.47s/it]\u001b[A\n",
      "Epoch 32:  88%|████████▊ | 50/57 [00:59<00:08,  1.20s/it, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:16,  2.31s/it]\u001b[A\n",
      "Epoch 32:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 32:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.19s/it]\u001b[A\n",
      "Epoch 32:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.18s/it]\u001b[A\n",
      "Epoch 32: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=243, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 33:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.88s/it]\u001b[A\n",
      "Epoch 33:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.45s/it]\u001b[A\n",
      "Epoch 33:  63%|██████▎   | 36/57 [00:26<00:15,  1.34it/s, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:47,  2.25s/it]\u001b[A\n",
      "Epoch 33:  67%|██████▋   | 38/57 [00:31<00:15,  1.22it/s, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:41,  2.21s/it]\u001b[A\n",
      "Epoch 33:  70%|███████   | 40/57 [00:35<00:15,  1.12it/s, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:37,  2.23s/it]\u001b[A\n",
      "Epoch 33:  74%|███████▎  | 42/57 [00:40<00:14,  1.05it/s, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:27<00:32,  2.19s/it]\u001b[A\n",
      "Epoch 33:  77%|███████▋  | 44/57 [00:44<00:13,  1.01s/it, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:32<00:27,  2.15s/it]\u001b[A\n",
      "Epoch 33:  81%|████████  | 46/57 [00:48<00:11,  1.06s/it, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:36<00:23,  2.18s/it]\u001b[A\n",
      "Epoch 33:  84%|████████▍ | 48/57 [00:53<00:09,  1.11s/it, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:41<00:20,  2.22s/it]\u001b[A\n",
      "Epoch 33:  88%|████████▊ | 50/57 [00:57<00:08,  1.15s/it, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:45<00:15,  2.24s/it]\u001b[A\n",
      "Epoch 33:  91%|█████████ | 52/57 [01:02<00:05,  1.19s/it, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:50<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 33:  95%|█████████▍| 54/57 [01:06<00:03,  1.23s/it, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:54<00:06,  2.29s/it]\u001b[A\n",
      "Epoch 33:  98%|█████████▊| 56/57 [01:11<00:01,  1.27s/it, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:58<00:02,  2.14s/it]\u001b[A\n",
      "Epoch 33: 100%|██████████| 57/57 [01:14<00:00,  1.30s/it, loss=233, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Epoch 34:  53%|█████▎    | 30/57 [00:13<00:12,  2.17it/s, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  56%|█████▌    | 32/57 [00:17<00:13,  1.82it/s, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:14,  2.96s/it]\u001b[A\n",
      "Epoch 34:  60%|█████▉    | 34/57 [00:22<00:15,  1.53it/s, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.51s/it]\u001b[A\n",
      "Epoch 34:  63%|██████▎   | 36/57 [00:26<00:15,  1.35it/s, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:48,  2.30s/it]\u001b[A\n",
      "Epoch 34:  67%|██████▋   | 38/57 [00:31<00:15,  1.22it/s, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:41,  2.20s/it]\u001b[A\n",
      "Epoch 34:  70%|███████   | 40/57 [00:35<00:15,  1.13it/s, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:47,  2.80s/it]\u001b[A\n",
      "Epoch 34:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:38,  2.59s/it]\u001b[A\n",
      "Epoch 34:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.35s/it]\u001b[A\n",
      "Epoch 34:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:23,  2.17s/it]\u001b[A\n",
      "Epoch 34:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:19,  2.21s/it]\u001b[A\n",
      "Epoch 34:  88%|████████▊ | 50/57 [00:59<00:08,  1.18s/it, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.25s/it]\u001b[A\n",
      "Epoch 34:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.28s/it]\u001b[A\n",
      "Epoch 34:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.27s/it]\u001b[A\n",
      "Epoch 34:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.20s/it]\u001b[A\n",
      "Epoch 34: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=237, v_num=92, train_loss_step=257.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Epoch 35:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  56%|█████▌    | 32/57 [00:18<00:14,  1.74it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:16,  3.06s/it]\u001b[A\n",
      "Epoch 35:  60%|█████▉    | 34/57 [00:23<00:15,  1.47it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.47s/it]\u001b[A\n",
      "Epoch 35:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.29s/it]\u001b[A\n",
      "Epoch 35:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.24s/it]\u001b[A\n",
      "Epoch 35:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.27s/it]\u001b[A\n",
      "Epoch 35:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:33,  2.24s/it]\u001b[A\n",
      "Epoch 35:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:28,  2.19s/it]\u001b[A\n",
      "Epoch 35:  81%|████████  | 46/57 [00:49<00:11,  1.07s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.20s/it]\u001b[A\n",
      "Epoch 35:  84%|████████▍ | 48/57 [00:53<00:10,  1.12s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:41<00:19,  2.17s/it]\u001b[A\n",
      "Epoch 35:  88%|████████▊ | 50/57 [00:58<00:08,  1.17s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.26s/it]\u001b[A\n",
      "Epoch 35:  91%|█████████ | 52/57 [01:03<00:06,  1.21s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:50<00:11,  2.25s/it]\u001b[A\n",
      "Epoch 35:  95%|█████████▍| 54/57 [01:07<00:03,  1.25s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.24s/it]\u001b[A\n",
      "Epoch 35:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.52s/it]\u001b[A\n",
      "Epoch 35: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Epoch 36:  53%|█████▎    | 30/57 [00:14<00:13,  2.06it/s, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  56%|█████▌    | 32/57 [00:18<00:14,  1.70it/s, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:14,  2.98s/it]\u001b[A\n",
      "Epoch 36:  60%|█████▉    | 34/57 [00:23<00:15,  1.47it/s, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.58s/it]\u001b[A\n",
      "Epoch 36:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:51,  2.43s/it]\u001b[A\n",
      "Epoch 36:  67%|██████▋   | 38/57 [00:32<00:16,  1.16it/s, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:45,  2.39s/it]\u001b[A\n",
      "Epoch 36:  70%|███████   | 40/57 [00:37<00:15,  1.08it/s, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:40,  2.41s/it]\u001b[A\n",
      "Epoch 36:  74%|███████▎  | 42/57 [00:42<00:15,  1.01s/it, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.38s/it]\u001b[A\n",
      "Epoch 36:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.24s/it]\u001b[A\n",
      "Epoch 36:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.22s/it]\u001b[A\n",
      "Epoch 36:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.24s/it]\u001b[A\n",
      "Epoch 36:  88%|████████▊ | 50/57 [00:59<00:08,  1.20s/it, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.16s/it]\u001b[A\n",
      "Epoch 36:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.24s/it]\u001b[A\n",
      "Epoch 36:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.21s/it]\u001b[A\n",
      "Epoch 36:  98%|█████████▊| 56/57 [01:13<00:01,  1.30s/it, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.18s/it]\u001b[A\n",
      "Epoch 36: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=241, v_num=92, train_loss_step=281.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 37:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  56%|█████▌    | 32/57 [00:18<00:14,  1.74it/s, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.95s/it]\u001b[A\n",
      "Epoch 37:  60%|█████▉    | 34/57 [00:22<00:15,  1.48it/s, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.45s/it]\u001b[A\n",
      "Epoch 37:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.40s/it]\u001b[A\n",
      "Epoch 37:  67%|██████▋   | 38/57 [00:32<00:16,  1.18it/s, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:44,  2.33s/it]\u001b[A\n",
      "Epoch 37:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:26<00:49,  2.93s/it]\u001b[A\n",
      "Epoch 37:  74%|███████▎  | 42/57 [00:43<00:15,  1.04s/it, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:31<00:40,  2.68s/it]\u001b[A\n",
      "Epoch 37:  77%|███████▋  | 44/57 [00:48<00:14,  1.10s/it, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:36<00:33,  2.55s/it]\u001b[A\n",
      "Epoch 37:  81%|████████  | 46/57 [00:53<00:12,  1.16s/it, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:40<00:26,  2.40s/it]\u001b[A\n",
      "Epoch 37:  84%|████████▍ | 48/57 [00:57<00:10,  1.20s/it, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:20,  2.29s/it]\u001b[A\n",
      "Epoch 37:  88%|████████▊ | 50/57 [01:02<00:08,  1.24s/it, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:15,  2.27s/it]\u001b[A\n",
      "Epoch 37:  91%|█████████ | 52/57 [01:06<00:06,  1.28s/it, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:11,  2.28s/it]\u001b[A\n",
      "Epoch 37:  95%|█████████▍| 54/57 [01:11<00:03,  1.32s/it, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:07,  2.37s/it]\u001b[A\n",
      "Epoch 37:  98%|█████████▊| 56/57 [01:15<00:01,  1.36s/it, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.20s/it]\u001b[A\n",
      "Epoch 37: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=244, v_num=92, train_loss_step=259.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Epoch 38:  53%|█████▎    | 30/57 [00:14<00:12,  2.12it/s, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  56%|█████▌    | 32/57 [00:18<00:14,  1.74it/s, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:18,  3.13s/it]\u001b[A\n",
      "Epoch 38:  60%|█████▉    | 34/57 [00:23<00:15,  1.46it/s, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.57s/it]\u001b[A\n",
      "Epoch 38:  63%|██████▎   | 36/57 [00:27<00:16,  1.29it/s, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:51,  2.46s/it]\u001b[A\n",
      "Epoch 38:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.37s/it]\u001b[A\n",
      "Epoch 38:  70%|███████   | 40/57 [00:37<00:15,  1.08it/s, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:41,  2.43s/it]\u001b[A\n",
      "Epoch 38:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.30s/it]\u001b[A\n",
      "Epoch 38:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.26s/it]\u001b[A\n",
      "Epoch 38:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.28s/it]\u001b[A\n",
      "Epoch 38:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:19,  2.19s/it]\u001b[A\n",
      "Epoch 38:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.14s/it]\u001b[A\n",
      "Epoch 38:  91%|█████████ | 52/57 [01:03<00:06,  1.23s/it, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 38:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:07,  2.34s/it]\u001b[A\n",
      "Epoch 38:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.26s/it]\u001b[A\n",
      "Epoch 38: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=243, v_num=92, train_loss_step=274.0, val_loss=206.0, train_loss_epoch=244.0]\n",
      "Epoch 39:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  56%|█████▌    | 32/57 [00:18<00:14,  1.74it/s, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:11,  2.85s/it]\u001b[A\n",
      "Epoch 39:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<01:00,  2.61s/it]\u001b[A\n",
      "Epoch 39:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.38s/it]\u001b[A\n",
      "Epoch 39:  67%|██████▋   | 38/57 [00:32<00:16,  1.19it/s, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:44,  2.33s/it]\u001b[A\n",
      "Epoch 39:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.32s/it]\u001b[A\n",
      "Epoch 39:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:36,  2.44s/it]\u001b[A\n",
      "Epoch 39:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.32s/it]\u001b[A\n",
      "Epoch 39:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:23,  2.16s/it]\u001b[A\n",
      "Epoch 39:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.22s/it]\u001b[A\n",
      "Epoch 39:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.26s/it]\u001b[A\n",
      "Epoch 39:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.32s/it]\u001b[A\n",
      "Epoch 39:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.31s/it]\u001b[A\n",
      "Epoch 39:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.19s/it]\u001b[A\n",
      "Epoch 39: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=243, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Epoch 40:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:  56%|█████▌    | 32/57 [00:18<00:14,  1.72it/s, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:17,  3.11s/it]\u001b[A\n",
      "Epoch 40:  60%|█████▉    | 34/57 [00:23<00:15,  1.47it/s, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.59s/it]\u001b[A\n",
      "Epoch 40:  63%|██████▎   | 36/57 [00:28<00:16,  1.29it/s, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.39s/it]\u001b[A\n",
      "Epoch 40:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.33s/it]\u001b[A\n",
      "Epoch 40:  70%|███████   | 40/57 [00:37<00:15,  1.08it/s, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.33s/it]\u001b[A\n",
      "Epoch 40:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.28s/it]\u001b[A\n",
      "Epoch 40:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.23s/it]\u001b[A\n",
      "Epoch 40:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.19s/it]\u001b[A\n",
      "Epoch 40:  84%|████████▍ | 48/57 [00:57<00:10,  1.19s/it, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:24,  2.67s/it]\u001b[A\n",
      "Epoch 40:  88%|████████▊ | 50/57 [01:01<00:08,  1.24s/it, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:18,  2.58s/it]\u001b[A\n",
      "Epoch 40:  91%|█████████ | 52/57 [01:06<00:06,  1.29s/it, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:12,  2.46s/it]\u001b[A\n",
      "Epoch 40:  95%|█████████▍| 54/57 [01:11<00:03,  1.32s/it, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:07,  2.43s/it]\u001b[A\n",
      "Epoch 40:  98%|█████████▊| 56/57 [01:16<00:01,  1.36s/it, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.22s/it]\u001b[A\n",
      "Epoch 40: 100%|██████████| 57/57 [01:19<00:00,  1.39s/it, loss=243, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 41:  53%|█████▎    | 30/57 [00:14<00:12,  2.13it/s, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:15,  3.00s/it]\u001b[A\n",
      "Epoch 41:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.50s/it]\u001b[A\n",
      "Epoch 41:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:51,  2.45s/it]\u001b[A\n",
      "Epoch 41:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:45,  2.38s/it]\u001b[A\n",
      "Epoch 41:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:41,  2.47s/it]\u001b[A\n",
      "Epoch 41:  74%|███████▎  | 42/57 [00:42<00:15,  1.00s/it, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:36,  2.45s/it]\u001b[A\n",
      "Epoch 41:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.28s/it]\u001b[A\n",
      "Epoch 41:  81%|████████  | 46/57 [00:50<00:12,  1.11s/it, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.29s/it]\u001b[A\n",
      "Epoch 41:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.31s/it]\u001b[A\n",
      "Epoch 41:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.29s/it]\u001b[A\n",
      "Epoch 41:  91%|█████████ | 52/57 [01:04<00:06,  1.25s/it, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:12,  2.47s/it]\u001b[A\n",
      "Epoch 41:  95%|█████████▍| 54/57 [01:10<00:03,  1.30s/it, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:07,  2.40s/it]\u001b[A\n",
      "Epoch 41:  98%|█████████▊| 56/57 [01:14<00:01,  1.33s/it, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.22s/it]\u001b[A\n",
      "Epoch 41: 100%|██████████| 57/57 [01:17<00:00,  1.36s/it, loss=241, v_num=92, train_loss_step=262.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Epoch 42:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:16,  3.05s/it]\u001b[A\n",
      "Epoch 42:  60%|█████▉    | 34/57 [00:22<00:15,  1.48it/s, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.48s/it]\u001b[A\n",
      "Epoch 42:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.30s/it]\u001b[A\n",
      "Epoch 42:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:21<00:54,  2.87s/it]\u001b[A\n",
      "Epoch 42:  70%|███████   | 40/57 [00:38<00:16,  1.05it/s, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:26<00:43,  2.58s/it]\u001b[A\n",
      "Epoch 42:  74%|███████▎  | 42/57 [00:42<00:15,  1.02s/it, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:36,  2.43s/it]\u001b[A\n",
      "Epoch 42:  77%|███████▋  | 44/57 [00:47<00:13,  1.07s/it, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:30,  2.32s/it]\u001b[A\n",
      "Epoch 42:  81%|████████  | 46/57 [00:51<00:12,  1.12s/it, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.32s/it]\u001b[A\n",
      "Epoch 42:  84%|████████▍ | 48/57 [00:56<00:10,  1.17s/it, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.23s/it]\u001b[A\n",
      "Epoch 42:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.18s/it]\u001b[A\n",
      "Epoch 42:  91%|█████████ | 52/57 [01:04<00:06,  1.25s/it, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.24s/it]\u001b[A\n",
      "Epoch 42:  95%|█████████▍| 54/57 [01:09<00:03,  1.29s/it, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:07,  2.39s/it]\u001b[A\n",
      "Epoch 42:  98%|█████████▊| 56/57 [01:14<00:01,  1.33s/it, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.16s/it]\u001b[A\n",
      "Epoch 42: 100%|██████████| 57/57 [01:17<00:00,  1.36s/it, loss=240, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 43:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.94s/it]\u001b[A\n",
      "Epoch 43:  60%|█████▉    | 34/57 [00:22<00:15,  1.48it/s, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:58,  2.56s/it]\u001b[A\n",
      "Epoch 43:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:52,  2.52s/it]\u001b[A\n",
      "Epoch 43:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.33s/it]\u001b[A\n",
      "Epoch 43:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.26s/it]\u001b[A\n",
      "Epoch 43:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:36,  2.41s/it]\u001b[A\n",
      "Epoch 43:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.28s/it]\u001b[A\n",
      "Epoch 43:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.23s/it]\u001b[A\n",
      "Epoch 43:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.25s/it]\u001b[A\n",
      "Epoch 43:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.23s/it]\u001b[A\n",
      "Epoch 43:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.33s/it]\u001b[A\n",
      "Epoch 43:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.27s/it]\u001b[A\n",
      "Epoch 43:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.18s/it]\u001b[A\n",
      "Epoch 43: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=233, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 44:  53%|█████▎    | 30/57 [00:14<00:13,  2.02it/s, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  56%|█████▌    | 32/57 [00:20<00:16,  1.53it/s, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:   7%|▋         | 2/27 [00:08<01:34,  3.79s/it]\u001b[A\n",
      "Epoch 44:  60%|█████▉    | 34/57 [00:25<00:17,  1.34it/s, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:12<01:01,  2.67s/it]\u001b[A\n",
      "Epoch 44:  63%|██████▎   | 36/57 [00:29<00:17,  1.21it/s, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:17<00:53,  2.53s/it]\u001b[A\n",
      "Epoch 44:  67%|██████▋   | 38/57 [00:34<00:17,  1.10it/s, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:21<00:45,  2.38s/it]\u001b[A\n",
      "Epoch 44:  70%|███████   | 40/57 [00:39<00:16,  1.02it/s, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:26<00:40,  2.41s/it]\u001b[A\n",
      "Epoch 44:  74%|███████▎  | 42/57 [00:44<00:15,  1.05s/it, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:31<00:35,  2.36s/it]\u001b[A\n",
      "Epoch 44:  77%|███████▋  | 44/57 [00:48<00:14,  1.10s/it, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:29,  2.25s/it]\u001b[A\n",
      "Epoch 44:  81%|████████  | 46/57 [00:52<00:12,  1.15s/it, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:23,  2.16s/it]\u001b[A\n",
      "Epoch 44:  84%|████████▍ | 48/57 [00:56<00:10,  1.19s/it, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:19,  2.16s/it]\u001b[A\n",
      "Epoch 44:  88%|████████▊ | 50/57 [01:01<00:08,  1.22s/it, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.18s/it]\u001b[A\n",
      "Epoch 44:  91%|█████████ | 52/57 [01:05<00:06,  1.27s/it, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.36s/it]\u001b[A\n",
      "Epoch 44:  95%|█████████▍| 54/57 [01:10<00:03,  1.31s/it, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:07,  2.34s/it]\u001b[A\n",
      "Epoch 44:  98%|█████████▊| 56/57 [01:15<00:01,  1.34s/it, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.20s/it]\u001b[A\n",
      "Epoch 44: 100%|██████████| 57/57 [01:18<00:00,  1.37s/it, loss=239, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Epoch 45:  53%|█████▎    | 30/57 [00:13<00:12,  2.16it/s, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45:  56%|█████▌    | 32/57 [00:17<00:13,  1.79it/s, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:17,  3.08s/it]\u001b[A\n",
      "Epoch 45:  60%|█████▉    | 34/57 [00:22<00:15,  1.52it/s, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:58,  2.55s/it]\u001b[A\n",
      "Epoch 45:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:54,  2.58s/it]\u001b[A\n",
      "Epoch 45:  67%|██████▋   | 38/57 [00:32<00:16,  1.18it/s, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:47,  2.49s/it]\u001b[A\n",
      "Epoch 45:  70%|███████   | 40/57 [00:37<00:15,  1.08it/s, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:41,  2.42s/it]\u001b[A\n",
      "Epoch 45:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:37,  2.49s/it]\u001b[A\n",
      "Epoch 45:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:31,  2.41s/it]\u001b[A\n",
      "Epoch 45:  81%|████████  | 46/57 [00:51<00:12,  1.11s/it, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.33s/it]\u001b[A\n",
      "Epoch 45:  84%|████████▍ | 48/57 [00:55<00:10,  1.17s/it, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:21,  2.41s/it]\u001b[A\n",
      "Epoch 45:  88%|████████▊ | 50/57 [01:00<00:08,  1.22s/it, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:16,  2.38s/it]\u001b[A\n",
      "Epoch 45:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.31s/it]\u001b[A\n",
      "Epoch 45:  95%|█████████▍| 54/57 [01:09<00:03,  1.30s/it, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:06,  2.20s/it]\u001b[A\n",
      "Epoch 45:  98%|█████████▊| 56/57 [01:14<00:01,  1.32s/it, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.06s/it]\u001b[A\n",
      "Epoch 45: 100%|██████████| 57/57 [01:17<00:00,  1.35s/it, loss=242, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 46:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46:  56%|█████▌    | 32/57 [00:18<00:14,  1.74it/s, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.89s/it]\u001b[A\n",
      "Epoch 46:  60%|█████▉    | 34/57 [00:22<00:15,  1.48it/s, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:58,  2.54s/it]\u001b[A\n",
      "Epoch 46:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.35s/it]\u001b[A\n",
      "Epoch 46:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:44,  2.34s/it]\u001b[A\n",
      "Epoch 46:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.25s/it]\u001b[A\n",
      "Epoch 46:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:33,  2.26s/it]\u001b[A\n",
      "Epoch 46:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.24s/it]\u001b[A\n",
      "Epoch 46:  81%|████████  | 46/57 [00:49<00:11,  1.09s/it, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.36s/it]\u001b[A\n",
      "Epoch 46:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.31s/it]\u001b[A\n",
      "Epoch 46:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.21s/it]\u001b[A\n",
      "Epoch 46:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.23s/it]\u001b[A\n",
      "Epoch 46:  95%|█████████▍| 54/57 [01:07<00:03,  1.26s/it, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.20s/it]\u001b[A\n",
      "Epoch 46:  98%|█████████▊| 56/57 [01:12<00:01,  1.30s/it, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.22s/it]\u001b[A\n",
      "Epoch 46: 100%|██████████| 57/57 [01:15<00:00,  1.33s/it, loss=239, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Epoch 47:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:11,  2.85s/it]\u001b[A\n",
      "Epoch 47:  60%|█████▉    | 34/57 [00:22<00:15,  1.50it/s, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:00,  2.62s/it]\u001b[A\n",
      "Epoch 47:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.39s/it]\u001b[A\n",
      "Epoch 47:  67%|██████▋   | 38/57 [00:32<00:16,  1.19it/s, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.30s/it]\u001b[A\n",
      "Epoch 47:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.28s/it]\u001b[A\n",
      "Epoch 47:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.30s/it]\u001b[A\n",
      "Epoch 47:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:28,  2.23s/it]\u001b[A\n",
      "Epoch 47:  81%|████████  | 46/57 [00:49<00:11,  1.09s/it, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:23,  2.16s/it]\u001b[A\n",
      "Epoch 47:  84%|████████▍ | 48/57 [00:54<00:10,  1.13s/it, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:19,  2.20s/it]\u001b[A\n",
      "Epoch 47:  88%|████████▊ | 50/57 [00:58<00:08,  1.18s/it, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.19s/it]\u001b[A\n",
      "Epoch 47:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.28s/it]\u001b[A\n",
      "Epoch 47:  95%|█████████▍| 54/57 [01:08<00:03,  1.26s/it, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.32s/it]\u001b[A\n",
      "Epoch 47:  98%|█████████▊| 56/57 [01:14<00:01,  1.33s/it, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.62s/it]\u001b[A\n",
      "Epoch 47: 100%|██████████| 57/57 [01:17<00:00,  1.36s/it, loss=239, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Epoch 48:  53%|█████▎    | 30/57 [00:13<00:12,  2.19it/s, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48:  56%|█████▌    | 32/57 [00:17<00:13,  1.80it/s, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:18,  3.13s/it]\u001b[A\n",
      "Epoch 48:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:00,  2.61s/it]\u001b[A\n",
      "Epoch 48:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:52,  2.50s/it]\u001b[A\n",
      "Epoch 48:  67%|██████▋   | 38/57 [00:32<00:16,  1.18it/s, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:45,  2.40s/it]\u001b[A\n",
      "Epoch 48:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:39,  2.32s/it]\u001b[A\n",
      "Epoch 48:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:35,  2.36s/it]\u001b[A\n",
      "Epoch 48:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:29,  2.25s/it]\u001b[A\n",
      "Epoch 48:  81%|████████  | 46/57 [00:50<00:12,  1.09s/it, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.28s/it]\u001b[A\n",
      "Epoch 48:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:19,  2.16s/it]\u001b[A\n",
      "Epoch 48:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.21s/it]\u001b[A\n",
      "Epoch 48:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.21s/it]\u001b[A\n",
      "Epoch 48:  95%|█████████▍| 54/57 [01:07<00:03,  1.26s/it, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.28s/it]\u001b[A\n",
      "Epoch 48:  98%|█████████▊| 56/57 [01:12<00:01,  1.30s/it, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.11s/it]\u001b[A\n",
      "Epoch 48: 100%|██████████| 57/57 [01:15<00:00,  1.32s/it, loss=235, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 49:  53%|█████▎    | 30/57 [00:13<00:12,  2.16it/s, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:16,  3.07s/it]\u001b[A\n",
      "Epoch 49:  60%|█████▉    | 34/57 [00:22<00:15,  1.50it/s, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:58,  2.57s/it]\u001b[A\n",
      "Epoch 49:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.31s/it]\u001b[A\n",
      "Epoch 49:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:45,  2.38s/it]\u001b[A\n",
      "Epoch 49:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.27s/it]\u001b[A\n",
      "Epoch 49:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.29s/it]\u001b[A\n",
      "Epoch 49:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.24s/it]\u001b[A\n",
      "Epoch 49:  81%|████████  | 46/57 [00:49<00:11,  1.07s/it, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.24s/it]\u001b[A\n",
      "Epoch 49:  84%|████████▍ | 48/57 [00:53<00:10,  1.12s/it, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:19,  2.18s/it]\u001b[A\n",
      "Epoch 49:  88%|████████▊ | 50/57 [00:58<00:08,  1.17s/it, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.14s/it]\u001b[A\n",
      "Epoch 49:  91%|█████████ | 52/57 [01:02<00:06,  1.21s/it, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.24s/it]\u001b[A\n",
      "Epoch 49:  95%|█████████▍| 54/57 [01:07<00:03,  1.24s/it, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:08,  2.94s/it]\u001b[A\n",
      "Epoch 49:  98%|█████████▊| 56/57 [01:14<00:01,  1.32s/it, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.45s/it]\u001b[A\n",
      "Epoch 49: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=245, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 50:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 50:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:   7%|▋         | 2/27 [00:05<01:10,  2.84s/it]\u001b[A\n",
      "Epoch 50:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:55,  2.40s/it]\u001b[A\n",
      "Epoch 50:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:49,  2.36s/it]\u001b[A\n",
      "Epoch 50:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.29s/it]\u001b[A\n",
      "Epoch 50:  70%|███████   | 40/57 [00:36<00:15,  1.11it/s, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:37,  2.21s/it]\u001b[A\n",
      "Epoch 50:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:37,  2.47s/it]\u001b[A\n",
      "Epoch 50:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:30,  2.32s/it]\u001b[A\n",
      "Epoch 50:  81%|████████  | 46/57 [00:50<00:12,  1.09s/it, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.26s/it]\u001b[A\n",
      "Epoch 50:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.32s/it]\u001b[A\n",
      "Epoch 50:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:16,  2.30s/it]\u001b[A\n",
      "Epoch 50:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.31s/it]\u001b[A\n",
      "Epoch 50:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.21s/it]\u001b[A\n",
      "Epoch 50:  98%|█████████▊| 56/57 [01:12<00:01,  1.30s/it, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.11s/it]\u001b[A\n",
      "Epoch 50: 100%|██████████| 57/57 [01:15<00:00,  1.33s/it, loss=240, v_num=92, train_loss_step=294.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Epoch 51:  53%|█████▎    | 30/57 [00:13<00:12,  2.20it/s, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 51:  56%|█████▌    | 32/57 [00:17<00:13,  1.84it/s, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:05<01:10,  2.84s/it]\u001b[A\n",
      "Epoch 51:  60%|█████▉    | 34/57 [00:21<00:14,  1.55it/s, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.47s/it]\u001b[A\n",
      "Epoch 51:  63%|██████▎   | 36/57 [00:26<00:15,  1.36it/s, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.36s/it]\u001b[A\n",
      "Epoch 51:  67%|██████▋   | 38/57 [00:30<00:15,  1.23it/s, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.23s/it]\u001b[A\n",
      "Epoch 51:  70%|███████   | 40/57 [00:35<00:14,  1.13it/s, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:38,  2.26s/it]\u001b[A\n",
      "Epoch 51:  74%|███████▎  | 42/57 [00:39<00:14,  1.05it/s, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:34,  2.29s/it]\u001b[A\n",
      "Epoch 51:  77%|███████▋  | 44/57 [00:44<00:13,  1.01s/it, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.30s/it]\u001b[A\n",
      "Epoch 51:  81%|████████  | 46/57 [00:48<00:11,  1.06s/it, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:25,  2.29s/it]\u001b[A\n",
      "Epoch 51:  84%|████████▍ | 48/57 [00:53<00:10,  1.11s/it, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:21,  2.35s/it]\u001b[A\n",
      "Epoch 51:  88%|████████▊ | 50/57 [00:58<00:08,  1.16s/it, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.26s/it]\u001b[A\n",
      "Epoch 51:  91%|█████████ | 52/57 [01:02<00:06,  1.21s/it, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.26s/it]\u001b[A\n",
      "Epoch 51:  95%|█████████▍| 54/57 [01:07<00:03,  1.25s/it, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.24s/it]\u001b[A\n",
      "Epoch 51:  98%|█████████▊| 56/57 [01:14<00:01,  1.33s/it, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.69s/it]\u001b[A\n",
      "Epoch 51: 100%|██████████| 57/57 [01:17<00:00,  1.36s/it, loss=243, v_num=92, train_loss_step=247.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 52:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 52:  56%|█████▌    | 32/57 [00:18<00:14,  1.74it/s, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:11,  2.88s/it]\u001b[A\n",
      "Epoch 52:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.49s/it]\u001b[A\n",
      "Epoch 52:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:52,  2.52s/it]\u001b[A\n",
      "Epoch 52:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.32s/it]\u001b[A\n",
      "Epoch 52:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.30s/it]\u001b[A\n",
      "Epoch 52:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.33s/it]\u001b[A\n",
      "Epoch 52:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.25s/it]\u001b[A\n",
      "Epoch 52:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.36s/it]\u001b[A\n",
      "Epoch 52:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.29s/it]\u001b[A\n",
      "Epoch 52:  88%|████████▊ | 50/57 [00:59<00:08,  1.20s/it, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.27s/it]\u001b[A\n",
      "Epoch 52:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 52:  95%|█████████▍| 54/57 [01:08<00:03,  1.28s/it, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.20s/it]\u001b[A\n",
      "Epoch 52:  98%|█████████▊| 56/57 [01:12<00:01,  1.30s/it, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.05s/it]\u001b[A\n",
      "Epoch 52: 100%|██████████| 57/57 [01:15<00:00,  1.33s/it, loss=242, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 53:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 53:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:   7%|▋         | 2/27 [00:05<01:09,  2.79s/it]\u001b[A\n",
      "Epoch 53:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:58,  2.53s/it]\u001b[A\n",
      "Epoch 53:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:47,  2.28s/it]\u001b[A\n",
      "Epoch 53:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.22s/it]\u001b[A\n",
      "Epoch 53:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:40,  2.36s/it]\u001b[A\n",
      "Epoch 53:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:35,  2.34s/it]\u001b[A\n",
      "Epoch 53:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.25s/it]\u001b[A\n",
      "Epoch 53:  81%|████████  | 46/57 [00:49<00:11,  1.08s/it, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.24s/it]\u001b[A\n",
      "Epoch 53:  84%|████████▍ | 48/57 [00:54<00:10,  1.13s/it, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.23s/it]\u001b[A\n",
      "Epoch 53:  88%|████████▊ | 50/57 [00:58<00:08,  1.17s/it, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.22s/it]\u001b[A\n",
      "Epoch 53:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.35s/it]\u001b[A\n",
      "Epoch 53:  95%|█████████▍| 54/57 [01:08<00:03,  1.26s/it, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:07,  2.37s/it]\u001b[A\n",
      "Epoch 53:  98%|█████████▊| 56/57 [01:12<00:01,  1.30s/it, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.12s/it]\u001b[A\n",
      "Epoch 53: 100%|██████████| 57/57 [01:15<00:00,  1.33s/it, loss=244, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Epoch 54:  53%|█████▎    | 30/57 [00:14<00:12,  2.11it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 54:  56%|█████▌    | 32/57 [00:18<00:14,  1.77it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:   7%|▋         | 2/27 [00:05<01:09,  2.77s/it]\u001b[A\n",
      "Epoch 54:  60%|█████▉    | 34/57 [00:22<00:15,  1.52it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.45s/it]\u001b[A\n",
      "Epoch 54:  63%|██████▎   | 36/57 [00:26<00:15,  1.34it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:49,  2.35s/it]\u001b[A\n",
      "Epoch 54:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:44,  2.36s/it]\u001b[A\n",
      "Epoch 54:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.29s/it]\u001b[A\n",
      "Epoch 54:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:33,  2.26s/it]\u001b[A\n",
      "Epoch 54:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.24s/it]\u001b[A\n",
      "Epoch 54:  81%|████████  | 46/57 [00:49<00:11,  1.08s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:25,  2.32s/it]\u001b[A\n",
      "Epoch 54:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.32s/it]\u001b[A\n",
      "Epoch 54:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:16,  2.33s/it]\u001b[A\n",
      "Epoch 54:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:12,  2.46s/it]\u001b[A\n",
      "Epoch 54:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.33s/it]\u001b[A\n",
      "Epoch 54:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.21s/it]\u001b[A\n",
      "Epoch 54: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=235, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Epoch 55:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 55:  56%|█████▌    | 32/57 [00:18<00:14,  1.69it/s, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:18,  3.15s/it]\u001b[A\n",
      "Epoch 55:  60%|█████▉    | 34/57 [00:23<00:15,  1.46it/s, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:57,  2.52s/it]\u001b[A\n",
      "Epoch 55:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.39s/it]\u001b[A\n",
      "Epoch 55:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.33s/it]\u001b[A\n",
      "Epoch 55:  70%|███████   | 40/57 [00:37<00:15,  1.08it/s, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:40,  2.37s/it]\u001b[A\n",
      "Epoch 55:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.32s/it]\u001b[A\n",
      "Epoch 55:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.34s/it]\u001b[A\n",
      "Epoch 55:  81%|████████  | 46/57 [00:51<00:12,  1.11s/it, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:26,  2.39s/it]\u001b[A\n",
      "Epoch 55:  84%|████████▍ | 48/57 [00:56<00:10,  1.17s/it, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:21,  2.40s/it]\u001b[A\n",
      "Epoch 55:  88%|████████▊ | 50/57 [01:00<00:08,  1.22s/it, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.33s/it]\u001b[A\n",
      "Epoch 55:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.32s/it]\u001b[A\n",
      "Epoch 55:  95%|█████████▍| 54/57 [01:09<00:03,  1.30s/it, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.28s/it]\u001b[A\n",
      "Epoch 55:  98%|█████████▊| 56/57 [01:14<00:01,  1.33s/it, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.11s/it]\u001b[A\n",
      "Epoch 55: 100%|██████████| 57/57 [01:17<00:00,  1.35s/it, loss=240, v_num=92, train_loss_step=285.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Epoch 56:  53%|█████▎    | 30/57 [00:14<00:12,  2.14it/s, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 56:  56%|█████▌    | 32/57 [00:18<00:14,  1.78it/s, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.89s/it]\u001b[A\n",
      "Epoch 56:  60%|█████▉    | 34/57 [00:22<00:15,  1.52it/s, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:13<01:19,  3.45s/it]\u001b[A\n",
      "Epoch 56:  63%|██████▎   | 36/57 [00:29<00:17,  1.23it/s, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:17<00:58,  2.79s/it]\u001b[A\n",
      "Epoch 56:  67%|██████▋   | 38/57 [00:34<00:17,  1.11it/s, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:22<00:48,  2.57s/it]\u001b[A\n",
      "Epoch 56:  70%|███████   | 40/57 [00:38<00:16,  1.03it/s, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:27<00:41,  2.45s/it]\u001b[A\n",
      "Epoch 56:  74%|███████▎  | 42/57 [00:43<00:15,  1.04s/it, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:31<00:35,  2.37s/it]\u001b[A\n",
      "Epoch 56:  77%|███████▋  | 44/57 [00:48<00:14,  1.09s/it, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:36<00:30,  2.34s/it]\u001b[A\n",
      "Epoch 56:  81%|████████  | 46/57 [00:52<00:12,  1.15s/it, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:40<00:24,  2.22s/it]\u001b[A\n",
      "Epoch 56:  84%|████████▍ | 48/57 [00:57<00:10,  1.19s/it, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:20,  2.25s/it]\u001b[A\n",
      "Epoch 56:  88%|████████▊ | 50/57 [01:01<00:08,  1.23s/it, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:15,  2.24s/it]\u001b[A\n",
      "Epoch 56:  91%|█████████ | 52/57 [01:06<00:06,  1.28s/it, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:11,  2.34s/it]\u001b[A\n",
      "Epoch 56:  95%|█████████▍| 54/57 [01:10<00:03,  1.31s/it, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:06,  2.26s/it]\u001b[A\n",
      "Epoch 56:  98%|█████████▊| 56/57 [01:15<00:01,  1.35s/it, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.18s/it]\u001b[A\n",
      "Epoch 56: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=235, v_num=92, train_loss_step=249.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Epoch 57:  53%|█████▎    | 30/57 [00:14<00:13,  2.07it/s, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 57:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:16,  3.05s/it]\u001b[A\n",
      "Epoch 57:  60%|█████▉    | 34/57 [00:23<00:15,  1.47it/s, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:58,  2.56s/it]\u001b[A\n",
      "Epoch 57:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.31s/it]\u001b[A\n",
      "Epoch 57:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.28s/it]\u001b[A\n",
      "Epoch 57:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:37,  2.22s/it]\u001b[A\n",
      "Epoch 57:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:34,  2.27s/it]\u001b[A\n",
      "Epoch 57:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:30,  2.32s/it]\u001b[A\n",
      "Epoch 57:  81%|████████  | 46/57 [00:50<00:11,  1.09s/it, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:25,  2.32s/it]\u001b[A\n",
      "Epoch 57:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.26s/it]\u001b[A\n",
      "Epoch 57:  88%|████████▊ | 50/57 [00:59<00:08,  1.18s/it, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.26s/it]\u001b[A\n",
      "Epoch 57:  91%|█████████ | 52/57 [01:03<00:06,  1.23s/it, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.26s/it]\u001b[A\n",
      "Epoch 57:  95%|█████████▍| 54/57 [01:08<00:03,  1.26s/it, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.20s/it]\u001b[A\n",
      "Epoch 57:  98%|█████████▊| 56/57 [01:12<00:01,  1.29s/it, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:59<00:02,  2.04s/it]\u001b[A\n",
      "Epoch 57: 100%|██████████| 57/57 [01:15<00:00,  1.32s/it, loss=225, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 58:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 58:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:   7%|▋         | 2/27 [00:05<01:09,  2.78s/it]\u001b[A\n",
      "Epoch 58:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:52,  2.30s/it]\u001b[A\n",
      "Epoch 58:  63%|██████▎   | 36/57 [00:26<00:15,  1.35it/s, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:46,  2.23s/it]\u001b[A\n",
      "Epoch 58:  67%|██████▋   | 38/57 [00:30<00:15,  1.23it/s, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:18<00:41,  2.20s/it]\u001b[A\n",
      "Epoch 58:  70%|███████   | 40/57 [00:35<00:15,  1.13it/s, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:40,  2.38s/it]\u001b[A\n",
      "Epoch 58:  74%|███████▎  | 42/57 [00:40<00:14,  1.04it/s, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:35,  2.36s/it]\u001b[A\n",
      "Epoch 58:  77%|███████▋  | 44/57 [00:47<00:14,  1.09s/it, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:37,  2.90s/it]\u001b[A\n",
      "Epoch 58:  81%|████████  | 46/57 [00:52<00:12,  1.14s/it, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:40<00:28,  2.59s/it]\u001b[A\n",
      "Epoch 58:  84%|████████▍ | 48/57 [00:56<00:10,  1.19s/it, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:21,  2.44s/it]\u001b[A\n",
      "Epoch 58:  88%|████████▊ | 50/57 [01:01<00:08,  1.23s/it, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:16,  2.31s/it]\u001b[A\n",
      "Epoch 58:  91%|█████████ | 52/57 [01:05<00:06,  1.27s/it, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:11,  2.40s/it]\u001b[A\n",
      "Epoch 58:  95%|█████████▍| 54/57 [01:10<00:03,  1.31s/it, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:07,  2.37s/it]\u001b[A\n",
      "Epoch 58:  98%|█████████▊| 56/57 [01:15<00:01,  1.35s/it, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.29s/it]\u001b[A\n",
      "Epoch 58: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=242, v_num=92, train_loss_step=230.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Epoch 59:  53%|█████▎    | 30/57 [00:14<00:12,  2.13it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 59:  56%|█████▌    | 32/57 [00:17<00:13,  1.79it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:11,  2.88s/it]\u001b[A\n",
      "Epoch 59:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.51s/it]\u001b[A\n",
      "Epoch 59:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.38s/it]\u001b[A\n",
      "Epoch 59:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.32s/it]\u001b[A\n",
      "Epoch 59:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:42,  2.50s/it]\u001b[A\n",
      "Epoch 59:  74%|███████▎  | 42/57 [00:42<00:15,  1.00s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:37,  2.48s/it]\u001b[A\n",
      "Epoch 59:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.36s/it]\u001b[A\n",
      "Epoch 59:  81%|████████  | 46/57 [00:51<00:12,  1.11s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:26,  2.45s/it]\u001b[A\n",
      "Epoch 59:  84%|████████▍ | 48/57 [00:56<00:10,  1.17s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:21,  2.39s/it]\u001b[A\n",
      "Epoch 59:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.30s/it]\u001b[A\n",
      "Epoch 59:  91%|█████████ | 52/57 [01:05<00:06,  1.25s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.35s/it]\u001b[A\n",
      "Epoch 59:  95%|█████████▍| 54/57 [01:09<00:03,  1.30s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:06,  2.29s/it]\u001b[A\n",
      "Epoch 59:  98%|█████████▊| 56/57 [01:14<00:01,  1.33s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.15s/it]\u001b[A\n",
      "Epoch 59: 100%|██████████| 57/57 [01:17<00:00,  1.36s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 60:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 60:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:17,  3.10s/it]\u001b[A\n",
      "Epoch 60:  60%|█████▉    | 34/57 [00:22<00:15,  1.48it/s, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.60s/it]\u001b[A\n",
      "Epoch 60:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.41s/it]\u001b[A\n",
      "Epoch 60:  67%|██████▋   | 38/57 [00:32<00:16,  1.18it/s, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:43,  2.30s/it]\u001b[A\n",
      "Epoch 60:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.27s/it]\u001b[A\n",
      "Epoch 60:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.34s/it]\u001b[A\n",
      "Epoch 60:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:31,  2.42s/it]\u001b[A\n",
      "Epoch 60:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.31s/it]\u001b[A\n",
      "Epoch 60:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.23s/it]\u001b[A\n",
      "Epoch 60:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.15s/it]\u001b[A\n",
      "Epoch 60:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.31s/it]\u001b[A\n",
      "Epoch 60:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.22s/it]\u001b[A\n",
      "Epoch 60:  98%|█████████▊| 56/57 [01:15<00:01,  1.35s/it, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.66s/it]\u001b[A\n",
      "Epoch 60: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=246, v_num=92, train_loss_step=295.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Epoch 61:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 61:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:15,  3.01s/it]\u001b[A\n",
      "Epoch 61:  60%|█████▉    | 34/57 [00:22<00:15,  1.50it/s, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.46s/it]\u001b[A\n",
      "Epoch 61:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:47,  2.26s/it]\u001b[A\n",
      "Epoch 61:  67%|██████▋   | 38/57 [00:31<00:15,  1.22it/s, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.24s/it]\u001b[A\n",
      "Epoch 61:  70%|███████   | 40/57 [00:35<00:15,  1.12it/s, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:37,  2.20s/it]\u001b[A\n",
      "Epoch 61:  74%|███████▎  | 42/57 [00:40<00:14,  1.04it/s, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:34,  2.33s/it]\u001b[A\n",
      "Epoch 61:  77%|███████▋  | 44/57 [00:45<00:13,  1.02s/it, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:32<00:28,  2.22s/it]\u001b[A\n",
      "Epoch 61:  81%|████████  | 46/57 [00:49<00:11,  1.07s/it, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:25,  2.30s/it]\u001b[A\n",
      "Epoch 61:  84%|████████▍ | 48/57 [00:54<00:10,  1.13s/it, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:21,  2.34s/it]\u001b[A\n",
      "Epoch 61:  88%|████████▊ | 50/57 [00:58<00:08,  1.17s/it, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:16,  2.35s/it]\u001b[A\n",
      "Epoch 61:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.34s/it]\u001b[A\n",
      "Epoch 61:  95%|█████████▍| 54/57 [01:07<00:03,  1.26s/it, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.23s/it]\u001b[A\n",
      "Epoch 61:  98%|█████████▊| 56/57 [01:12<00:01,  1.29s/it, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.25s/it]\u001b[A\n",
      "Epoch 61: 100%|██████████| 57/57 [01:15<00:00,  1.33s/it, loss=236, v_num=92, train_loss_step=261.0, val_loss=206.0, train_loss_epoch=245.0]\n",
      "Epoch 62:  53%|█████▎    | 30/57 [00:14<00:13,  2.06it/s, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 62:  56%|█████▌    | 32/57 [00:18<00:14,  1.74it/s, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:14,  2.99s/it]\u001b[A\n",
      "Epoch 62:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:55,  2.41s/it]\u001b[A\n",
      "Epoch 62:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.37s/it]\u001b[A\n",
      "Epoch 62:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.31s/it]\u001b[A\n",
      "Epoch 62:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.33s/it]\u001b[A\n",
      "Epoch 62:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.37s/it]\u001b[A\n",
      "Epoch 62:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:31,  2.43s/it]\u001b[A\n",
      "Epoch 62:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.23s/it]\u001b[A\n",
      "Epoch 62:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.24s/it]\u001b[A\n",
      "Epoch 62:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.21s/it]\u001b[A\n",
      "Epoch 62:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.22s/it]\u001b[A\n",
      "Epoch 62:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.33s/it]\u001b[A\n",
      "Epoch 62:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.19s/it]\u001b[A\n",
      "Epoch 62: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=242, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Epoch 63:  53%|█████▎    | 30/57 [00:14<00:13,  2.08it/s, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 63:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.93s/it]\u001b[A\n",
      "Epoch 63:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:55,  2.40s/it]\u001b[A\n",
      "Epoch 63:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:53,  2.55s/it]\u001b[A\n",
      "Epoch 63:  67%|██████▋   | 38/57 [00:32<00:16,  1.16it/s, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:23<01:04,  3.39s/it]\u001b[A\n",
      "Epoch 63:  70%|███████   | 40/57 [00:40<00:17,  1.01s/it, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:28<00:48,  2.85s/it]\u001b[A\n",
      "Epoch 63:  74%|███████▎  | 42/57 [00:45<00:16,  1.08s/it, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:32<00:37,  2.52s/it]\u001b[A\n",
      "Epoch 63:  77%|███████▋  | 44/57 [00:49<00:14,  1.12s/it, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:37<00:30,  2.37s/it]\u001b[A\n",
      "Epoch 63:  81%|████████  | 46/57 [00:53<00:12,  1.17s/it, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:41<00:24,  2.23s/it]\u001b[A\n",
      "Epoch 63:  84%|████████▍ | 48/57 [00:58<00:10,  1.21s/it, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:19,  2.21s/it]\u001b[A\n",
      "Epoch 63:  88%|████████▊ | 50/57 [01:02<00:08,  1.25s/it, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:50<00:15,  2.18s/it]\u001b[A\n",
      "Epoch 63:  91%|█████████ | 52/57 [01:07<00:06,  1.29s/it, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:11,  2.31s/it]\u001b[A\n",
      "Epoch 63:  95%|█████████▍| 54/57 [01:11<00:03,  1.33s/it, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:06,  2.23s/it]\u001b[A\n",
      "Epoch 63:  98%|█████████▊| 56/57 [01:16<00:01,  1.36s/it, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.09s/it]\u001b[A\n",
      "Epoch 63: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=237, v_num=92, train_loss_step=234.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Epoch 64:  53%|█████▎    | 30/57 [00:14<00:13,  2.07it/s, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 64:  56%|█████▌    | 32/57 [00:18<00:14,  1.70it/s, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:19,  3.17s/it]\u001b[A\n",
      "Epoch 64:  60%|█████▉    | 34/57 [00:23<00:15,  1.46it/s, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:00,  2.63s/it]\u001b[A\n",
      "Epoch 64:  63%|██████▎   | 36/57 [00:27<00:16,  1.29it/s, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.37s/it]\u001b[A\n",
      "Epoch 64:  67%|██████▋   | 38/57 [00:32<00:16,  1.16it/s, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:46,  2.46s/it]\u001b[A\n",
      "Epoch 64:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:38,  2.29s/it]\u001b[A\n",
      "Epoch 64:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.31s/it]\u001b[A\n",
      "Epoch 64:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.36s/it]\u001b[A\n",
      "Epoch 64:  81%|████████  | 46/57 [00:51<00:12,  1.12s/it, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.29s/it]\u001b[A\n",
      "Epoch 64:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:19,  2.19s/it]\u001b[A\n",
      "Epoch 64:  88%|████████▊ | 50/57 [00:59<00:08,  1.20s/it, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.20s/it]\u001b[A\n",
      "Epoch 64:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.32s/it]\u001b[A\n",
      "Epoch 64:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.30s/it]\u001b[A\n",
      "Epoch 64:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.13s/it]\u001b[A\n",
      "Epoch 64: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=237, v_num=92, train_loss_step=263.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 65:  53%|█████▎    | 30/57 [00:13<00:12,  2.16it/s, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 65:  56%|█████▌    | 32/57 [00:18<00:14,  1.77it/s, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:16,  3.06s/it]\u001b[A\n",
      "Epoch 65:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:00,  2.63s/it]\u001b[A\n",
      "Epoch 65:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.40s/it]\u001b[A\n",
      "Epoch 65:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.32s/it]\u001b[A\n",
      "Epoch 65:  70%|███████   | 40/57 [00:36<00:15,  1.11it/s, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.26s/it]\u001b[A\n",
      "Epoch 65:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.38s/it]\u001b[A\n",
      "Epoch 65:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.30s/it]\u001b[A\n",
      "Epoch 65:  81%|████████  | 46/57 [00:50<00:11,  1.09s/it, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.24s/it]\u001b[A\n",
      "Epoch 65:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.29s/it]\u001b[A\n",
      "Epoch 65:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.26s/it]\u001b[A\n",
      "Epoch 65:  91%|█████████ | 52/57 [01:03<00:06,  1.23s/it, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.33s/it]\u001b[A\n",
      "Epoch 65:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:07,  2.34s/it]\u001b[A\n",
      "Epoch 65:  98%|█████████▊| 56/57 [01:16<00:01,  1.36s/it, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:04<00:02,  2.84s/it]\u001b[A\n",
      "Epoch 65: 100%|██████████| 57/57 [01:19<00:00,  1.39s/it, loss=230, v_num=92, train_loss_step=235.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Epoch 66:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 66:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.90s/it]\u001b[A\n",
      "Epoch 66:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.44s/it]\u001b[A\n",
      "Epoch 66:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:47,  2.27s/it]\u001b[A\n",
      "Epoch 66:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:44,  2.34s/it]\u001b[A\n",
      "Epoch 66:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.35s/it]\u001b[A\n",
      "Epoch 66:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.35s/it]\u001b[A\n",
      "Epoch 66:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:28,  2.19s/it]\u001b[A\n",
      "Epoch 66:  81%|████████  | 46/57 [00:49<00:11,  1.08s/it, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:23,  2.15s/it]\u001b[A\n",
      "Epoch 66:  84%|████████▍ | 48/57 [00:54<00:10,  1.13s/it, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:41<00:19,  2.20s/it]\u001b[A\n",
      "Epoch 66:  88%|████████▊ | 50/57 [00:58<00:08,  1.17s/it, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.24s/it]\u001b[A\n",
      "Epoch 66:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:50<00:11,  2.21s/it]\u001b[A\n",
      "Epoch 66:  95%|█████████▍| 54/57 [01:07<00:03,  1.25s/it, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.21s/it]\u001b[A\n",
      "Epoch 66:  98%|█████████▊| 56/57 [01:11<00:01,  1.28s/it, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:59<00:02,  2.09s/it]\u001b[A\n",
      "Epoch 66: 100%|██████████| 57/57 [01:14<00:00,  1.31s/it, loss=245, v_num=92, train_loss_step=279.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Epoch 67:  53%|█████▎    | 30/57 [00:14<00:12,  2.14it/s, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 67:  56%|█████▌    | 32/57 [00:18<00:14,  1.74it/s, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:21,  3.28s/it]\u001b[A\n",
      "Epoch 67:  60%|█████▉    | 34/57 [00:23<00:15,  1.46it/s, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:58,  2.54s/it]\u001b[A\n",
      "Epoch 67:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.37s/it]\u001b[A\n",
      "Epoch 67:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:42,  2.25s/it]\u001b[A\n",
      "Epoch 67:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:37,  2.24s/it]\u001b[A\n",
      "Epoch 67:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:33,  2.23s/it]\u001b[A\n",
      "Epoch 67:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:32,  2.49s/it]\u001b[A\n",
      "Epoch 67:  81%|████████  | 46/57 [00:50<00:12,  1.09s/it, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.24s/it]\u001b[A\n",
      "Epoch 67:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.25s/it]\u001b[A\n",
      "Epoch 67:  88%|████████▊ | 50/57 [00:59<00:08,  1.18s/it, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.24s/it]\u001b[A\n",
      "Epoch 67:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.22s/it]\u001b[A\n",
      "Epoch 67:  95%|█████████▍| 54/57 [01:08<00:03,  1.26s/it, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.19s/it]\u001b[A\n",
      "Epoch 67:  98%|█████████▊| 56/57 [01:12<00:01,  1.29s/it, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.11s/it]\u001b[A\n",
      "Epoch 67: 100%|██████████| 57/57 [01:15<00:00,  1.32s/it, loss=234, v_num=92, train_loss_step=202.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Epoch 68:  53%|█████▎    | 30/57 [00:14<00:12,  2.11it/s, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 68:  56%|█████▌    | 32/57 [00:17<00:14,  1.78it/s, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.90s/it]\u001b[A\n",
      "Epoch 68:  60%|█████▉    | 34/57 [00:22<00:15,  1.52it/s, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:54,  2.37s/it]\u001b[A\n",
      "Epoch 68:  63%|██████▎   | 36/57 [00:26<00:15,  1.34it/s, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:48,  2.31s/it]\u001b[A\n",
      "Epoch 68:  67%|██████▋   | 38/57 [00:31<00:15,  1.22it/s, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.29s/it]\u001b[A\n",
      "Epoch 68:  70%|███████   | 40/57 [00:35<00:15,  1.12it/s, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:39,  2.31s/it]\u001b[A\n",
      "Epoch 68:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:35,  2.38s/it]\u001b[A\n",
      "Epoch 68:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:36<00:42,  3.26s/it]\u001b[A\n",
      "Epoch 68:  81%|████████  | 46/57 [00:52<00:12,  1.15s/it, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:40<00:29,  2.68s/it]\u001b[A\n",
      "Epoch 68:  84%|████████▍ | 48/57 [00:57<00:10,  1.19s/it, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:22,  2.45s/it]\u001b[A\n",
      "Epoch 68:  88%|████████▊ | 50/57 [01:01<00:08,  1.23s/it, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:16,  2.32s/it]\u001b[A\n",
      "Epoch 68:  91%|█████████ | 52/57 [01:06<00:06,  1.28s/it, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:11,  2.30s/it]\u001b[A\n",
      "Epoch 68:  95%|█████████▍| 54/57 [01:10<00:03,  1.31s/it, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:06,  2.23s/it]\u001b[A\n",
      "Epoch 68:  98%|█████████▊| 56/57 [01:14<00:01,  1.34s/it, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.10s/it]\u001b[A\n",
      "Epoch 68: 100%|██████████| 57/57 [01:17<00:00,  1.37s/it, loss=240, v_num=92, train_loss_step=240.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 69:  53%|█████▎    | 30/57 [00:14<00:13,  2.03it/s, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 69:  56%|█████▌    | 32/57 [00:19<00:15,  1.65it/s, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:22,  3.29s/it]\u001b[A\n",
      "Epoch 69:  60%|█████▉    | 34/57 [00:23<00:16,  1.42it/s, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:58,  2.54s/it]\u001b[A\n",
      "Epoch 69:  63%|██████▎   | 36/57 [00:28<00:16,  1.26it/s, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.40s/it]\u001b[A\n",
      "Epoch 69:  67%|██████▋   | 38/57 [00:33<00:16,  1.15it/s, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.32s/it]\u001b[A\n",
      "Epoch 69:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.24s/it]\u001b[A\n",
      "Epoch 69:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.28s/it]\u001b[A\n",
      "Epoch 69:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.33s/it]\u001b[A\n",
      "Epoch 69:  81%|████████  | 46/57 [00:51<00:12,  1.11s/it, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.31s/it]\u001b[A\n",
      "Epoch 69:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.30s/it]\u001b[A\n",
      "Epoch 69:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:16,  2.29s/it]\u001b[A\n",
      "Epoch 69:  91%|█████████ | 52/57 [01:05<00:06,  1.25s/it, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.35s/it]\u001b[A\n",
      "Epoch 69:  95%|█████████▍| 54/57 [01:09<00:03,  1.29s/it, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.27s/it]\u001b[A\n",
      "Epoch 69:  98%|█████████▊| 56/57 [01:14<00:01,  1.32s/it, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.17s/it]\u001b[A\n",
      "Epoch 69: 100%|██████████| 57/57 [01:17<00:00,  1.35s/it, loss=233, v_num=92, train_loss_step=229.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Epoch 70:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 70:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:14,  2.97s/it]\u001b[A\n",
      "Epoch 70:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:55,  2.41s/it]\u001b[A\n",
      "Epoch 70:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:51,  2.45s/it]\u001b[A\n",
      "Epoch 70:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:47,  2.48s/it]\u001b[A\n",
      "Epoch 70:  70%|███████   | 40/57 [00:37<00:15,  1.08it/s, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.34s/it]\u001b[A\n",
      "Epoch 70:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:33,  2.23s/it]\u001b[A\n",
      "Epoch 70:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.24s/it]\u001b[A\n",
      "Epoch 70:  81%|████████  | 46/57 [00:50<00:12,  1.09s/it, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.19s/it]\u001b[A\n",
      "Epoch 70:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.23s/it]\u001b[A\n",
      "Epoch 70:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.25s/it]\u001b[A\n",
      "Epoch 70:  91%|█████████ | 52/57 [01:03<00:06,  1.23s/it, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.28s/it]\u001b[A\n",
      "Epoch 70:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.30s/it]\u001b[A\n",
      "Epoch 70:  98%|█████████▊| 56/57 [01:12<00:01,  1.30s/it, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.14s/it]\u001b[A\n",
      "Epoch 70: 100%|██████████| 57/57 [01:15<00:00,  1.33s/it, loss=241, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Epoch 71:  53%|█████▎    | 30/57 [00:14<00:12,  2.12it/s, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 71:  56%|█████▌    | 32/57 [00:18<00:14,  1.77it/s, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.89s/it]\u001b[A\n",
      "Epoch 71:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:55,  2.41s/it]\u001b[A\n",
      "Epoch 71:  63%|██████▎   | 36/57 [00:26<00:15,  1.34it/s, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:18<01:11,  3.39s/it]\u001b[A\n",
      "Epoch 71:  67%|██████▋   | 38/57 [00:34<00:17,  1.10it/s, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:22<00:53,  2.79s/it]\u001b[A\n",
      "Epoch 71:  70%|███████   | 40/57 [00:39<00:16,  1.02it/s, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:27<00:43,  2.54s/it]\u001b[A\n",
      "Epoch 71:  74%|███████▎  | 42/57 [00:44<00:15,  1.05s/it, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:32<00:36,  2.45s/it]\u001b[A\n",
      "Epoch 71:  77%|███████▋  | 44/57 [00:48<00:14,  1.10s/it, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:36<00:30,  2.33s/it]\u001b[A\n",
      "Epoch 71:  81%|████████  | 46/57 [00:52<00:12,  1.15s/it, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:40<00:24,  2.21s/it]\u001b[A\n",
      "Epoch 71:  84%|████████▍ | 48/57 [00:57<00:10,  1.19s/it, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:19,  2.20s/it]\u001b[A\n",
      "Epoch 71:  88%|████████▊ | 50/57 [01:01<00:08,  1.23s/it, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:15,  2.25s/it]\u001b[A\n",
      "Epoch 71:  91%|█████████ | 52/57 [01:06<00:06,  1.27s/it, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:11,  2.31s/it]\u001b[A\n",
      "Epoch 71:  95%|█████████▍| 54/57 [01:11<00:03,  1.32s/it, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:07,  2.34s/it]\u001b[A\n",
      "Epoch 71:  98%|█████████▊| 56/57 [01:15<00:01,  1.35s/it, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.18s/it]\u001b[A\n",
      "Epoch 71: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=236, v_num=92, train_loss_step=220.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Epoch 72:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 72:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:16,  3.07s/it]\u001b[A\n",
      "Epoch 72:  60%|█████▉    | 34/57 [00:23<00:15,  1.47it/s, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.57s/it]\u001b[A\n",
      "Epoch 72:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.32s/it]\u001b[A\n",
      "Epoch 72:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.21s/it]\u001b[A\n",
      "Epoch 72:  70%|███████   | 40/57 [00:36<00:15,  1.11it/s, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.24s/it]\u001b[A\n",
      "Epoch 72:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:35,  2.34s/it]\u001b[A\n",
      "Epoch 72:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:31,  2.40s/it]\u001b[A\n",
      "Epoch 72:  81%|████████  | 46/57 [00:50<00:12,  1.09s/it, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.27s/it]\u001b[A\n",
      "Epoch 72:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.25s/it]\u001b[A\n",
      "Epoch 72:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.23s/it]\u001b[A\n",
      "Epoch 72:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 72:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.25s/it]\u001b[A\n",
      "Epoch 72:  98%|█████████▊| 56/57 [01:13<00:01,  1.30s/it, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.12s/it]\u001b[A\n",
      "Epoch 72: 100%|██████████| 57/57 [01:15<00:00,  1.33s/it, loss=235, v_num=92, train_loss_step=211.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Epoch 73:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 73:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.91s/it]\u001b[A\n",
      "Epoch 73:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:54,  2.36s/it]\u001b[A\n",
      "Epoch 73:  63%|██████▎   | 36/57 [00:26<00:15,  1.34it/s, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:46,  2.21s/it]\u001b[A\n",
      "Epoch 73:  67%|██████▋   | 38/57 [00:31<00:15,  1.22it/s, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:41,  2.21s/it]\u001b[A\n",
      "Epoch 73:  70%|███████   | 40/57 [00:35<00:15,  1.12it/s, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:38,  2.27s/it]\u001b[A\n",
      "Epoch 73:  74%|███████▎  | 42/57 [00:40<00:14,  1.04it/s, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:34,  2.28s/it]\u001b[A\n",
      "Epoch 73:  77%|███████▋  | 44/57 [00:44<00:13,  1.02s/it, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:32<00:28,  2.23s/it]\u001b[A\n",
      "Epoch 73:  81%|████████  | 46/57 [00:49<00:11,  1.07s/it, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:36<00:23,  2.16s/it]\u001b[A\n",
      "Epoch 73:  84%|████████▍ | 48/57 [00:53<00:10,  1.11s/it, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:41<00:19,  2.20s/it]\u001b[A\n",
      "Epoch 73:  88%|████████▊ | 50/57 [00:57<00:08,  1.16s/it, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:45<00:15,  2.15s/it]\u001b[A\n",
      "Epoch 73:  91%|█████████ | 52/57 [01:02<00:05,  1.19s/it, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:50<00:11,  2.24s/it]\u001b[A\n",
      "Epoch 73:  95%|█████████▍| 54/57 [01:06<00:03,  1.24s/it, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:54<00:06,  2.27s/it]\u001b[A\n",
      "Epoch 73:  98%|█████████▊| 56/57 [01:11<00:01,  1.27s/it, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:58<00:02,  2.13s/it]\u001b[A\n",
      "Epoch 73: 100%|██████████| 57/57 [01:14<00:00,  1.30s/it, loss=235, v_num=92, train_loss_step=213.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Epoch 74:  53%|█████▎    | 30/57 [00:13<00:12,  2.17it/s, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 74:  56%|█████▌    | 32/57 [00:17<00:13,  1.79it/s, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:   7%|▋         | 2/27 [00:09<02:07,  5.11s/it]\u001b[A\n",
      "Epoch 74:  60%|█████▉    | 34/57 [00:26<00:17,  1.30it/s, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:14<01:14,  3.22s/it]\u001b[A\n",
      "Epoch 74:  63%|██████▎   | 36/57 [00:30<00:17,  1.18it/s, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:18<00:54,  2.58s/it]\u001b[A\n",
      "Epoch 74:  67%|██████▋   | 38/57 [00:34<00:17,  1.10it/s, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:22<00:43,  2.31s/it]\u001b[A\n",
      "Epoch 74:  70%|███████   | 40/57 [00:39<00:16,  1.02it/s, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:27<00:39,  2.31s/it]\u001b[A\n",
      "Epoch 74:  74%|███████▎  | 42/57 [00:43<00:15,  1.04s/it, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:32<00:34,  2.32s/it]\u001b[A\n",
      "Epoch 74:  77%|███████▋  | 44/57 [00:48<00:14,  1.09s/it, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:36<00:29,  2.31s/it]\u001b[A\n",
      "Epoch 74:  81%|████████  | 46/57 [00:52<00:12,  1.15s/it, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:41<00:24,  2.26s/it]\u001b[A\n",
      "Epoch 74:  84%|████████▍ | 48/57 [00:57<00:10,  1.19s/it, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:20,  2.30s/it]\u001b[A\n",
      "Epoch 74:  88%|████████▊ | 50/57 [01:01<00:08,  1.24s/it, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:50<00:15,  2.29s/it]\u001b[A\n",
      "Epoch 74:  91%|█████████ | 52/57 [01:06<00:06,  1.28s/it, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:55<00:11,  2.37s/it]\u001b[A\n",
      "Epoch 74:  95%|█████████▍| 54/57 [01:11<00:03,  1.32s/it, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:06,  2.28s/it]\u001b[A\n",
      "Epoch 74:  98%|█████████▊| 56/57 [01:15<00:01,  1.35s/it, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.17s/it]\u001b[A\n",
      "Epoch 74: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=237, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Epoch 75:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 75:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:11,  2.87s/it]\u001b[A\n",
      "Epoch 75:  60%|█████▉    | 34/57 [00:22<00:15,  1.50it/s, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:55,  2.40s/it]\u001b[A\n",
      "Epoch 75:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:47,  2.24s/it]\u001b[A\n",
      "Epoch 75:  67%|██████▋   | 38/57 [00:31<00:15,  1.22it/s, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.28s/it]\u001b[A\n",
      "Epoch 75:  70%|███████   | 40/57 [00:35<00:15,  1.12it/s, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:37,  2.21s/it]\u001b[A\n",
      "Epoch 75:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:35,  2.34s/it]\u001b[A\n",
      "Epoch 75:  77%|███████▋  | 44/57 [00:45<00:13,  1.02s/it, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:32<00:28,  2.19s/it]\u001b[A\n",
      "Epoch 75:  81%|████████  | 46/57 [00:49<00:11,  1.07s/it, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:36<00:23,  2.15s/it]\u001b[A\n",
      "Epoch 75:  84%|████████▍ | 48/57 [00:53<00:10,  1.12s/it, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:41<00:19,  2.21s/it]\u001b[A\n",
      "Epoch 75:  88%|████████▊ | 50/57 [00:58<00:08,  1.16s/it, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:45<00:15,  2.14s/it]\u001b[A\n",
      "Epoch 75:  91%|█████████ | 52/57 [01:02<00:06,  1.21s/it, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:50<00:11,  2.28s/it]\u001b[A\n",
      "Epoch 75:  95%|█████████▍| 54/57 [01:07<00:03,  1.24s/it, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.26s/it]\u001b[A\n",
      "Epoch 75:  98%|█████████▊| 56/57 [01:11<00:01,  1.28s/it, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:59<00:02,  2.17s/it]\u001b[A\n",
      "Epoch 75: 100%|██████████| 57/57 [01:14<00:00,  1.31s/it, loss=246, v_num=92, train_loss_step=290.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Epoch 76:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 76:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.95s/it]\u001b[A\n",
      "Epoch 76:  60%|█████▉    | 34/57 [00:22<00:15,  1.50it/s, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:58,  2.54s/it]\u001b[A\n",
      "Epoch 76:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.32s/it]\u001b[A\n",
      "Epoch 76:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.23s/it]\u001b[A\n",
      "Epoch 76:  70%|███████   | 40/57 [00:35<00:15,  1.11it/s, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:37,  2.20s/it]\u001b[A\n",
      "Epoch 76:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:33,  2.25s/it]\u001b[A\n",
      "Epoch 76:  77%|███████▋  | 44/57 [00:44<00:13,  1.02s/it, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:32<00:29,  2.28s/it]\u001b[A\n",
      "Epoch 76:  81%|████████  | 46/57 [00:49<00:11,  1.07s/it, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.19s/it]\u001b[A\n",
      "Epoch 76:  84%|████████▍ | 48/57 [00:53<00:10,  1.12s/it, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:41<00:19,  2.17s/it]\u001b[A\n",
      "Epoch 76:  88%|████████▊ | 50/57 [00:58<00:08,  1.16s/it, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:45<00:15,  2.15s/it]\u001b[A\n",
      "Epoch 76:  91%|█████████ | 52/57 [01:02<00:06,  1.21s/it, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:50<00:11,  2.24s/it]\u001b[A\n",
      "Epoch 76:  95%|█████████▍| 54/57 [01:06<00:03,  1.24s/it, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:54<00:06,  2.18s/it]\u001b[A\n",
      "Epoch 76:  98%|█████████▊| 56/57 [01:11<00:01,  1.27s/it, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:58<00:02,  2.08s/it]\u001b[A\n",
      "Epoch 76: 100%|██████████| 57/57 [01:14<00:00,  1.30s/it, loss=236, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=246.0]\n",
      "Epoch 77:  53%|█████▎    | 30/57 [00:14<00:12,  2.12it/s, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 77:  56%|█████▌    | 32/57 [00:21<00:16,  1.47it/s, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:09<01:52,  4.49s/it]\u001b[A\n",
      "Epoch 77:  60%|█████▉    | 34/57 [00:26<00:18,  1.27it/s, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:14<01:10,  3.04s/it]\u001b[A\n",
      "Epoch 77:  63%|██████▎   | 36/57 [00:31<00:18,  1.16it/s, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:19<00:55,  2.65s/it]\u001b[A\n",
      "Epoch 77:  67%|██████▋   | 38/57 [00:35<00:17,  1.06it/s, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:23<00:46,  2.44s/it]\u001b[A\n",
      "Epoch 77:  70%|███████   | 40/57 [00:40<00:17,  1.00s/it, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:28<00:38,  2.29s/it]\u001b[A\n",
      "Epoch 77:  74%|███████▎  | 42/57 [00:44<00:15,  1.06s/it, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:32<00:34,  2.30s/it]\u001b[A\n",
      "Epoch 77:  77%|███████▋  | 44/57 [00:48<00:14,  1.11s/it, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:37<00:29,  2.24s/it]\u001b[A\n",
      "Epoch 77:  81%|████████  | 46/57 [00:53<00:12,  1.16s/it, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:41<00:24,  2.25s/it]\u001b[A\n",
      "Epoch 77:  84%|████████▍ | 48/57 [00:58<00:10,  1.21s/it, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:46<00:20,  2.26s/it]\u001b[A\n",
      "Epoch 77:  88%|████████▊ | 50/57 [01:02<00:08,  1.26s/it, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:50<00:15,  2.26s/it]\u001b[A\n",
      "Epoch 77:  91%|█████████ | 52/57 [01:07<00:06,  1.30s/it, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:55<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 77:  95%|█████████▍| 54/57 [01:11<00:03,  1.33s/it, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:06,  2.15s/it]\u001b[A\n",
      "Epoch 77:  98%|█████████▊| 56/57 [01:15<00:01,  1.35s/it, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.09s/it]\u001b[A\n",
      "Epoch 77: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=240, v_num=92, train_loss_step=237.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 78:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 78:  56%|█████▌    | 32/57 [00:18<00:14,  1.72it/s, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.93s/it]\u001b[A\n",
      "Epoch 78:  60%|█████▉    | 34/57 [00:23<00:15,  1.48it/s, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.51s/it]\u001b[A\n",
      "Epoch 78:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.35s/it]\u001b[A\n",
      "Epoch 78:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.24s/it]\u001b[A\n",
      "Epoch 78:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.26s/it]\u001b[A\n",
      "Epoch 78:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.32s/it]\u001b[A\n",
      "Epoch 78:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.30s/it]\u001b[A\n",
      "Epoch 78:  81%|████████  | 46/57 [00:50<00:12,  1.09s/it, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:26,  2.41s/it]\u001b[A\n",
      "Epoch 78:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:22,  2.45s/it]\u001b[A\n",
      "Epoch 78:  88%|████████▊ | 50/57 [01:00<00:08,  1.20s/it, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:16,  2.29s/it]\u001b[A\n",
      "Epoch 78:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 78:  95%|█████████▍| 54/57 [01:08<00:03,  1.28s/it, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.25s/it]\u001b[A\n",
      "Epoch 78:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.15s/it]\u001b[A\n",
      "Epoch 78: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=241, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Epoch 79:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 79:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:17,  3.12s/it]\u001b[A\n",
      "Epoch 79:  60%|█████▉    | 34/57 [00:23<00:15,  1.47it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:58,  2.56s/it]\u001b[A\n",
      "Epoch 79:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.37s/it]\u001b[A\n",
      "Epoch 79:  67%|██████▋   | 38/57 [00:32<00:16,  1.18it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.32s/it]\u001b[A\n",
      "Epoch 79:  70%|███████   | 40/57 [00:37<00:15,  1.08it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.31s/it]\u001b[A\n",
      "Epoch 79:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.32s/it]\u001b[A\n",
      "Epoch 79:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.24s/it]\u001b[A\n",
      "Epoch 79:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.25s/it]\u001b[A\n",
      "Epoch 79:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:21,  2.34s/it]\u001b[A\n",
      "Epoch 79:  88%|████████▊ | 50/57 [01:00<00:08,  1.20s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.40s/it]\u001b[A\n",
      "Epoch 79:  91%|█████████ | 52/57 [01:04<00:06,  1.25s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.33s/it]\u001b[A\n",
      "Epoch 79:  95%|█████████▍| 54/57 [01:09<00:03,  1.29s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:07,  2.35s/it]\u001b[A\n",
      "Epoch 79:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.20s/it]\u001b[A\n",
      "Epoch 79: 100%|██████████| 57/57 [01:17<00:00,  1.35s/it, loss=235, v_num=92, train_loss_step=231.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 80:  53%|█████▎    | 30/57 [00:14<00:13,  2.05it/s, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 80:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.91s/it]\u001b[A\n",
      "Epoch 80:  60%|█████▉    | 34/57 [00:27<00:18,  1.26it/s, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:14<01:23,  3.63s/it]\u001b[A\n",
      "Epoch 80:  63%|██████▎   | 36/57 [00:31<00:18,  1.13it/s, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:19<00:59,  2.81s/it]\u001b[A\n",
      "Epoch 80:  67%|██████▋   | 38/57 [00:36<00:18,  1.05it/s, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:24<00:49,  2.60s/it]\u001b[A\n",
      "Epoch 80:  70%|███████   | 40/57 [00:41<00:17,  1.03s/it, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:29<00:43,  2.56s/it]\u001b[A\n",
      "Epoch 80:  74%|███████▎  | 42/57 [00:45<00:16,  1.09s/it, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:33<00:35,  2.35s/it]\u001b[A\n",
      "Epoch 80:  77%|███████▋  | 44/57 [00:50<00:14,  1.15s/it, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:38<00:30,  2.34s/it]\u001b[A\n",
      "Epoch 80:  81%|████████  | 46/57 [00:54<00:13,  1.19s/it, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:42<00:25,  2.32s/it]\u001b[A\n",
      "Epoch 80:  84%|████████▍ | 48/57 [00:59<00:11,  1.25s/it, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:47<00:21,  2.43s/it]\u001b[A\n",
      "Epoch 80:  88%|████████▊ | 50/57 [01:04<00:09,  1.29s/it, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:52<00:16,  2.36s/it]\u001b[A\n",
      "Epoch 80:  91%|█████████ | 52/57 [01:09<00:06,  1.33s/it, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:56<00:11,  2.30s/it]\u001b[A\n",
      "Epoch 80:  95%|█████████▍| 54/57 [01:13<00:04,  1.36s/it, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [01:00<00:06,  2.18s/it]\u001b[A\n",
      "Epoch 80:  98%|█████████▊| 56/57 [01:18<00:01,  1.40s/it, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:05<00:02,  2.18s/it]\u001b[A\n",
      "Epoch 80: 100%|██████████| 57/57 [01:21<00:00,  1.42s/it, loss=239, v_num=92, train_loss_step=227.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 81:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 81:  56%|█████▌    | 32/57 [00:18<00:14,  1.71it/s, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:19,  3.17s/it]\u001b[A\n",
      "Epoch 81:  60%|█████▉    | 34/57 [00:23<00:15,  1.45it/s, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:00,  2.65s/it]\u001b[A\n",
      "Epoch 81:  63%|██████▎   | 36/57 [00:28<00:16,  1.28it/s, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:51,  2.44s/it]\u001b[A\n",
      "Epoch 81:  67%|██████▋   | 38/57 [00:32<00:16,  1.16it/s, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:43,  2.30s/it]\u001b[A\n",
      "Epoch 81:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:39,  2.35s/it]\u001b[A\n",
      "Epoch 81:  74%|███████▎  | 42/57 [00:42<00:15,  1.00s/it, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:33,  2.27s/it]\u001b[A\n",
      "Epoch 81:  77%|███████▋  | 44/57 [00:46<00:13,  1.06s/it, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.38s/it]\u001b[A\n",
      "Epoch 81:  81%|████████  | 46/57 [00:51<00:12,  1.12s/it, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:26,  2.40s/it]\u001b[A\n",
      "Epoch 81:  84%|████████▍ | 48/57 [00:56<00:10,  1.17s/it, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.28s/it]\u001b[A\n",
      "Epoch 81:  88%|████████▊ | 50/57 [01:00<00:08,  1.22s/it, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.42s/it]\u001b[A\n",
      "Epoch 81:  91%|█████████ | 52/57 [01:06<00:06,  1.27s/it, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:12,  2.51s/it]\u001b[A\n",
      "Epoch 81:  95%|█████████▍| 54/57 [01:10<00:03,  1.31s/it, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:07,  2.47s/it]\u001b[A\n",
      "Epoch 81:  98%|█████████▊| 56/57 [01:15<00:01,  1.35s/it, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.32s/it]\u001b[A\n",
      "Epoch 81: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=238, v_num=92, train_loss_step=232.0, val_loss=206.0, train_loss_epoch=240.0]\n",
      "Epoch 82:  53%|█████▎    | 30/57 [00:14<00:12,  2.14it/s, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 82:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:19,  3.19s/it]\u001b[A\n",
      "Epoch 82:  60%|█████▉    | 34/57 [00:23<00:15,  1.45it/s, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:05,  2.83s/it]\u001b[A\n",
      "Epoch 82:  63%|██████▎   | 36/57 [00:28<00:16,  1.27it/s, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:54,  2.60s/it]\u001b[A\n",
      "Epoch 82:  67%|██████▋   | 38/57 [00:33<00:16,  1.14it/s, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:21<00:46,  2.44s/it]\u001b[A\n",
      "Epoch 82:  70%|███████   | 40/57 [00:37<00:16,  1.06it/s, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:26<00:40,  2.37s/it]\u001b[A\n",
      "Epoch 82:  74%|███████▎  | 42/57 [00:42<00:15,  1.01s/it, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:31<00:36,  2.44s/it]\u001b[A\n",
      "Epoch 82:  77%|███████▋  | 44/57 [00:47<00:13,  1.07s/it, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:30,  2.32s/it]\u001b[A\n",
      "Epoch 82:  81%|████████  | 46/57 [00:51<00:12,  1.12s/it, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:40<00:25,  2.32s/it]\u001b[A\n",
      "Epoch 82:  84%|████████▍ | 48/57 [00:56<00:10,  1.17s/it, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:21,  2.37s/it]\u001b[A\n",
      "Epoch 82:  88%|████████▊ | 50/57 [01:01<00:08,  1.22s/it, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:15,  2.25s/it]\u001b[A\n",
      "Epoch 82:  91%|█████████ | 52/57 [01:05<00:06,  1.27s/it, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.28s/it]\u001b[A\n",
      "Epoch 82:  95%|█████████▍| 54/57 [01:10<00:03,  1.30s/it, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:06,  2.25s/it]\u001b[A\n",
      "Epoch 82:  98%|█████████▊| 56/57 [01:14<00:01,  1.33s/it, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.12s/it]\u001b[A\n",
      "Epoch 82: 100%|██████████| 57/57 [01:17<00:00,  1.36s/it, loss=239, v_num=92, train_loss_step=217.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Epoch 83:  53%|█████▎    | 30/57 [00:14<00:12,  2.14it/s, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 83:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:21,  3.25s/it]\u001b[A\n",
      "Epoch 83:  60%|█████▉    | 34/57 [00:23<00:15,  1.46it/s, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:00,  2.64s/it]\u001b[A\n",
      "Epoch 83:  63%|██████▎   | 36/57 [00:27<00:16,  1.29it/s, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.36s/it]\u001b[A\n",
      "Epoch 83:  67%|██████▋   | 38/57 [00:32<00:16,  1.19it/s, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:24<01:06,  3.48s/it]\u001b[A\n",
      "Epoch 83:  70%|███████   | 40/57 [00:40<00:17,  1.01s/it, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:28<00:48,  2.86s/it]\u001b[A\n",
      "Epoch 83:  74%|███████▎  | 42/57 [00:44<00:16,  1.07s/it, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:32<00:36,  2.44s/it]\u001b[A\n",
      "Epoch 83:  77%|███████▋  | 44/57 [00:48<00:14,  1.11s/it, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:37<00:30,  2.32s/it]\u001b[A\n",
      "Epoch 83:  81%|████████  | 46/57 [00:53<00:12,  1.16s/it, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:41<00:24,  2.24s/it]\u001b[A\n",
      "Epoch 83:  84%|████████▍ | 48/57 [00:57<00:10,  1.20s/it, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:19,  2.22s/it]\u001b[A\n",
      "Epoch 83:  88%|████████▊ | 50/57 [01:02<00:08,  1.25s/it, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:50<00:15,  2.18s/it]\u001b[A\n",
      "Epoch 83:  91%|█████████ | 52/57 [01:06<00:06,  1.28s/it, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:11,  2.21s/it]\u001b[A\n",
      "Epoch 83:  95%|█████████▍| 54/57 [01:11<00:03,  1.32s/it, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:06,  2.25s/it]\u001b[A\n",
      "Epoch 83:  98%|█████████▊| 56/57 [01:15<00:01,  1.35s/it, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.16s/it]\u001b[A\n",
      "Epoch 83: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=240, v_num=92, train_loss_step=270.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 84:  53%|█████▎    | 30/57 [00:14<00:12,  2.12it/s, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 84:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:15,  3.03s/it]\u001b[A\n",
      "Epoch 84:  60%|█████▉    | 34/57 [00:22<00:15,  1.48it/s, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.57s/it]\u001b[A\n",
      "Epoch 84:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.35s/it]\u001b[A\n",
      "Epoch 84:  67%|██████▋   | 38/57 [00:32<00:16,  1.18it/s, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.34s/it]\u001b[A\n",
      "Epoch 84:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.30s/it]\u001b[A\n",
      "Epoch 84:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.31s/it]\u001b[A\n",
      "Epoch 84:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:28,  2.22s/it]\u001b[A\n",
      "Epoch 84:  81%|████████  | 46/57 [00:49<00:11,  1.08s/it, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.19s/it]\u001b[A\n",
      "Epoch 84:  84%|████████▍ | 48/57 [00:54<00:10,  1.13s/it, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:19,  2.20s/it]\u001b[A\n",
      "Epoch 84:  88%|████████▊ | 50/57 [00:58<00:08,  1.17s/it, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.18s/it]\u001b[A\n",
      "Epoch 84:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.23s/it]\u001b[A\n",
      "Epoch 84:  95%|█████████▍| 54/57 [01:07<00:03,  1.26s/it, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:07,  2.40s/it]\u001b[A\n",
      "Epoch 84:  98%|█████████▊| 56/57 [01:12<00:01,  1.30s/it, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.20s/it]\u001b[A\n",
      "Epoch 84: 100%|██████████| 57/57 [01:15<00:00,  1.33s/it, loss=235, v_num=92, train_loss_step=243.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Epoch 85:  53%|█████▎    | 30/57 [00:13<00:12,  2.15it/s, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 85:  56%|█████▌    | 32/57 [00:18<00:14,  1.77it/s, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:15,  3.04s/it]\u001b[A\n",
      "Epoch 85:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.49s/it]\u001b[A\n",
      "Epoch 85:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.32s/it]\u001b[A\n",
      "Epoch 85:  67%|██████▋   | 38/57 [00:31<00:15,  1.21it/s, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.27s/it]\u001b[A\n",
      "Epoch 85:  70%|███████   | 40/57 [00:35<00:15,  1.12it/s, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.24s/it]\u001b[A\n",
      "Epoch 85:  74%|███████▎  | 42/57 [00:40<00:14,  1.04it/s, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:33,  2.24s/it]\u001b[A\n",
      "Epoch 85:  77%|███████▋  | 44/57 [00:45<00:13,  1.02s/it, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:30,  2.31s/it]\u001b[A\n",
      "Epoch 85:  81%|████████  | 46/57 [00:49<00:11,  1.08s/it, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.34s/it]\u001b[A\n",
      "Epoch 85:  84%|████████▍ | 48/57 [00:54<00:10,  1.13s/it, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.26s/it]\u001b[A\n",
      "Epoch 85:  88%|████████▊ | 50/57 [00:58<00:08,  1.17s/it, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.19s/it]\u001b[A\n",
      "Epoch 85:  91%|█████████ | 52/57 [01:03<00:06,  1.21s/it, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.36s/it]\u001b[A\n",
      "Epoch 85:  95%|█████████▍| 54/57 [01:07<00:03,  1.25s/it, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.20s/it]\u001b[A\n",
      "Epoch 85:  98%|█████████▊| 56/57 [01:11<00:01,  1.28s/it, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:59<00:02,  2.11s/it]\u001b[A\n",
      "Epoch 85: 100%|██████████| 57/57 [01:14<00:00,  1.31s/it, loss=232, v_num=92, train_loss_step=225.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Epoch 86:  53%|█████▎    | 30/57 [00:14<00:12,  2.13it/s, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 86:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.94s/it]\u001b[A\n",
      "Epoch 86:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:55,  2.43s/it]\u001b[A\n",
      "Epoch 86:  63%|██████▎   | 36/57 [00:26<00:15,  1.34it/s, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:46,  2.23s/it]\u001b[A\n",
      "Epoch 86:  67%|██████▋   | 38/57 [00:31<00:15,  1.22it/s, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.24s/it]\u001b[A\n",
      "Epoch 86:  70%|███████   | 40/57 [00:35<00:15,  1.12it/s, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:38,  2.25s/it]\u001b[A\n",
      "Epoch 86:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:35,  2.37s/it]\u001b[A\n",
      "Epoch 86:  77%|███████▋  | 44/57 [00:45<00:13,  1.02s/it, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.26s/it]\u001b[A\n",
      "Epoch 86:  81%|████████  | 46/57 [00:49<00:11,  1.07s/it, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.22s/it]\u001b[A\n",
      "Epoch 86:  84%|████████▍ | 48/57 [00:57<00:10,  1.20s/it, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:27,  3.06s/it]\u001b[A\n",
      "Epoch 86:  88%|████████▊ | 50/57 [01:02<00:08,  1.25s/it, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:50<00:18,  2.67s/it]\u001b[A\n",
      "Epoch 86:  91%|█████████ | 52/57 [01:06<00:06,  1.29s/it, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:55<00:12,  2.50s/it]\u001b[A\n",
      "Epoch 86:  95%|█████████▍| 54/57 [01:11<00:03,  1.33s/it, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:59<00:07,  2.36s/it]\u001b[A\n",
      "Epoch 86:  98%|█████████▊| 56/57 [01:15<00:01,  1.36s/it, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.22s/it]\u001b[A\n",
      "Epoch 86: 100%|██████████| 57/57 [01:19<00:00,  1.39s/it, loss=245, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=231.0]\n",
      "Epoch 87:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 87:  56%|█████▌    | 32/57 [00:18<00:14,  1.71it/s, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:17,  3.10s/it]\u001b[A\n",
      "Epoch 87:  60%|█████▉    | 34/57 [00:23<00:15,  1.48it/s, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.60s/it]\u001b[A\n",
      "Epoch 87:  63%|██████▎   | 36/57 [00:27<00:16,  1.29it/s, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:51,  2.46s/it]\u001b[A\n",
      "Epoch 87:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:45,  2.39s/it]\u001b[A\n",
      "Epoch 87:  70%|███████   | 40/57 [00:37<00:15,  1.08it/s, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.25s/it]\u001b[A\n",
      "Epoch 87:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.33s/it]\u001b[A\n",
      "Epoch 87:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:28,  2.22s/it]\u001b[A\n",
      "Epoch 87:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.23s/it]\u001b[A\n",
      "Epoch 87:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.22s/it]\u001b[A\n",
      "Epoch 87:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.18s/it]\u001b[A\n",
      "Epoch 87:  91%|█████████ | 52/57 [01:03<00:06,  1.23s/it, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.20s/it]\u001b[A\n",
      "Epoch 87:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.33s/it]\u001b[A\n",
      "Epoch 87:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.13s/it]\u001b[A\n",
      "Epoch 87: 100%|██████████| 57/57 [01:16<00:00,  1.33s/it, loss=239, v_num=92, train_loss_step=236.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Epoch 88:  53%|█████▎    | 30/57 [00:14<00:13,  2.04it/s, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 88:  56%|█████▌    | 32/57 [00:18<00:14,  1.71it/s, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:21,  3.28s/it]\u001b[A\n",
      "Epoch 88:  60%|█████▉    | 34/57 [00:23<00:16,  1.43it/s, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:01,  2.68s/it]\u001b[A\n",
      "Epoch 88:  63%|██████▎   | 36/57 [00:28<00:16,  1.27it/s, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.39s/it]\u001b[A\n",
      "Epoch 88:  67%|██████▋   | 38/57 [00:32<00:16,  1.16it/s, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:45,  2.37s/it]\u001b[A\n",
      "Epoch 88:  70%|███████   | 40/57 [00:37<00:15,  1.06it/s, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:40,  2.39s/it]\u001b[A\n",
      "Epoch 88:  74%|███████▎  | 42/57 [00:42<00:15,  1.01s/it, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:36,  2.47s/it]\u001b[A\n",
      "Epoch 88:  77%|███████▋  | 44/57 [00:47<00:13,  1.07s/it, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:31,  2.39s/it]\u001b[A\n",
      "Epoch 88:  81%|████████  | 46/57 [00:52<00:12,  1.13s/it, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.33s/it]\u001b[A\n",
      "Epoch 88:  84%|████████▍ | 48/57 [00:56<00:10,  1.18s/it, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:21,  2.36s/it]\u001b[A\n",
      "Epoch 88:  88%|████████▊ | 50/57 [01:00<00:08,  1.22s/it, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.19s/it]\u001b[A\n",
      "Epoch 88:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 88:  95%|█████████▍| 54/57 [01:10<00:03,  1.30s/it, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.31s/it]\u001b[A\n",
      "Epoch 88:  98%|█████████▊| 56/57 [01:14<00:01,  1.34s/it, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.19s/it]\u001b[A\n",
      "Epoch 88: 100%|██████████| 57/57 [01:17<00:00,  1.37s/it, loss=237, v_num=92, train_loss_step=228.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Epoch 89:  53%|█████▎    | 30/57 [00:14<00:12,  2.13it/s, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 89:  56%|█████▌    | 32/57 [00:17<00:13,  1.79it/s, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:   7%|▋         | 2/27 [00:05<01:11,  2.86s/it]\u001b[A\n",
      "Epoch 89:  60%|█████▉    | 34/57 [00:22<00:15,  1.52it/s, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.47s/it]\u001b[A\n",
      "Epoch 89:  63%|██████▎   | 36/57 [00:26<00:15,  1.34it/s, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.33s/it]\u001b[A\n",
      "Epoch 89:  67%|██████▋   | 38/57 [00:31<00:15,  1.21it/s, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.30s/it]\u001b[A\n",
      "Epoch 89:  70%|███████   | 40/57 [00:35<00:15,  1.12it/s, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.30s/it]\u001b[A\n",
      "Epoch 89:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:36,  2.44s/it]\u001b[A\n",
      "Epoch 89:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:30,  2.38s/it]\u001b[A\n",
      "Epoch 89:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:28,  2.56s/it]\u001b[A\n",
      "Epoch 89:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:21,  2.42s/it]\u001b[A\n",
      "Epoch 89:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.41s/it]\u001b[A\n",
      "Epoch 89:  91%|█████████ | 52/57 [01:05<00:06,  1.26s/it, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:12,  2.43s/it]\u001b[A\n",
      "Epoch 89:  95%|█████████▍| 54/57 [01:10<00:03,  1.30s/it, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:07,  2.43s/it]\u001b[A\n",
      "Epoch 89:  98%|█████████▊| 56/57 [01:14<00:01,  1.34s/it, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.20s/it]\u001b[A\n",
      "Epoch 89: 100%|██████████| 57/57 [01:17<00:00,  1.37s/it, loss=234, v_num=92, train_loss_step=208.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Epoch 90:  53%|█████▎    | 30/57 [00:18<00:16,  1.60it/s, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 90:  56%|█████▌    | 32/57 [00:22<00:17,  1.40it/s, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.92s/it]\u001b[A\n",
      "Epoch 90:  60%|█████▉    | 34/57 [00:27<00:18,  1.25it/s, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:55,  2.40s/it]\u001b[A\n",
      "Epoch 90:  63%|██████▎   | 36/57 [00:31<00:18,  1.14it/s, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:47,  2.27s/it]\u001b[A\n",
      "Epoch 90:  67%|██████▋   | 38/57 [00:35<00:17,  1.06it/s, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.23s/it]\u001b[A\n",
      "Epoch 90:  70%|███████   | 40/57 [00:40<00:17,  1.01s/it, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:40,  2.40s/it]\u001b[A\n",
      "Epoch 90:  74%|███████▎  | 42/57 [00:45<00:16,  1.09s/it, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.38s/it]\u001b[A\n",
      "Epoch 90:  77%|███████▋  | 44/57 [00:49<00:14,  1.14s/it, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.27s/it]\u001b[A\n",
      "Epoch 90:  81%|████████  | 46/57 [00:54<00:12,  1.18s/it, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.30s/it]\u001b[A\n",
      "Epoch 90:  84%|████████▍ | 48/57 [00:59<00:11,  1.24s/it, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.33s/it]\u001b[A\n",
      "Epoch 90:  88%|████████▊ | 50/57 [01:04<00:09,  1.29s/it, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:16,  2.42s/it]\u001b[A\n",
      "Epoch 90:  91%|█████████ | 52/57 [01:09<00:06,  1.33s/it, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:12,  2.48s/it]\u001b[A\n",
      "Epoch 90:  95%|█████████▍| 54/57 [01:14<00:04,  1.37s/it, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:07,  2.52s/it]\u001b[A\n",
      "Epoch 90:  98%|█████████▊| 56/57 [01:19<00:01,  1.41s/it, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.29s/it]\u001b[A\n",
      "Epoch 90: 100%|██████████| 57/57 [01:22<00:00,  1.44s/it, loss=246, v_num=92, train_loss_step=258.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Epoch 91:  53%|█████▎    | 30/57 [00:14<00:13,  2.02it/s, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 91:  56%|█████▌    | 32/57 [00:18<00:14,  1.69it/s, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:11,  2.87s/it]\u001b[A\n",
      "Epoch 91:  60%|█████▉    | 34/57 [00:23<00:15,  1.46it/s, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.47s/it]\u001b[A\n",
      "Epoch 91:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.35s/it]\u001b[A\n",
      "Epoch 91:  67%|██████▋   | 38/57 [00:32<00:16,  1.18it/s, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.28s/it]\u001b[A\n",
      "Epoch 91:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.28s/it]\u001b[A\n",
      "Epoch 91:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:33,  2.26s/it]\u001b[A\n",
      "Epoch 91:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:32<00:28,  2.19s/it]\u001b[A\n",
      "Epoch 91:  81%|████████  | 46/57 [00:50<00:12,  1.09s/it, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.23s/it]\u001b[A\n",
      "Epoch 91:  84%|████████▍ | 48/57 [00:54<00:10,  1.13s/it, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:41<00:20,  2.25s/it]\u001b[A\n",
      "Epoch 91:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.24s/it]\u001b[A\n",
      "Epoch 91:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:50<00:11,  2.21s/it]\u001b[A\n",
      "Epoch 91:  95%|█████████▍| 54/57 [01:08<00:03,  1.26s/it, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.23s/it]\u001b[A\n",
      "Epoch 91:  98%|█████████▊| 56/57 [01:12<00:01,  1.29s/it, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:59<00:02,  2.13s/it]\u001b[A\n",
      "Epoch 91: 100%|██████████| 57/57 [01:15<00:00,  1.32s/it, loss=234, v_num=92, train_loss_step=277.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Epoch 92:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 92:  56%|█████▌    | 32/57 [00:18<00:14,  1.70it/s, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:22,  3.29s/it]\u001b[A\n",
      "Epoch 92:  60%|█████▉    | 34/57 [00:23<00:15,  1.44it/s, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.60s/it]\u001b[A\n",
      "Epoch 92:  63%|██████▎   | 36/57 [00:28<00:16,  1.27it/s, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:50,  2.42s/it]\u001b[A\n",
      "Epoch 92:  67%|██████▋   | 38/57 [00:32<00:16,  1.16it/s, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.34s/it]\u001b[A\n",
      "Epoch 92:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:39,  2.31s/it]\u001b[A\n",
      "Epoch 92:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:33,  2.23s/it]\u001b[A\n",
      "Epoch 92:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.34s/it]\u001b[A\n",
      "Epoch 92:  81%|████████  | 46/57 [00:50<00:12,  1.11s/it, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.29s/it]\u001b[A\n",
      "Epoch 92:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.28s/it]\u001b[A\n",
      "Epoch 92:  88%|████████▊ | 50/57 [01:00<00:08,  1.20s/it, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:16,  2.34s/it]\u001b[A\n",
      "Epoch 92:  91%|█████████ | 52/57 [01:04<00:06,  1.25s/it, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.36s/it]\u001b[A\n",
      "Epoch 92:  95%|█████████▍| 54/57 [01:09<00:03,  1.29s/it, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:06,  2.21s/it]\u001b[A\n",
      "Epoch 92:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.11s/it]\u001b[A\n",
      "Epoch 92: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=241, v_num=92, train_loss_step=223.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Epoch 93:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 93:  56%|█████▌    | 32/57 [00:18<00:14,  1.77it/s, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:   7%|▋         | 2/27 [00:05<01:11,  2.85s/it]\u001b[A\n",
      "Epoch 93:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.51s/it]\u001b[A\n",
      "Epoch 93:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:48,  2.32s/it]\u001b[A\n",
      "Epoch 93:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.31s/it]\u001b[A\n",
      "Epoch 93:  70%|███████   | 40/57 [00:36<00:15,  1.11it/s, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.28s/it]\u001b[A\n",
      "Epoch 93:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:36,  2.45s/it]\u001b[A\n",
      "Epoch 93:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.30s/it]\u001b[A\n",
      "Epoch 93:  81%|████████  | 46/57 [00:54<00:13,  1.19s/it, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:42<00:35,  3.19s/it]\u001b[A\n",
      "Epoch 93:  84%|████████▍ | 48/57 [00:58<00:11,  1.23s/it, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:46<00:23,  2.65s/it]\u001b[A\n",
      "Epoch 93:  88%|████████▊ | 50/57 [01:03<00:08,  1.26s/it, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:51<00:17,  2.45s/it]\u001b[A\n",
      "Epoch 93:  91%|█████████ | 52/57 [01:07<00:06,  1.31s/it, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:56<00:12,  2.44s/it]\u001b[A\n",
      "Epoch 93:  95%|█████████▍| 54/57 [01:12<00:04,  1.35s/it, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  89%|████████▉ | 24/27 [01:00<00:07,  2.39s/it]\u001b[A\n",
      "Epoch 93:  98%|█████████▊| 56/57 [01:17<00:01,  1.39s/it, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:05<00:02,  2.37s/it]\u001b[A\n",
      "Epoch 93: 100%|██████████| 57/57 [01:21<00:00,  1.42s/it, loss=234, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Epoch 94:  53%|█████▎    | 30/57 [00:13<00:12,  2.16it/s, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 94:  56%|█████▌    | 32/57 [00:17<00:13,  1.80it/s, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:   7%|▋         | 2/27 [00:05<01:10,  2.80s/it]\u001b[A\n",
      "Epoch 94:  60%|█████▉    | 34/57 [00:22<00:15,  1.52it/s, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:01,  2.67s/it]\u001b[A\n",
      "Epoch 94:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:51,  2.45s/it]\u001b[A\n",
      "Epoch 94:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:44,  2.35s/it]\u001b[A\n",
      "Epoch 94:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:41,  2.42s/it]\u001b[A\n",
      "Epoch 94:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:37,  2.47s/it]\u001b[A\n",
      "Epoch 94:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.35s/it]\u001b[A\n",
      "Epoch 94:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.26s/it]\u001b[A\n",
      "Epoch 94:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.28s/it]\u001b[A\n",
      "Epoch 94:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:48<00:15,  2.27s/it]\u001b[A\n",
      "Epoch 94:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.24s/it]\u001b[A\n",
      "Epoch 94:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.24s/it]\u001b[A\n",
      "Epoch 94:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.25s/it]\u001b[A\n",
      "Epoch 94: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=239, v_num=92, train_loss_step=252.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Epoch 95:  53%|█████▎    | 30/57 [00:14<00:12,  2.11it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 95:  56%|█████▌    | 32/57 [00:18<00:14,  1.72it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:21,  3.25s/it]\u001b[A\n",
      "Epoch 95:  60%|█████▉    | 34/57 [00:23<00:15,  1.45it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:00,  2.62s/it]\u001b[A\n",
      "Epoch 95:  63%|██████▎   | 36/57 [00:27<00:16,  1.29it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.37s/it]\u001b[A\n",
      "Epoch 95:  67%|██████▋   | 38/57 [00:32<00:16,  1.18it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:43,  2.30s/it]\u001b[A\n",
      "Epoch 95:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.24s/it]\u001b[A\n",
      "Epoch 95:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.35s/it]\u001b[A\n",
      "Epoch 95:  77%|███████▋  | 44/57 [00:45<00:13,  1.05s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.26s/it]\u001b[A\n",
      "Epoch 95:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.30s/it]\u001b[A\n",
      "Epoch 95:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.27s/it]\u001b[A\n",
      "Epoch 95:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.19s/it]\u001b[A\n",
      "Epoch 95:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.27s/it]\u001b[A\n",
      "Epoch 95:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:07,  2.42s/it]\u001b[A\n",
      "Epoch 95:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.25s/it]\u001b[A\n",
      "Epoch 95: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=240, v_num=92, train_loss_step=253.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 96:  53%|█████▎    | 30/57 [00:14<00:12,  2.12it/s, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 96:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:15,  3.04s/it]\u001b[A\n",
      "Epoch 96:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:58,  2.53s/it]\u001b[A\n",
      "Epoch 96:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.36s/it]\u001b[A\n",
      "Epoch 96:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.26s/it]\u001b[A\n",
      "Epoch 96:  70%|███████   | 40/57 [00:36<00:15,  1.11it/s, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.33s/it]\u001b[A\n",
      "Epoch 96:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.33s/it]\u001b[A\n",
      "Epoch 96:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:30,  2.33s/it]\u001b[A\n",
      "Epoch 96:  81%|████████  | 46/57 [00:50<00:11,  1.09s/it, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.35s/it]\u001b[A\n",
      "Epoch 96:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.26s/it]\u001b[A\n",
      "Epoch 96:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:16,  2.31s/it]\u001b[A\n",
      "Epoch 96:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.39s/it]\u001b[A\n",
      "Epoch 96:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:07,  2.41s/it]\u001b[A\n",
      "Epoch 96:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.24s/it]\u001b[A\n",
      "Epoch 96: 100%|██████████| 57/57 [01:16<00:00,  1.35s/it, loss=237, v_num=92, train_loss_step=241.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 97:  53%|█████▎    | 30/57 [00:14<00:13,  2.07it/s, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 97:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:16,  3.08s/it]\u001b[A\n",
      "Epoch 97:  60%|█████▉    | 34/57 [00:23<00:15,  1.48it/s, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.47s/it]\u001b[A\n",
      "Epoch 97:  63%|██████▎   | 36/57 [00:32<00:18,  1.12it/s, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:19<01:12,  3.44s/it]\u001b[A\n",
      "Epoch 97:  67%|██████▋   | 38/57 [00:36<00:18,  1.04it/s, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:24<00:53,  2.79s/it]\u001b[A\n",
      "Epoch 97:  70%|███████   | 40/57 [00:41<00:17,  1.05s/it, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:29<00:45,  2.68s/it]\u001b[A\n",
      "Epoch 97:  74%|███████▎  | 42/57 [00:46<00:16,  1.12s/it, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:34<00:38,  2.58s/it]\u001b[A\n",
      "Epoch 97:  77%|███████▋  | 44/57 [00:51<00:15,  1.17s/it, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:39<00:32,  2.52s/it]\u001b[A\n",
      "Epoch 97:  81%|████████  | 46/57 [00:56<00:13,  1.23s/it, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:43<00:25,  2.36s/it]\u001b[A\n",
      "Epoch 97:  84%|████████▍ | 48/57 [01:00<00:11,  1.26s/it, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:48<00:20,  2.24s/it]\u001b[A\n",
      "Epoch 97:  88%|████████▊ | 50/57 [01:05<00:09,  1.30s/it, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:52<00:15,  2.20s/it]\u001b[A\n",
      "Epoch 97:  91%|█████████ | 52/57 [01:09<00:06,  1.34s/it, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:57<00:11,  2.36s/it]\u001b[A\n",
      "Epoch 97:  95%|█████████▍| 54/57 [01:14<00:04,  1.38s/it, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  89%|████████▉ | 24/27 [01:02<00:06,  2.26s/it]\u001b[A\n",
      "Epoch 97:  98%|█████████▊| 56/57 [01:18<00:01,  1.41s/it, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:06<00:02,  2.17s/it]\u001b[A\n",
      "Epoch 97: 100%|██████████| 57/57 [01:21<00:00,  1.44s/it, loss=232, v_num=92, train_loss_step=265.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Epoch 98:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 98:  56%|█████▌    | 32/57 [00:18<00:14,  1.71it/s, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:21,  3.24s/it]\u001b[A\n",
      "Epoch 98:  60%|█████▉    | 34/57 [00:23<00:15,  1.45it/s, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:57,  2.52s/it]\u001b[A\n",
      "Epoch 98:  63%|██████▎   | 36/57 [00:27<00:16,  1.29it/s, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.36s/it]\u001b[A\n",
      "Epoch 98:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:43,  2.27s/it]\u001b[A\n",
      "Epoch 98:  70%|███████   | 40/57 [00:36<00:15,  1.09it/s, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.28s/it]\u001b[A\n",
      "Epoch 98:  74%|███████▎  | 42/57 [00:41<00:14,  1.01it/s, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.31s/it]\u001b[A\n",
      "Epoch 98:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:28,  2.21s/it]\u001b[A\n",
      "Epoch 98:  81%|████████  | 46/57 [00:50<00:11,  1.09s/it, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.28s/it]\u001b[A\n",
      "Epoch 98:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.25s/it]\u001b[A\n",
      "Epoch 98:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.24s/it]\u001b[A\n",
      "Epoch 98:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.28s/it]\u001b[A\n",
      "Epoch 98:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:07,  2.47s/it]\u001b[A\n",
      "Epoch 98:  98%|█████████▊| 56/57 [01:13<00:01,  1.32s/it, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.21s/it]\u001b[A\n",
      "Epoch 98: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=245, v_num=92, train_loss_step=221.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Epoch 99:  53%|█████▎    | 30/57 [00:14<00:13,  2.01it/s, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 99:  56%|█████▌    | 32/57 [00:18<00:14,  1.69it/s, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:18,  3.14s/it]\u001b[A\n",
      "Epoch 99:  60%|█████▉    | 34/57 [00:23<00:15,  1.44it/s, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.51s/it]\u001b[A\n",
      "Epoch 99:  63%|██████▎   | 36/57 [00:28<00:16,  1.28it/s, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.32s/it]\u001b[A\n",
      "Epoch 99:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.28s/it]\u001b[A\n",
      "Epoch 99:  70%|███████   | 40/57 [00:36<00:15,  1.08it/s, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.26s/it]\u001b[A\n",
      "Epoch 99:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:34,  2.33s/it]\u001b[A\n",
      "Epoch 99:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.30s/it]\u001b[A\n",
      "Epoch 99:  81%|████████  | 46/57 [00:50<00:12,  1.11s/it, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:24,  2.24s/it]\u001b[A\n",
      "Epoch 99:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.32s/it]\u001b[A\n",
      "Epoch 99:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.27s/it]\u001b[A\n",
      "Epoch 99:  91%|█████████ | 52/57 [01:05<00:06,  1.25s/it, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:12,  2.47s/it]\u001b[A\n",
      "Epoch 99:  95%|█████████▍| 54/57 [01:10<00:03,  1.30s/it, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:57<00:07,  2.47s/it]\u001b[A\n",
      "Epoch 99:  98%|█████████▊| 56/57 [01:15<00:01,  1.34s/it, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:01<00:02,  2.29s/it]\u001b[A\n",
      "Epoch 99: 100%|██████████| 57/57 [01:18<00:00,  1.37s/it, loss=235, v_num=92, train_loss_step=205.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Epoch 100:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 100:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:14,  2.96s/it]\u001b[A\n",
      "Epoch 100:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.49s/it]\u001b[A\n",
      "Epoch 100:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:46,  2.22s/it]\u001b[A\n",
      "Epoch 100:  67%|██████▋   | 38/57 [00:31<00:15,  1.21it/s, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:41,  2.17s/it]\u001b[A\n",
      "Epoch 100:  70%|███████   | 40/57 [00:35<00:15,  1.12it/s, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:37,  2.21s/it]\u001b[A\n",
      "Epoch 100:  74%|███████▎  | 42/57 [00:40<00:14,  1.04it/s, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:34,  2.27s/it]\u001b[A\n",
      "Epoch 100:  77%|███████▋  | 44/57 [00:44<00:13,  1.01s/it, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:32<00:30,  2.31s/it]\u001b[A\n",
      "Epoch 100:  81%|████████  | 46/57 [00:49<00:11,  1.07s/it, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.26s/it]\u001b[A\n",
      "Epoch 100:  84%|████████▍ | 48/57 [00:53<00:10,  1.12s/it, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:41<00:20,  2.26s/it]\u001b[A\n",
      "Epoch 100:  88%|████████▊ | 50/57 [00:58<00:08,  1.17s/it, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.23s/it]\u001b[A\n",
      "Epoch 100:  91%|█████████ | 52/57 [01:02<00:06,  1.21s/it, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:50<00:11,  2.28s/it]\u001b[A\n",
      "Epoch 100:  95%|█████████▍| 54/57 [01:07<00:03,  1.25s/it, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.24s/it]\u001b[A\n",
      "Epoch 100:  98%|█████████▊| 56/57 [01:12<00:01,  1.29s/it, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:59<00:02,  2.17s/it]\u001b[A\n",
      "Epoch 100: 100%|██████████| 57/57 [01:15<00:00,  1.32s/it, loss=242, v_num=92, train_loss_step=251.0, val_loss=206.0, train_loss_epoch=235.0]\n",
      "Epoch 101:  53%|█████▎    | 30/57 [00:14<00:12,  2.08it/s, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 101:  56%|█████▌    | 32/57 [00:22<00:17,  1.39it/s, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:   7%|▋         | 2/27 [00:10<02:02,  4.88s/it]\u001b[A\n",
      "Epoch 101:  60%|█████▉    | 34/57 [00:27<00:18,  1.23it/s, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:15<01:12,  3.15s/it]\u001b[A\n",
      "Epoch 101:  63%|██████▎   | 36/57 [00:32<00:18,  1.12it/s, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:19<00:55,  2.63s/it]\u001b[A\n",
      "Epoch 101:  67%|██████▋   | 38/57 [00:36<00:18,  1.04it/s, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:24<00:45,  2.39s/it]\u001b[A\n",
      "Epoch 101:  70%|███████   | 40/57 [00:40<00:17,  1.02s/it, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:28<00:39,  2.34s/it]\u001b[A\n",
      "Epoch 101:  74%|███████▎  | 42/57 [00:45<00:16,  1.09s/it, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:33<00:36,  2.41s/it]\u001b[A\n",
      "Epoch 101:  77%|███████▋  | 44/57 [00:50<00:14,  1.15s/it, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:38<00:30,  2.34s/it]\u001b[A\n",
      "Epoch 101:  81%|████████  | 46/57 [00:55<00:13,  1.21s/it, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:43<00:25,  2.33s/it]\u001b[A\n",
      "Epoch 101:  84%|████████▍ | 48/57 [00:59<00:11,  1.25s/it, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:47<00:19,  2.21s/it]\u001b[A\n",
      "Epoch 101:  88%|████████▊ | 50/57 [01:03<00:08,  1.28s/it, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:51<00:14,  2.13s/it]\u001b[A\n",
      "Epoch 101:  91%|█████████ | 52/57 [01:08<00:06,  1.32s/it, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:56<00:11,  2.27s/it]\u001b[A\n",
      "Epoch 101:  95%|█████████▍| 54/57 [01:13<00:04,  1.35s/it, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  89%|████████▉ | 24/27 [01:00<00:06,  2.27s/it]\u001b[A\n",
      "Epoch 101:  98%|█████████▊| 56/57 [01:17<00:01,  1.38s/it, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:04<00:02,  2.10s/it]\u001b[A\n",
      "Epoch 101: 100%|██████████| 57/57 [01:20<00:00,  1.41s/it, loss=244, v_num=92, train_loss_step=246.0, val_loss=206.0, train_loss_epoch=242.0]\n",
      "Epoch 102:  53%|█████▎    | 30/57 [00:14<00:12,  2.13it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 102:  56%|█████▌    | 32/57 [00:17<00:13,  1.79it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:15,  3.01s/it]\u001b[A\n",
      "Epoch 102:  60%|█████▉    | 34/57 [00:22<00:15,  1.50it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.46s/it]\u001b[A\n",
      "Epoch 102:  63%|██████▎   | 36/57 [00:26<00:15,  1.34it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:47,  2.28s/it]\u001b[A\n",
      "Epoch 102:  67%|██████▋   | 38/57 [00:31<00:15,  1.21it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.27s/it]\u001b[A\n",
      "Epoch 102:  70%|███████   | 40/57 [00:35<00:15,  1.11it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.29s/it]\u001b[A\n",
      "Epoch 102:  74%|███████▎  | 42/57 [00:40<00:14,  1.03it/s, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:33,  2.25s/it]\u001b[A\n",
      "Epoch 102:  77%|███████▋  | 44/57 [00:44<00:13,  1.02s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:32<00:28,  2.18s/it]\u001b[A\n",
      "Epoch 102:  81%|████████  | 46/57 [00:49<00:11,  1.07s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.20s/it]\u001b[A\n",
      "Epoch 102:  84%|████████▍ | 48/57 [00:53<00:10,  1.12s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:41<00:20,  2.26s/it]\u001b[A\n",
      "Epoch 102:  88%|████████▊ | 50/57 [00:58<00:08,  1.17s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.23s/it]\u001b[A\n",
      "Epoch 102:  91%|█████████ | 52/57 [01:02<00:06,  1.21s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 102:  95%|█████████▍| 54/57 [01:07<00:03,  1.25s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.22s/it]\u001b[A\n",
      "Epoch 102:  98%|█████████▊| 56/57 [01:11<00:01,  1.28s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:59<00:02,  2.07s/it]\u001b[A\n",
      "Epoch 102: 100%|██████████| 57/57 [01:14<00:00,  1.31s/it, loss=237, v_num=92, train_loss_step=248.0, val_loss=206.0, train_loss_epoch=241.0]\n",
      "Epoch 103:  53%|█████▎    | 30/57 [00:14<00:12,  2.13it/s, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 103:  56%|█████▌    | 32/57 [00:17<00:14,  1.78it/s, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:11,  2.84s/it]\u001b[A\n",
      "Epoch 103:  60%|█████▉    | 34/57 [00:22<00:15,  1.52it/s, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:54,  2.37s/it]\u001b[A\n",
      "Epoch 103:  63%|██████▎   | 36/57 [00:26<00:15,  1.36it/s, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:14<00:46,  2.23s/it]\u001b[A\n",
      "Epoch 103:  67%|██████▋   | 38/57 [00:30<00:15,  1.23it/s, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.26s/it]\u001b[A\n",
      "Epoch 103:  70%|███████   | 40/57 [00:35<00:15,  1.13it/s, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:23<00:37,  2.19s/it]\u001b[A\n",
      "Epoch 103:  74%|███████▎  | 42/57 [00:39<00:14,  1.05it/s, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:27<00:33,  2.20s/it]\u001b[A\n",
      "Epoch 103:  77%|███████▋  | 44/57 [00:44<00:13,  1.00s/it, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:32<00:28,  2.23s/it]\u001b[A\n",
      "Epoch 103:  81%|████████  | 46/57 [00:48<00:11,  1.05s/it, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:36<00:23,  2.17s/it]\u001b[A\n",
      "Epoch 103:  84%|████████▍ | 48/57 [00:52<00:09,  1.10s/it, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:40<00:19,  2.18s/it]\u001b[A\n",
      "Epoch 103:  88%|████████▊ | 50/57 [00:57<00:08,  1.15s/it, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:45<00:15,  2.20s/it]\u001b[A\n",
      "Epoch 103:  91%|█████████ | 52/57 [01:01<00:05,  1.19s/it, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:49<00:11,  2.20s/it]\u001b[A\n",
      "Epoch 103:  95%|█████████▍| 54/57 [01:05<00:03,  1.22s/it, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:54<00:06,  2.20s/it]\u001b[A\n",
      "Epoch 103:  98%|█████████▊| 56/57 [01:10<00:01,  1.26s/it, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:58<00:02,  2.08s/it]\u001b[A\n",
      "Epoch 103: 100%|██████████| 57/57 [01:13<00:00,  1.29s/it, loss=240, v_num=92, train_loss_step=260.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 104:  53%|█████▎    | 30/57 [00:13<00:12,  2.16it/s, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 104:  56%|█████▌    | 32/57 [00:17<00:13,  1.80it/s, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.95s/it]\u001b[A\n",
      "Epoch 104:  60%|█████▉    | 34/57 [00:22<00:15,  1.53it/s, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:58,  2.55s/it]\u001b[A\n",
      "Epoch 104:  63%|██████▎   | 36/57 [00:26<00:15,  1.34it/s, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.34s/it]\u001b[A\n",
      "Epoch 104:  67%|██████▋   | 38/57 [00:31<00:15,  1.21it/s, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.30s/it]\u001b[A\n",
      "Epoch 104:  70%|███████   | 40/57 [00:35<00:15,  1.12it/s, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:37,  2.22s/it]\u001b[A\n",
      "Epoch 104:  74%|███████▎  | 42/57 [00:40<00:14,  1.04it/s, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:34,  2.28s/it]\u001b[A\n",
      "Epoch 104:  77%|███████▋  | 44/57 [00:44<00:13,  1.02s/it, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:30,  2.32s/it]\u001b[A\n",
      "Epoch 104:  81%|████████  | 46/57 [00:49<00:11,  1.08s/it, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:24,  2.24s/it]\u001b[A\n",
      "Epoch 104:  84%|████████▍ | 48/57 [00:53<00:10,  1.12s/it, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.23s/it]\u001b[A\n",
      "Epoch 104:  88%|████████▊ | 50/57 [00:58<00:08,  1.17s/it, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.16s/it]\u001b[A\n",
      "Epoch 104:  91%|█████████ | 52/57 [01:02<00:06,  1.21s/it, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.29s/it]\u001b[A\n",
      "Epoch 104:  95%|█████████▍| 54/57 [01:07<00:03,  1.25s/it, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.17s/it]\u001b[A\n",
      "Epoch 104:  98%|█████████▊| 56/57 [01:11<00:01,  1.28s/it, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:59<00:02,  2.06s/it]\u001b[A\n",
      "Epoch 104: 100%|██████████| 57/57 [01:14<00:00,  1.31s/it, loss=242, v_num=92, train_loss_step=238.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Epoch 105:  53%|█████▎    | 30/57 [00:14<00:13,  2.04it/s, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 105:  56%|█████▌    | 32/57 [00:18<00:14,  1.70it/s, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:17,  3.11s/it]\u001b[A\n",
      "Epoch 105:  60%|█████▉    | 34/57 [00:23<00:15,  1.44it/s, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.58s/it]\u001b[A\n",
      "Epoch 105:  63%|██████▎   | 36/57 [00:28<00:16,  1.25it/s, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:16<00:54,  2.61s/it]\u001b[A\n",
      "Epoch 105:  67%|██████▋   | 38/57 [00:33<00:16,  1.13it/s, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:45,  2.39s/it]\u001b[A\n",
      "Epoch 105:  70%|███████   | 40/57 [00:37<00:16,  1.06it/s, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:40,  2.38s/it]\u001b[A\n",
      "Epoch 105:  74%|███████▎  | 42/57 [00:43<00:15,  1.03s/it, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:30<00:36,  2.45s/it]\u001b[A\n",
      "Epoch 105:  77%|███████▋  | 44/57 [00:47<00:14,  1.08s/it, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:35<00:30,  2.38s/it]\u001b[A\n",
      "Epoch 105:  81%|████████  | 46/57 [00:52<00:12,  1.14s/it, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:39<00:25,  2.30s/it]\u001b[A\n",
      "Epoch 105:  84%|████████▍ | 48/57 [00:56<00:10,  1.19s/it, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:44<00:20,  2.31s/it]\u001b[A\n",
      "Epoch 105:  88%|████████▊ | 50/57 [01:01<00:08,  1.23s/it, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:16,  2.31s/it]\u001b[A\n",
      "Epoch 105:  91%|█████████ | 52/57 [01:06<00:06,  1.27s/it, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:53<00:11,  2.34s/it]\u001b[A\n",
      "Epoch 105:  95%|█████████▍| 54/57 [01:10<00:03,  1.31s/it, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:06,  2.25s/it]\u001b[A\n",
      "Epoch 105:  98%|█████████▊| 56/57 [01:15<00:01,  1.34s/it, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:02<00:02,  2.15s/it]\u001b[A\n",
      "Epoch 105: 100%|██████████| 57/57 [01:18<00:00,  1.37s/it, loss=237, v_num=92, train_loss_step=224.0, val_loss=206.0, train_loss_epoch=243.0]\n",
      "Epoch 106:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 106:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:19,  3.19s/it]\u001b[A\n",
      "Epoch 106:  60%|█████▉    | 34/57 [00:22<00:15,  1.48it/s, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.44s/it]\u001b[A\n",
      "Epoch 106:  63%|██████▎   | 36/57 [00:27<00:15,  1.31it/s, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.37s/it]\u001b[A\n",
      "Epoch 106:  67%|██████▋   | 38/57 [00:31<00:15,  1.19it/s, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.29s/it]\u001b[A\n",
      "Epoch 106:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.27s/it]\u001b[A\n",
      "Epoch 106:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:33,  2.24s/it]\u001b[A\n",
      "Epoch 106:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:28,  2.22s/it]\u001b[A\n",
      "Epoch 106:  81%|████████  | 46/57 [00:49<00:11,  1.08s/it, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:23,  2.16s/it]\u001b[A\n",
      "Epoch 106:  84%|████████▍ | 48/57 [00:53<00:10,  1.12s/it, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.30s/it]\u001b[A\n",
      "Epoch 106:  88%|████████▊ | 50/57 [00:58<00:08,  1.18s/it, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.23s/it]\u001b[A\n",
      "Epoch 106:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.34s/it]\u001b[A\n",
      "Epoch 106:  95%|█████████▍| 54/57 [01:07<00:03,  1.26s/it, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.27s/it]\u001b[A\n",
      "Epoch 106:  98%|█████████▊| 56/57 [01:12<00:01,  1.30s/it, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.26s/it]\u001b[A\n",
      "Epoch 106: 100%|██████████| 57/57 [01:16<00:00,  1.33s/it, loss=235, v_num=92, train_loss_step=212.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Epoch 107:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 107:  56%|█████▌    | 32/57 [00:18<00:14,  1.75it/s, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:14,  2.97s/it]\u001b[A\n",
      "Epoch 107:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:56,  2.47s/it]\u001b[A\n",
      "Epoch 107:  63%|██████▎   | 36/57 [00:27<00:15,  1.32it/s, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.32s/it]\u001b[A\n",
      "Epoch 107:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.26s/it]\u001b[A\n",
      "Epoch 107:  70%|███████   | 40/57 [00:36<00:15,  1.11it/s, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:40,  2.36s/it]\u001b[A\n",
      "Epoch 107:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:36,  2.42s/it]\u001b[A\n",
      "Epoch 107:  77%|███████▋  | 44/57 [00:46<00:13,  1.05s/it, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:31,  2.41s/it]\u001b[A\n",
      "Epoch 107:  81%|████████  | 46/57 [00:50<00:12,  1.10s/it, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.29s/it]\u001b[A\n",
      "Epoch 107:  84%|████████▍ | 48/57 [00:55<00:10,  1.15s/it, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.28s/it]\u001b[A\n",
      "Epoch 107:  88%|████████▊ | 50/57 [00:59<00:08,  1.19s/it, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.22s/it]\u001b[A\n",
      "Epoch 107:  91%|█████████ | 52/57 [01:04<00:06,  1.23s/it, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.23s/it]\u001b[A\n",
      "Epoch 107:  95%|█████████▍| 54/57 [01:08<00:03,  1.27s/it, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.30s/it]\u001b[A\n",
      "Epoch 107:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.14s/it]\u001b[A\n",
      "Epoch 107: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=250, v_num=92, train_loss_step=250.0, val_loss=206.0, train_loss_epoch=237.0]\n",
      "Epoch 108:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 108:  56%|█████▌    | 32/57 [00:18<00:14,  1.70it/s, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:20,  3.21s/it]\u001b[A\n",
      "Epoch 108:  60%|█████▉    | 34/57 [00:23<00:15,  1.45it/s, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<01:02,  2.73s/it]\u001b[A\n",
      "Epoch 108:  63%|██████▎   | 36/57 [00:28<00:16,  1.28it/s, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.38s/it]\u001b[A\n",
      "Epoch 108:  67%|██████▋   | 38/57 [00:33<00:16,  1.15it/s, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:20<00:45,  2.41s/it]\u001b[A\n",
      "Epoch 108:  70%|███████   | 40/57 [00:37<00:15,  1.06it/s, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:25<00:40,  2.37s/it]\u001b[A\n",
      "Epoch 108:  74%|███████▎  | 42/57 [00:43<00:15,  1.03s/it, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:31<00:39,  2.65s/it]\u001b[A\n",
      "Epoch 108:  77%|███████▋  | 44/57 [00:48<00:14,  1.09s/it, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:36<00:32,  2.50s/it]\u001b[A\n",
      "Epoch 108:  81%|████████  | 46/57 [00:52<00:12,  1.15s/it, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:40<00:25,  2.32s/it]\u001b[A\n",
      "Epoch 108:  84%|████████▍ | 48/57 [00:57<00:10,  1.19s/it, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:45<00:20,  2.31s/it]\u001b[A\n",
      "Epoch 108:  88%|████████▊ | 50/57 [01:01<00:08,  1.24s/it, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:49<00:15,  2.27s/it]\u001b[A\n",
      "Epoch 108:  91%|█████████ | 52/57 [01:06<00:06,  1.28s/it, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:54<00:11,  2.33s/it]\u001b[A\n",
      "Epoch 108:  95%|█████████▍| 54/57 [01:11<00:03,  1.32s/it, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:58<00:06,  2.27s/it]\u001b[A\n",
      "Epoch 108:  98%|█████████▊| 56/57 [01:15<00:01,  1.35s/it, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:03<00:02,  2.16s/it]\u001b[A\n",
      "Epoch 108: 100%|██████████| 57/57 [01:18<00:00,  1.38s/it, loss=240, v_num=92, train_loss_step=269.0, val_loss=206.0, train_loss_epoch=249.0]\n",
      "Epoch 109:  53%|█████▎    | 30/57 [00:14<00:12,  2.10it/s, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 109:  56%|█████▌    | 32/57 [00:23<00:18,  1.37it/s, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:   7%|▋         | 2/27 [00:11<02:03,  4.92s/it]\u001b[A\n",
      "Epoch 109:  60%|█████▉    | 34/57 [00:27<00:18,  1.23it/s, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:15<01:10,  3.05s/it]\u001b[A\n",
      "Epoch 109:  63%|██████▎   | 36/57 [00:31<00:18,  1.13it/s, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:19<00:52,  2.52s/it]\u001b[A\n",
      "Epoch 109:  67%|██████▋   | 38/57 [00:36<00:18,  1.05it/s, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:24<00:45,  2.37s/it]\u001b[A\n",
      "Epoch 109:  70%|███████   | 40/57 [00:40<00:17,  1.01s/it, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:28<00:38,  2.25s/it]\u001b[A\n",
      "Epoch 109:  74%|███████▎  | 42/57 [00:45<00:16,  1.07s/it, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:32<00:33,  2.23s/it]\u001b[A\n",
      "Epoch 109:  77%|███████▋  | 44/57 [00:49<00:14,  1.12s/it, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:37<00:28,  2.20s/it]\u001b[A\n",
      "Epoch 109:  81%|████████  | 46/57 [00:53<00:12,  1.17s/it, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:41<00:24,  2.20s/it]\u001b[A\n",
      "Epoch 109:  84%|████████▍ | 48/57 [00:58<00:10,  1.21s/it, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:46<00:20,  2.24s/it]\u001b[A\n",
      "Epoch 109:  88%|████████▊ | 50/57 [01:03<00:08,  1.26s/it, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:51<00:16,  2.38s/it]\u001b[A\n",
      "Epoch 109:  91%|█████████ | 52/57 [01:07<00:06,  1.30s/it, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:55<00:11,  2.30s/it]\u001b[A\n",
      "Epoch 109:  95%|█████████▍| 54/57 [01:12<00:04,  1.34s/it, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  89%|████████▉ | 24/27 [01:00<00:06,  2.28s/it]\u001b[A\n",
      "Epoch 109:  98%|█████████▊| 56/57 [01:16<00:01,  1.37s/it, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:04<00:02,  2.24s/it]\u001b[A\n",
      "Epoch 109: 100%|██████████| 57/57 [01:20<00:00,  1.41s/it, loss=238, v_num=92, train_loss_step=244.0, val_loss=206.0, train_loss_epoch=238.0]\n",
      "Epoch 110:  53%|█████▎    | 30/57 [00:14<00:13,  2.04it/s, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 110:  56%|█████▌    | 32/57 [00:18<00:14,  1.70it/s, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:18,  3.12s/it]\u001b[A\n",
      "Epoch 110:  60%|█████▉    | 34/57 [00:23<00:15,  1.45it/s, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:11<00:59,  2.59s/it]\u001b[A\n",
      "Epoch 110:  63%|██████▎   | 36/57 [00:28<00:16,  1.28it/s, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.36s/it]\u001b[A\n",
      "Epoch 110:  67%|██████▋   | 38/57 [00:32<00:16,  1.17it/s, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.25s/it]\u001b[A\n",
      "Epoch 110:  70%|███████   | 40/57 [00:37<00:15,  1.07it/s, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:38,  2.28s/it]\u001b[A\n",
      "Epoch 110:  74%|███████▎  | 42/57 [00:41<00:14,  1.00it/s, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.39s/it]\u001b[A\n",
      "Epoch 110:  77%|███████▋  | 44/57 [00:46<00:13,  1.07s/it, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:34<00:30,  2.35s/it]\u001b[A\n",
      "Epoch 110:  81%|████████  | 46/57 [00:51<00:12,  1.12s/it, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.33s/it]\u001b[A\n",
      "Epoch 110:  84%|████████▍ | 48/57 [00:55<00:10,  1.16s/it, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:43<00:20,  2.28s/it]\u001b[A\n",
      "Epoch 110:  88%|████████▊ | 50/57 [01:00<00:08,  1.21s/it, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:47<00:15,  2.17s/it]\u001b[A\n",
      "Epoch 110:  91%|█████████ | 52/57 [01:04<00:06,  1.24s/it, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:52<00:11,  2.27s/it]\u001b[A\n",
      "Epoch 110:  95%|█████████▍| 54/57 [01:09<00:03,  1.28s/it, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:56<00:06,  2.18s/it]\u001b[A\n",
      "Epoch 110:  98%|█████████▊| 56/57 [01:13<00:01,  1.31s/it, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.07s/it]\u001b[A\n",
      "Epoch 110: 100%|██████████| 57/57 [01:16<00:00,  1.34s/it, loss=231, v_num=92, train_loss_step=218.0, val_loss=206.0, train_loss_epoch=236.0]\n",
      "Epoch 111:  53%|█████▎    | 30/57 [00:14<00:12,  2.12it/s, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 111:  56%|█████▌    | 32/57 [00:18<00:14,  1.76it/s, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:13,  2.94s/it]\u001b[A\n",
      "Epoch 111:  60%|█████▉    | 34/57 [00:22<00:15,  1.51it/s, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.50s/it]\u001b[A\n",
      "Epoch 111:  63%|██████▎   | 36/57 [00:27<00:15,  1.33it/s, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:50,  2.39s/it]\u001b[A\n",
      "Epoch 111:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:43,  2.29s/it]\u001b[A\n",
      "Epoch 111:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:40,  2.40s/it]\u001b[A\n",
      "Epoch 111:  74%|███████▎  | 42/57 [00:41<00:14,  1.02it/s, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:29<00:35,  2.36s/it]\u001b[A\n",
      "Epoch 111:  77%|███████▋  | 44/57 [00:45<00:13,  1.04s/it, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:30,  2.31s/it]\u001b[A\n",
      "Epoch 111:  81%|████████  | 46/57 [00:50<00:11,  1.09s/it, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:38<00:25,  2.28s/it]\u001b[A\n",
      "Epoch 111:  84%|████████▍ | 48/57 [00:54<00:10,  1.14s/it, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:19,  2.22s/it]\u001b[A\n",
      "Epoch 111:  88%|████████▊ | 50/57 [00:58<00:08,  1.18s/it, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.15s/it]\u001b[A\n",
      "Epoch 111:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:10,  2.16s/it]\u001b[A\n",
      "Epoch 111:  95%|█████████▍| 54/57 [01:07<00:03,  1.25s/it, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.22s/it]\u001b[A\n",
      "Epoch 111:  98%|█████████▊| 56/57 [01:12<00:01,  1.29s/it, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:00<00:02,  2.19s/it]\u001b[A\n",
      "Epoch 111: 100%|██████████| 57/57 [01:15<00:00,  1.32s/it, loss=235, v_num=92, train_loss_step=233.0, val_loss=206.0, train_loss_epoch=233.0]\n",
      "Epoch 112:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 112:  56%|█████▌    | 32/57 [00:18<00:14,  1.73it/s, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:12,  2.90s/it]\u001b[A\n",
      "Epoch 112:  60%|█████▉    | 34/57 [00:22<00:15,  1.49it/s, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.52s/it]\u001b[A\n",
      "Epoch 112:  63%|██████▎   | 36/57 [00:27<00:16,  1.31it/s, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:48,  2.32s/it]\u001b[A\n",
      "Epoch 112:  67%|██████▋   | 38/57 [00:31<00:15,  1.20it/s, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:19<00:42,  2.21s/it]\u001b[A\n",
      "Epoch 112:  70%|███████   | 40/57 [00:36<00:15,  1.10it/s, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:24<00:39,  2.30s/it]\u001b[A\n",
      "Epoch 112:  74%|███████▎  | 42/57 [00:40<00:14,  1.02it/s, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:28<00:34,  2.29s/it]\u001b[A\n",
      "Epoch 112:  77%|███████▋  | 44/57 [00:45<00:13,  1.03s/it, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:33<00:29,  2.24s/it]\u001b[A\n",
      "Epoch 112:  81%|████████  | 46/57 [00:49<00:11,  1.08s/it, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:37<00:25,  2.28s/it]\u001b[A\n",
      "Epoch 112:  84%|████████▍ | 48/57 [00:54<00:10,  1.13s/it, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:42<00:20,  2.31s/it]\u001b[A\n",
      "Epoch 112:  88%|████████▊ | 50/57 [00:58<00:08,  1.18s/it, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:46<00:15,  2.19s/it]\u001b[A\n",
      "Epoch 112:  91%|█████████ | 52/57 [01:03<00:06,  1.22s/it, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:51<00:11,  2.24s/it]\u001b[A\n",
      "Epoch 112:  95%|█████████▍| 54/57 [01:07<00:03,  1.25s/it, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  89%|████████▉ | 24/27 [00:55<00:06,  2.17s/it]\u001b[A\n",
      "Epoch 112:  98%|█████████▊| 56/57 [01:12<00:01,  1.29s/it, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Validating:  96%|█████████▋| 26/27 [00:59<00:02,  2.05s/it]\u001b[A\n",
      "Epoch 112: 100%|██████████| 57/57 [01:14<00:00,  1.31s/it, loss=232, v_num=92, train_loss_step=222.0, val_loss=206.0, train_loss_epoch=239.0]\n",
      "Epoch 113:  53%|█████▎    | 30/57 [00:14<00:12,  2.09it/s, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 113:  56%|█████▌    | 32/57 [00:18<00:14,  1.72it/s, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:   7%|▋         | 2/27 [00:06<01:14,  2.97s/it]\u001b[A\n",
      "Epoch 113:  60%|█████▉    | 34/57 [00:23<00:15,  1.47it/s, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  15%|█▍        | 4/27 [00:10<00:57,  2.51s/it]\u001b[A\n",
      "Epoch 113:  63%|██████▎   | 36/57 [00:27<00:16,  1.30it/s, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  22%|██▏       | 6/27 [00:15<00:49,  2.36s/it]\u001b[A\n",
      "Epoch 113:  67%|██████▋   | 38/57 [00:37<00:18,  1.01it/s, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  30%|██▉       | 8/27 [00:25<01:06,  3.52s/it]\u001b[A\n",
      "Epoch 113:  70%|███████   | 40/57 [00:42<00:17,  1.05s/it, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  37%|███▋      | 10/27 [00:30<00:49,  2.94s/it]\u001b[A\n",
      "Epoch 113:  74%|███████▎  | 42/57 [00:47<00:16,  1.12s/it, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  44%|████▍     | 12/27 [00:35<00:39,  2.67s/it]\u001b[A\n",
      "Epoch 113:  77%|███████▋  | 44/57 [00:51<00:15,  1.17s/it, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  52%|█████▏    | 14/27 [00:39<00:30,  2.38s/it]\u001b[A\n",
      "Epoch 113:  81%|████████  | 46/57 [00:55<00:13,  1.21s/it, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  59%|█████▉    | 16/27 [00:43<00:24,  2.26s/it]\u001b[A\n",
      "Epoch 113:  84%|████████▍ | 48/57 [01:00<00:11,  1.26s/it, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  67%|██████▋   | 18/27 [00:48<00:20,  2.30s/it]\u001b[A\n",
      "Epoch 113:  88%|████████▊ | 50/57 [01:04<00:09,  1.29s/it, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  74%|███████▍  | 20/27 [00:53<00:16,  2.36s/it]\u001b[A\n",
      "Epoch 113:  91%|█████████ | 52/57 [01:09<00:06,  1.34s/it, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  81%|████████▏ | 22/27 [00:57<00:11,  2.37s/it]\u001b[A\n",
      "Epoch 113:  95%|█████████▍| 54/57 [01:14<00:04,  1.38s/it, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  89%|████████▉ | 24/27 [01:02<00:06,  2.30s/it]\u001b[A\n",
      "Epoch 113:  98%|█████████▊| 56/57 [01:18<00:01,  1.41s/it, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Validating:  96%|█████████▋| 26/27 [01:06<00:02,  2.09s/it]\u001b[A\n",
      "Epoch 113: 100%|██████████| 57/57 [01:21<00:00,  1.43s/it, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=234.0]\n",
      "Epoch 113: 100%|██████████| 57/57 [01:22<00:00,  1.45s/it, loss=232, v_num=92, train_loss_step=256.0, val_loss=206.0, train_loss_epoch=231.0]\n"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dca7c1d7",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "b8abc9e1",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightning_logs/default/version_92/checkpoints/epoch=113-step=3419.ckpt\n"
     ]
    }
   ],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(best_model_path)\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6f8c49a8",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2267477e",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "# calcualte root mean squared error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "val_predictions = best_tft.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b45d005a",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9b05009c",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2466)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "torch.sqrt(criterion(actuals,val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3246d67c",
   "metadata": {
    "gradient": {
     "id": "1c670f30",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 1., 1., 1., 2.]) tensor([1.6709, 1.7547, 1.8134, 1.8597, 1.8989, 1.9335, 1.9645, 1.9926])\n",
      "tensor([2., 3., 1., 1., 1., 1., 1., 1.]) tensor([1.7913, 1.8773, 1.9382, 1.9869, 2.0293, 2.0671, 2.1010, 2.1315])\n",
      "tensor([6., 6., 6., 6., 6., 4., 1., 1.]) tensor([4.5743, 4.5718, 4.5447, 4.5077, 4.4673, 4.4266, 4.3870, 4.3495])\n",
      "tensor([1., 1., 1., 1., 1., 1., 4., 2.]) tensor([1.4190, 1.4802, 1.5359, 1.5909, 1.6472, 1.7036, 1.7584, 1.8097])\n",
      "tensor([2., 2., 1., 1., 1., 1., 2., 1.]) tensor([1.7114, 1.8005, 1.8651, 1.9179, 1.9643, 2.0058, 2.0435, 2.0779])\n",
      "tensor([1., 1., 1., 1., 1., 6., 3., 1.]) tensor([1.3339, 1.4022, 1.4604, 1.5153, 1.5731, 1.6346, 1.6982, 1.7614])\n",
      "tensor([3., 3., 3., 3., 7., 1., 1., 3.]) tensor([2.1456, 2.2359, 2.3096, 2.3743, 2.4334, 2.4871, 2.5355, 2.5790])\n",
      "tensor([10., 11.,  2.,  1.,  3.,  6.,  5.,  6.]) tensor([3.7821, 3.8382, 3.8572, 3.8558, 3.8423, 3.8215, 3.7969, 3.7709])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1.]) tensor([2.9306, 3.0377, 3.1275, 3.2057, 3.2769, 3.3407, 3.3979, 3.4489])\n",
      "tensor([5., 3., 2., 1., 1., 2., 2., 1.]) tensor([3.4625, 3.5491, 3.5905, 3.6068, 3.6077, 3.5994, 3.5865, 3.5723])\n",
      "tensor([7., 7., 1., 1., 1., 2., 1., 5.]) tensor([4.0588, 4.0871, 4.0915, 4.0812, 4.0614, 4.0354, 4.0060, 3.9753])\n",
      "tensor([2., 2., 3., 3., 2., 1., 7., 9.]) tensor([2.2410, 2.3443, 2.4173, 2.4751, 2.5244, 2.5674, 2.6052, 2.6390])\n",
      "tensor([4., 4., 4., 1., 2., 4., 3., 2.]) tensor([2.4526, 2.5319, 2.5703, 2.5901, 2.6020, 2.6106, 2.6182, 2.6259])\n",
      "tensor([1., 1., 1., 1., 1., 2., 2., 2.]) tensor([2.0210, 2.1071, 2.1902, 2.2705, 2.3593, 2.4602, 2.5709, 2.6863])\n",
      "tensor([4., 2., 1., 1., 1., 1., 3., 2.]) tensor([1.7667, 1.8561, 1.9218, 1.9755, 2.0228, 2.0650, 2.1030, 2.1373])\n",
      "tensor([1., 1., 1., 2., 2., 2., 3., 3.]) tensor([1.9383, 2.0158, 2.0628, 2.0953, 2.1206, 2.1420, 2.1611, 2.1789])\n",
      "tensor([4., 4., 4., 1., 2., 2., 1., 2.]) tensor([2.7949, 2.9265, 3.0059, 3.0571, 3.0928, 3.1193, 3.1404, 3.1589])\n",
      "tensor([2., 2., 2., 4., 3., 3., 1., 1.]) tensor([1.8736, 1.9617, 2.0225, 2.0699, 2.1104, 2.1461, 2.1779, 2.2067])\n",
      "tensor([21.,  1.,  5., 11., 11.,  9.,  6., 17.]) tensor([6.3135, 6.3153, 6.3065, 6.2902, 6.2662, 6.2356, 6.1998, 6.1606])\n",
      "tensor([8., 8., 8., 8., 8., 1., 2., 9.]) tensor([2.3040, 2.3797, 2.4378, 2.4845, 2.5244, 2.5588, 2.5900, 2.6185])\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(actuals[i],val_predictions[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4272f9e2",
   "metadata": {
    "gradient": {
     "id": "e6fed50e",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_prediction_length: 8\n",
      "max_encoder_length   : 20\n"
     ]
    }
   ],
   "source": [
    "print('max_prediction_length:',max_prediction_length)\n",
    "print('max_encoder_length   :',max_encoder_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "62265f9e",
   "metadata": {
    "gradient": {
     "id": "46847089",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>QTT</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>S100</th>\n",
       "      <th>item_id</th>\n",
       "      <th>S101</th>\n",
       "      <th>S102</th>\n",
       "      <th>S103</th>\n",
       "      <th>I100</th>\n",
       "      <th>I101</th>\n",
       "      <th>...</th>\n",
       "      <th>C101</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_month_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>317_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>140_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>319_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>164_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>321_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>339_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>324_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>128_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>335_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>164_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69116</th>\n",
       "      <td>2021-10-24</td>\n",
       "      <td>-1</td>\n",
       "      <td>94</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>297</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69117</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>248_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69118</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69119</th>\n",
       "      <td>2021-10-17</td>\n",
       "      <td>-1</td>\n",
       "      <td>93</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>62_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>12_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>79_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69120</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>62_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>12_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>79_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69121 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE  QTT  date_block_num     S100      item_id    S101     S102  \\\n",
       "0     2021-10-03   -1              91   0_S100  317_item_id  1_S101  17_S102   \n",
       "1     2021-10-03   -1              91   0_S100  319_item_id  1_S101  17_S102   \n",
       "2     2021-10-03   -1              91   0_S100  321_item_id  1_S101  17_S102   \n",
       "3     2021-10-03   -1              91   0_S100  324_item_id  1_S101  17_S102   \n",
       "4     2021-10-03   -1              91   0_S100  335_item_id  1_S101  17_S102   \n",
       "...          ...  ...             ...      ...          ...     ...      ...   \n",
       "69116 2021-10-24   -1              94  22_S100  251_item_id  0_S101   0_S102   \n",
       "69117 2021-11-07   -1              96  22_S100  248_item_id  0_S101   0_S102   \n",
       "69118 2021-11-07   -1              96  22_S100  251_item_id  0_S101   0_S102   \n",
       "69119 2021-10-17   -1              93  22_S100   62_item_id  0_S101   0_S102   \n",
       "69120 2021-11-07   -1              96  22_S100   62_item_id  0_S101   0_S102   \n",
       "\n",
       "          S103     I100    I101  ...      C101 day_of_week day is_month_end  \\\n",
       "0      10_S103   1_I100  2_I101  ...  140_C101           6   3        False   \n",
       "1      10_S103   1_I100  2_I101  ...  164_C101           6   3        False   \n",
       "2      10_S103   1_I100  2_I101  ...  339_C101           6   3        False   \n",
       "3      10_S103   1_I100  2_I101  ...  128_C101           6   3        False   \n",
       "4      10_S103   1_I100  2_I101  ...  164_C101           6   3        False   \n",
       "...        ...      ...     ...  ...       ...         ...  ..          ...   \n",
       "69116  10_S103  18_I100  2_I101  ...   76_C101           6  24        False   \n",
       "69117  10_S103  18_I100  2_I101  ...   76_C101           6   7        False   \n",
       "69118  10_S103  18_I100  2_I101  ...   76_C101           6   7        False   \n",
       "69119  10_S103  12_I100  2_I101  ...   79_C101           6  17        False   \n",
       "69120  10_S103  12_I100  2_I101  ...   79_C101           6   7        False   \n",
       "\n",
       "       day_of_year  is_quarter_start  year  month  is_year_start  \\\n",
       "0              276             False  2021     10          False   \n",
       "1              276             False  2021     10          False   \n",
       "2              276             False  2021     10          False   \n",
       "3              276             False  2021     10          False   \n",
       "4              276             False  2021     10          False   \n",
       "...            ...               ...   ...    ...            ...   \n",
       "69116          297             False  2021     10          False   \n",
       "69117          311             False  2021     11          False   \n",
       "69118          311             False  2021     11          False   \n",
       "69119          290             False  2021     10          False   \n",
       "69120          311             False  2021     11          False   \n",
       "\n",
       "       is_month_start  \n",
       "0               False  \n",
       "1               False  \n",
       "2               False  \n",
       "3               False  \n",
       "4               False  \n",
       "...               ...  \n",
       "69116           False  \n",
       "69117           False  \n",
       "69118           False  \n",
       "69119           False  \n",
       "69120           False  \n",
       "\n",
       "[69121 rows x 23 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d8c83077",
   "metadata": {
    "gradient": {
     "id": "bfd9fc24",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>QTT</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>S100</th>\n",
       "      <th>item_id</th>\n",
       "      <th>S101</th>\n",
       "      <th>S102</th>\n",
       "      <th>S103</th>\n",
       "      <th>I100</th>\n",
       "      <th>I101</th>\n",
       "      <th>...</th>\n",
       "      <th>C101</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_month_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>331_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>136</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>327_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>164_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>136</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>329_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>339_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>136</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>330_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>354_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>136</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>339_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>136</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733805</th>\n",
       "      <td>2021-08-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733806</th>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>245_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>140_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733807</th>\n",
       "      <td>2021-08-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>241</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733808</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>255</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733809</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215490 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE  QTT  date_block_num     S100      item_id    S101     S102  \\\n",
       "571    2021-05-16  1.0              71   0_S100  331_item_id  1_S101  17_S102   \n",
       "572    2021-05-16  2.0              71   0_S100  327_item_id  1_S101  17_S102   \n",
       "573    2021-05-16  1.0              71   0_S100  329_item_id  1_S101  17_S102   \n",
       "574    2021-05-16  2.0              71   0_S100  330_item_id  1_S101  17_S102   \n",
       "575    2021-05-16  1.0              71   0_S100  339_item_id  1_S101  17_S102   \n",
       "...           ...  ...             ...      ...          ...     ...      ...   \n",
       "733805 2021-08-08  1.0              83  22_S100  251_item_id  0_S101   0_S102   \n",
       "733806 2021-08-15  1.0              84  22_S100  245_item_id  0_S101   0_S102   \n",
       "733807 2021-08-29  1.0              86  22_S100  251_item_id  0_S101   0_S102   \n",
       "733808 2021-09-12  1.0              88  22_S100  251_item_id  0_S101   0_S102   \n",
       "733809 2021-09-26  1.0              90  22_S100  251_item_id  0_S101   0_S102   \n",
       "\n",
       "           S103     I100    I101  ...      C101 day_of_week day is_month_end  \\\n",
       "571     10_S103   1_I100  2_I101  ...   76_C101           6  16        False   \n",
       "572     10_S103   1_I100  2_I101  ...  164_C101           6  16        False   \n",
       "573     10_S103   1_I100  2_I101  ...  339_C101           6  16        False   \n",
       "574     10_S103   1_I100  2_I101  ...  354_C101           6  16        False   \n",
       "575     10_S103   1_I100  2_I101  ...   76_C101           6  16        False   \n",
       "...         ...      ...     ...  ...       ...         ...  ..          ...   \n",
       "733805  10_S103  18_I100  2_I101  ...   76_C101           6   8        False   \n",
       "733806  10_S103  18_I100  2_I101  ...  140_C101           6  15        False   \n",
       "733807  10_S103  18_I100  2_I101  ...   76_C101           6  29        False   \n",
       "733808  10_S103  18_I100  2_I101  ...   76_C101           6  12        False   \n",
       "733809  10_S103  18_I100  2_I101  ...   76_C101           6  26        False   \n",
       "\n",
       "        day_of_year  is_quarter_start  year  month  is_year_start  \\\n",
       "571             136             False  2021      5          False   \n",
       "572             136             False  2021      5          False   \n",
       "573             136             False  2021      5          False   \n",
       "574             136             False  2021      5          False   \n",
       "575             136             False  2021      5          False   \n",
       "...             ...               ...   ...    ...            ...   \n",
       "733805          220             False  2021      8          False   \n",
       "733806          227             False  2021      8          False   \n",
       "733807          241             False  2021      8          False   \n",
       "733808          255             False  2021      9          False   \n",
       "733809          269             False  2021      9          False   \n",
       "\n",
       "        is_month_start  \n",
       "571              False  \n",
       "572              False  \n",
       "573              False  \n",
       "574              False  \n",
       "575              False  \n",
       "...                ...  \n",
       "733805           False  \n",
       "733806           False  \n",
       "733807           False  \n",
       "733808           False  \n",
       "733809           False  \n",
       "\n",
       "[215490 rows x 23 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select last 30 days from data (max_encoder_length is 24)\n",
    "encoder_data = df_sales[lambda x: x.date_block_num > x.date_block_num.max() - max_encoder_length]\n",
    "\n",
    "print(encoder_data['date_block_num'].min(),encoder_data['date_block_num'].max())\n",
    "#print(encoder_data['DATE'].min(),encoder_data['DATE'].max())\n",
    "encoder_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bc4be3bd",
   "metadata": {
    "gradient": {
     "id": "8ea2098f",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "last_data = df_sales[df_sales['date_block_num'].isin([idx  -  max_prediction_length for idx in df_submission_sample['date_block_num'].unique()])]\n",
    "last_data['date_block_num'] = last_data['date_block_num'] + max_prediction_length\n",
    "\n",
    "decoder_data = pd.merge(df_submission_sample[[col for col in df_submission_sample.columns if 'QTT' not in col]], \n",
    "        last_data[['date_block_num','S100', 'item_id',\"QTT\"]],\n",
    "        on = ['date_block_num', 'S100', 'item_id',],\n",
    "                        how='left'\n",
    "        )\n",
    "\n",
    "\n",
    "encoder_data.replace([np.inf, -np.inf, np.nan],0,inplace=True)\n",
    "decoder_data.replace([np.inf, -np.inf, np.nan],0,inplace=True)\n",
    "\n",
    "\n",
    "# combine encoder and decoder data\n",
    "new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "42608133",
   "metadata": {
    "gradient": {
     "id": "f3d5a5be",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>QTT</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>S100</th>\n",
       "      <th>item_id</th>\n",
       "      <th>S101</th>\n",
       "      <th>S102</th>\n",
       "      <th>S103</th>\n",
       "      <th>I100</th>\n",
       "      <th>I101</th>\n",
       "      <th>...</th>\n",
       "      <th>C101</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_month_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>2021-08-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>316_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>128_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>2021-08-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>317_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>140_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>2021-08-08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>319_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>164_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>2021-08-08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>320_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>201_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2021-08-08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>322_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>354_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733805</th>\n",
       "      <td>2021-08-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733806</th>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>245_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>140_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>227</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733807</th>\n",
       "      <td>2021-08-29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>241</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733808</th>\n",
       "      <td>2021-09-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>255</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733809</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "      <td>269</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84002 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE  QTT  date_block_num     S100      item_id    S101     S102  \\\n",
       "643    2021-08-08  1.0              91   0_S100  316_item_id  1_S101  17_S102   \n",
       "644    2021-08-08  1.0              91   0_S100  317_item_id  1_S101  17_S102   \n",
       "645    2021-08-08  2.0              91   0_S100  319_item_id  1_S101  17_S102   \n",
       "646    2021-08-08  2.0              91   0_S100  320_item_id  1_S101  17_S102   \n",
       "647    2021-08-08  2.0              91   0_S100  322_item_id  1_S101  17_S102   \n",
       "...           ...  ...             ...      ...          ...     ...      ...   \n",
       "733805 2021-08-08  1.0              91  22_S100  251_item_id  0_S101   0_S102   \n",
       "733806 2021-08-15  1.0              92  22_S100  245_item_id  0_S101   0_S102   \n",
       "733807 2021-08-29  1.0              94  22_S100  251_item_id  0_S101   0_S102   \n",
       "733808 2021-09-12  1.0              96  22_S100  251_item_id  0_S101   0_S102   \n",
       "733809 2021-09-26  1.0              98  22_S100  251_item_id  0_S101   0_S102   \n",
       "\n",
       "           S103     I100    I101  ...      C101 day_of_week day is_month_end  \\\n",
       "643     10_S103   1_I100  2_I101  ...  128_C101           6   8        False   \n",
       "644     10_S103   1_I100  2_I101  ...  140_C101           6   8        False   \n",
       "645     10_S103   1_I100  2_I101  ...  164_C101           6   8        False   \n",
       "646     10_S103   1_I100  2_I101  ...  201_C101           6   8        False   \n",
       "647     10_S103   1_I100  2_I101  ...  354_C101           6   8        False   \n",
       "...         ...      ...     ...  ...       ...         ...  ..          ...   \n",
       "733805  10_S103  18_I100  2_I101  ...   76_C101           6   8        False   \n",
       "733806  10_S103  18_I100  2_I101  ...  140_C101           6  15        False   \n",
       "733807  10_S103  18_I100  2_I101  ...   76_C101           6  29        False   \n",
       "733808  10_S103  18_I100  2_I101  ...   76_C101           6  12        False   \n",
       "733809  10_S103  18_I100  2_I101  ...   76_C101           6  26        False   \n",
       "\n",
       "        day_of_year  is_quarter_start  year  month  is_year_start  \\\n",
       "643             220             False  2021      8          False   \n",
       "644             220             False  2021      8          False   \n",
       "645             220             False  2021      8          False   \n",
       "646             220             False  2021      8          False   \n",
       "647             220             False  2021      8          False   \n",
       "...             ...               ...   ...    ...            ...   \n",
       "733805          220             False  2021      8          False   \n",
       "733806          227             False  2021      8          False   \n",
       "733807          241             False  2021      8          False   \n",
       "733808          255             False  2021      9          False   \n",
       "733809          269             False  2021      9          False   \n",
       "\n",
       "        is_month_start  \n",
       "643              False  \n",
       "644              False  \n",
       "645              False  \n",
       "646              False  \n",
       "647              False  \n",
       "...                ...  \n",
       "733805           False  \n",
       "733806           False  \n",
       "733807           False  \n",
       "733808           False  \n",
       "733809           False  \n",
       "\n",
       "[84002 rows x 23 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "167796c0",
   "metadata": {
    "gradient": {
     "id": "cc9ecb1f",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>S100</th>\n",
       "      <th>item_id</th>\n",
       "      <th>S101</th>\n",
       "      <th>S102</th>\n",
       "      <th>S103</th>\n",
       "      <th>I100</th>\n",
       "      <th>I101</th>\n",
       "      <th>I102</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>QTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>317_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>319_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>321_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>324_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>335_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69116</th>\n",
       "      <td>2021-10-24</td>\n",
       "      <td>94</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>297</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69117</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>248_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69118</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69119</th>\n",
       "      <td>2021-10-17</td>\n",
       "      <td>93</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>62_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>12_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69120</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>62_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>12_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69121 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE  date_block_num     S100      item_id    S101     S102  \\\n",
       "0     2021-10-03              91   0_S100  317_item_id  1_S101  17_S102   \n",
       "1     2021-10-03              91   0_S100  319_item_id  1_S101  17_S102   \n",
       "2     2021-10-03              91   0_S100  321_item_id  1_S101  17_S102   \n",
       "3     2021-10-03              91   0_S100  324_item_id  1_S101  17_S102   \n",
       "4     2021-10-03              91   0_S100  335_item_id  1_S101  17_S102   \n",
       "...          ...             ...      ...          ...     ...      ...   \n",
       "69116 2021-10-24              94  22_S100  251_item_id  0_S101   0_S102   \n",
       "69117 2021-11-07              96  22_S100  248_item_id  0_S101   0_S102   \n",
       "69118 2021-11-07              96  22_S100  251_item_id  0_S101   0_S102   \n",
       "69119 2021-10-17              93  22_S100   62_item_id  0_S101   0_S102   \n",
       "69120 2021-11-07              96  22_S100   62_item_id  0_S101   0_S102   \n",
       "\n",
       "          S103     I100    I101    I102  ... day_of_week day is_month_end  \\\n",
       "0      10_S103   1_I100  2_I101  1_I102  ...           6   3        False   \n",
       "1      10_S103   1_I100  2_I101  1_I102  ...           6   3        False   \n",
       "2      10_S103   1_I100  2_I101  1_I102  ...           6   3        False   \n",
       "3      10_S103   1_I100  2_I101  1_I102  ...           6   3        False   \n",
       "4      10_S103   1_I100  2_I101  1_I102  ...           6   3        False   \n",
       "...        ...      ...     ...     ...  ...         ...  ..          ...   \n",
       "69116  10_S103  18_I100  2_I101  1_I102  ...           6  24        False   \n",
       "69117  10_S103  18_I100  2_I101  1_I102  ...           6   7        False   \n",
       "69118  10_S103  18_I100  2_I101  1_I102  ...           6   7        False   \n",
       "69119  10_S103  12_I100  2_I101  1_I102  ...           6  17        False   \n",
       "69120  10_S103  12_I100  2_I101  1_I102  ...           6   7        False   \n",
       "\n",
       "       day_of_year  is_quarter_start  year  month  is_year_start  \\\n",
       "0              276             False  2021     10          False   \n",
       "1              276             False  2021     10          False   \n",
       "2              276             False  2021     10          False   \n",
       "3              276             False  2021     10          False   \n",
       "4              276             False  2021     10          False   \n",
       "...            ...               ...   ...    ...            ...   \n",
       "69116          297             False  2021     10          False   \n",
       "69117          311             False  2021     11          False   \n",
       "69118          311             False  2021     11          False   \n",
       "69119          290             False  2021     10          False   \n",
       "69120          311             False  2021     11          False   \n",
       "\n",
       "       is_month_start  QTT  \n",
       "0               False  1.0  \n",
       "1               False  2.0  \n",
       "2               False  0.0  \n",
       "3               False  0.0  \n",
       "4               False  0.0  \n",
       "...               ...  ...  \n",
       "69116           False  1.0  \n",
       "69117           False  0.0  \n",
       "69118           False  1.0  \n",
       "69119           False  1.0  \n",
       "69120           False  0.0  \n",
       "\n",
       "[69121 rows x 23 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "62e16bca",
   "metadata": {
    "gradient": {
     "id": "f13fe547",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>QTT</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>S100</th>\n",
       "      <th>item_id</th>\n",
       "      <th>S101</th>\n",
       "      <th>S102</th>\n",
       "      <th>S103</th>\n",
       "      <th>I100</th>\n",
       "      <th>I101</th>\n",
       "      <th>...</th>\n",
       "      <th>C101</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_month_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>331_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>136</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>327_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>164_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>136</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>329_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>339_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>136</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>330_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>354_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>136</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>339_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>False</td>\n",
       "      <td>136</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284606</th>\n",
       "      <td>2021-10-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>297</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284607</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>248_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284608</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>76_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284609</th>\n",
       "      <td>2021-10-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>62_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>12_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>79_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284610</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>62_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>12_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>79_C101</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284611 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATE  QTT  date_block_num     S100      item_id    S101     S102  \\\n",
       "0      2021-05-16  1.0              71   0_S100  331_item_id  1_S101  17_S102   \n",
       "1      2021-05-16  2.0              71   0_S100  327_item_id  1_S101  17_S102   \n",
       "2      2021-05-16  1.0              71   0_S100  329_item_id  1_S101  17_S102   \n",
       "3      2021-05-16  2.0              71   0_S100  330_item_id  1_S101  17_S102   \n",
       "4      2021-05-16  1.0              71   0_S100  339_item_id  1_S101  17_S102   \n",
       "...           ...  ...             ...      ...          ...     ...      ...   \n",
       "284606 2021-10-24  1.0              94  22_S100  251_item_id  0_S101   0_S102   \n",
       "284607 2021-11-07  0.0              96  22_S100  248_item_id  0_S101   0_S102   \n",
       "284608 2021-11-07  1.0              96  22_S100  251_item_id  0_S101   0_S102   \n",
       "284609 2021-10-17  1.0              93  22_S100   62_item_id  0_S101   0_S102   \n",
       "284610 2021-11-07  0.0              96  22_S100   62_item_id  0_S101   0_S102   \n",
       "\n",
       "           S103     I100    I101  ...      C101 day_of_week day is_month_end  \\\n",
       "0       10_S103   1_I100  2_I101  ...   76_C101           6  16        False   \n",
       "1       10_S103   1_I100  2_I101  ...  164_C101           6  16        False   \n",
       "2       10_S103   1_I100  2_I101  ...  339_C101           6  16        False   \n",
       "3       10_S103   1_I100  2_I101  ...  354_C101           6  16        False   \n",
       "4       10_S103   1_I100  2_I101  ...   76_C101           6  16        False   \n",
       "...         ...      ...     ...  ...       ...         ...  ..          ...   \n",
       "284606  10_S103  18_I100  2_I101  ...   76_C101           6  24        False   \n",
       "284607  10_S103  18_I100  2_I101  ...   76_C101           6   7        False   \n",
       "284608  10_S103  18_I100  2_I101  ...   76_C101           6   7        False   \n",
       "284609  10_S103  12_I100  2_I101  ...   79_C101           6  17        False   \n",
       "284610  10_S103  12_I100  2_I101  ...   79_C101           6   7        False   \n",
       "\n",
       "        day_of_year  is_quarter_start  year  month  is_year_start  \\\n",
       "0               136             False  2021      5          False   \n",
       "1               136             False  2021      5          False   \n",
       "2               136             False  2021      5          False   \n",
       "3               136             False  2021      5          False   \n",
       "4               136             False  2021      5          False   \n",
       "...             ...               ...   ...    ...            ...   \n",
       "284606          297             False  2021     10          False   \n",
       "284607          311             False  2021     11          False   \n",
       "284608          311             False  2021     11          False   \n",
       "284609          290             False  2021     10          False   \n",
       "284610          311             False  2021     11          False   \n",
       "\n",
       "        is_month_start  \n",
       "0                False  \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  \n",
       "...                ...  \n",
       "284606           False  \n",
       "284607           False  \n",
       "284608           False  \n",
       "284609           False  \n",
       "284610           False  \n",
       "\n",
       "[284611 rows x 23 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prediction_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "854ceb5d",
   "metadata": {
    "gradient": {
     "id": "29b1675a",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATE', 'QTT', 'date_block_num', 'S100', 'item_id', 'S101', 'S102',\n",
       "       'S103', 'I100', 'I101', 'I102', 'I103', 'C100', 'C101', 'day_of_week',\n",
       "       'day', 'is_month_end', 'day_of_year', 'is_quarter_start', 'year',\n",
       "       'month', 'is_year_start', 'is_month_start'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission_sample.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "416aed39",
   "metadata": {},
   "source": [
    "new_raw_predictions, new_x = best_tft.predict(new_prediction_data, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "73152e64",
   "metadata": {
    "gradient": {
     "id": "05a0a2bc",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions = best_tft.predict(new_prediction_data, mode=\"prediction\", return_x=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d5a7ad4c",
   "metadata": {
    "gradient": {
     "id": "0c6cb462",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(predictions.numpy()).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8229bfcc",
   "metadata": {
    "gradient": {
     "id": "c118757f",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "ga = predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7833f4f6",
   "metadata": {
    "gradient": {
     "id": "a975f357",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.991668</td>\n",
       "      <td>2.081356</td>\n",
       "      <td>2.142166</td>\n",
       "      <td>2.189419</td>\n",
       "      <td>2.229165</td>\n",
       "      <td>2.264290</td>\n",
       "      <td>2.295785</td>\n",
       "      <td>2.324450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.374382</td>\n",
       "      <td>1.440966</td>\n",
       "      <td>1.498263</td>\n",
       "      <td>1.552595</td>\n",
       "      <td>1.610255</td>\n",
       "      <td>1.673098</td>\n",
       "      <td>1.740388</td>\n",
       "      <td>1.809329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.574277</td>\n",
       "      <td>4.571805</td>\n",
       "      <td>4.544686</td>\n",
       "      <td>4.507704</td>\n",
       "      <td>4.467286</td>\n",
       "      <td>4.426587</td>\n",
       "      <td>4.387007</td>\n",
       "      <td>4.349529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.770678</td>\n",
       "      <td>1.856464</td>\n",
       "      <td>1.917959</td>\n",
       "      <td>1.966986</td>\n",
       "      <td>2.008974</td>\n",
       "      <td>2.045620</td>\n",
       "      <td>2.078148</td>\n",
       "      <td>2.107347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.276937</td>\n",
       "      <td>1.346896</td>\n",
       "      <td>1.403343</td>\n",
       "      <td>1.450797</td>\n",
       "      <td>1.497786</td>\n",
       "      <td>1.548286</td>\n",
       "      <td>1.603709</td>\n",
       "      <td>1.663314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27917</th>\n",
       "      <td>1.194264</td>\n",
       "      <td>1.263497</td>\n",
       "      <td>1.319135</td>\n",
       "      <td>1.367578</td>\n",
       "      <td>1.416099</td>\n",
       "      <td>1.467100</td>\n",
       "      <td>1.523348</td>\n",
       "      <td>1.583263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27918</th>\n",
       "      <td>1.221878</td>\n",
       "      <td>1.283498</td>\n",
       "      <td>1.334304</td>\n",
       "      <td>1.380934</td>\n",
       "      <td>1.428878</td>\n",
       "      <td>1.480126</td>\n",
       "      <td>1.534703</td>\n",
       "      <td>1.590261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27919</th>\n",
       "      <td>1.269643</td>\n",
       "      <td>1.331808</td>\n",
       "      <td>1.384484</td>\n",
       "      <td>1.434266</td>\n",
       "      <td>1.486253</td>\n",
       "      <td>1.541367</td>\n",
       "      <td>1.598302</td>\n",
       "      <td>1.655143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27920</th>\n",
       "      <td>1.318292</td>\n",
       "      <td>1.381839</td>\n",
       "      <td>1.436346</td>\n",
       "      <td>1.488346</td>\n",
       "      <td>1.542643</td>\n",
       "      <td>1.599944</td>\n",
       "      <td>1.658792</td>\n",
       "      <td>1.716357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27921</th>\n",
       "      <td>1.905698</td>\n",
       "      <td>1.953051</td>\n",
       "      <td>1.994792</td>\n",
       "      <td>2.033995</td>\n",
       "      <td>2.070551</td>\n",
       "      <td>2.104146</td>\n",
       "      <td>2.134877</td>\n",
       "      <td>2.162919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27922 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      1.991668  2.081356  2.142166  2.189419  2.229165  2.264290  2.295785   \n",
       "1      1.374382  1.440966  1.498263  1.552595  1.610255  1.673098  1.740388   \n",
       "2      4.574277  4.571805  4.544686  4.507704  4.467286  4.426587  4.387007   \n",
       "3      1.770678  1.856464  1.917959  1.966986  2.008974  2.045620  2.078148   \n",
       "4      1.276937  1.346896  1.403343  1.450797  1.497786  1.548286  1.603709   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "27917  1.194264  1.263497  1.319135  1.367578  1.416099  1.467100  1.523348   \n",
       "27918  1.221878  1.283498  1.334304  1.380934  1.428878  1.480126  1.534703   \n",
       "27919  1.269643  1.331808  1.384484  1.434266  1.486253  1.541367  1.598302   \n",
       "27920  1.318292  1.381839  1.436346  1.488346  1.542643  1.599944  1.658792   \n",
       "27921  1.905698  1.953051  1.994792  2.033995  2.070551  2.104146  2.134877   \n",
       "\n",
       "              7  \n",
       "0      2.324450  \n",
       "1      1.809329  \n",
       "2      4.349529  \n",
       "3      2.107347  \n",
       "4      1.663314  \n",
       "...         ...  \n",
       "27917  1.583263  \n",
       "27918  1.590261  \n",
       "27919  1.655143  \n",
       "27920  1.716357  \n",
       "27921  2.162919  \n",
       "\n",
       "[27922 rows x 8 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4594cd16",
   "metadata": {
    "gradient": {
     "id": "b2372070",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.145923, 1.1579393)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 1\n",
    "ga[idx].max(),ga[idx].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "41902cde",
   "metadata": {
    "gradient": {
     "id": "7aafdcaa",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_submission_sample['date_block_num'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b0c9bd8f",
   "metadata": {
    "gradient": {
     "id": "c7ba2537",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions['date_block_num'] = sorted(df_submission_sample['date_block_num'].unique())\n",
    "predictions = pd.melt(predictions, id_vars=['date_block_num'])\n",
    "predictions = predictions.sort_values(['date_block_num', 'variable']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "43bb3b69",
   "metadata": {
    "gradient": {
     "id": "24c90d4a",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_test = df_submission_sample.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "71ab332f",
   "metadata": {
    "gradient": {
     "id": "3a9b6c09",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_test[['date_block_num', 'S100', 'item_id']].sort_values(['date_block_num', 'S100', 'item_id']).reset_index(drop=True)\n",
    "df_test = df_test.join(predictions['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d6558542",
   "metadata": {
    "gradient": {
     "id": "b0dd08bd",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>QTT</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>S100</th>\n",
       "      <th>item_id</th>\n",
       "      <th>S101</th>\n",
       "      <th>S102</th>\n",
       "      <th>S103</th>\n",
       "      <th>I100</th>\n",
       "      <th>I101</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>317_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.991668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>319_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.374382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>321_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.574277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>324_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.770678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>-1</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>335_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.276937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69116</th>\n",
       "      <td>2021-10-24</td>\n",
       "      <td>-1</td>\n",
       "      <td>94</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>297</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.762314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69117</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>248_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.412992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69118</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.696996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69119</th>\n",
       "      <td>2021-10-17</td>\n",
       "      <td>-1</td>\n",
       "      <td>93</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>62_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>12_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.767642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69120</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>-1</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>62_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>12_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.882660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69121 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE  QTT  date_block_num     S100      item_id    S101     S102  \\\n",
       "0     2021-10-03   -1              91   0_S100  317_item_id  1_S101  17_S102   \n",
       "1     2021-10-03   -1              91   0_S100  319_item_id  1_S101  17_S102   \n",
       "2     2021-10-03   -1              91   0_S100  321_item_id  1_S101  17_S102   \n",
       "3     2021-10-03   -1              91   0_S100  324_item_id  1_S101  17_S102   \n",
       "4     2021-10-03   -1              91   0_S100  335_item_id  1_S101  17_S102   \n",
       "...          ...  ...             ...      ...          ...     ...      ...   \n",
       "69116 2021-10-24   -1              94  22_S100  251_item_id  0_S101   0_S102   \n",
       "69117 2021-11-07   -1              96  22_S100  248_item_id  0_S101   0_S102   \n",
       "69118 2021-11-07   -1              96  22_S100  251_item_id  0_S101   0_S102   \n",
       "69119 2021-10-17   -1              93  22_S100   62_item_id  0_S101   0_S102   \n",
       "69120 2021-11-07   -1              96  22_S100   62_item_id  0_S101   0_S102   \n",
       "\n",
       "          S103     I100    I101  ... day_of_week day is_month_end day_of_year  \\\n",
       "0      10_S103   1_I100  2_I101  ...           6   3        False         276   \n",
       "1      10_S103   1_I100  2_I101  ...           6   3        False         276   \n",
       "2      10_S103   1_I100  2_I101  ...           6   3        False         276   \n",
       "3      10_S103   1_I100  2_I101  ...           6   3        False         276   \n",
       "4      10_S103   1_I100  2_I101  ...           6   3        False         276   \n",
       "...        ...      ...     ...  ...         ...  ..          ...         ...   \n",
       "69116  10_S103  18_I100  2_I101  ...           6  24        False         297   \n",
       "69117  10_S103  18_I100  2_I101  ...           6   7        False         311   \n",
       "69118  10_S103  18_I100  2_I101  ...           6   7        False         311   \n",
       "69119  10_S103  12_I100  2_I101  ...           6  17        False         290   \n",
       "69120  10_S103  12_I100  2_I101  ...           6   7        False         311   \n",
       "\n",
       "       is_quarter_start  year  month  is_year_start  is_month_start     value  \n",
       "0                 False  2021     10          False           False  1.991668  \n",
       "1                 False  2021     10          False           False  1.374382  \n",
       "2                 False  2021     10          False           False  4.574277  \n",
       "3                 False  2021     10          False           False  1.770678  \n",
       "4                 False  2021     10          False           False  1.276937  \n",
       "...                 ...   ...    ...            ...             ...       ...  \n",
       "69116             False  2021     10          False           False  1.762314  \n",
       "69117             False  2021     11          False           False  1.412992  \n",
       "69118             False  2021     11          False           False  1.696996  \n",
       "69119             False  2021     10          False           False  2.767642  \n",
       "69120             False  2021     11          False           False  1.882660  \n",
       "\n",
       "[69121 rows x 24 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d3df19c7",
   "metadata": {
    "gradient": {
     "id": "58e344b8",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "df_test.drop(columns=['QTT'],inplace=True)\n",
    "df_test = df_test.rename(columns={\"value\": \"QTT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0bf5b96d",
   "metadata": {
    "gradient": {
     "id": "1e4428c8",
     "kernelId": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>S100</th>\n",
       "      <th>item_id</th>\n",
       "      <th>S101</th>\n",
       "      <th>S102</th>\n",
       "      <th>S103</th>\n",
       "      <th>I100</th>\n",
       "      <th>I101</th>\n",
       "      <th>I102</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>QTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>317_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.991668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>319_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.374382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>321_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.574277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>324_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.770678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>91</td>\n",
       "      <td>0_S100</td>\n",
       "      <td>335_item_id</td>\n",
       "      <td>1_S101</td>\n",
       "      <td>17_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>1_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>276</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.276937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69116</th>\n",
       "      <td>2021-10-24</td>\n",
       "      <td>94</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "      <td>297</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.762314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69117</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>248_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.412992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69118</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>251_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>18_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.696996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69119</th>\n",
       "      <td>2021-10-17</td>\n",
       "      <td>93</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>62_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>12_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>290</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.767642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69120</th>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>96</td>\n",
       "      <td>22_S100</td>\n",
       "      <td>62_item_id</td>\n",
       "      <td>0_S101</td>\n",
       "      <td>0_S102</td>\n",
       "      <td>10_S103</td>\n",
       "      <td>12_I100</td>\n",
       "      <td>2_I101</td>\n",
       "      <td>1_I102</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>311</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.882660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69121 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATE  date_block_num     S100      item_id    S101     S102  \\\n",
       "0     2021-10-03              91   0_S100  317_item_id  1_S101  17_S102   \n",
       "1     2021-10-03              91   0_S100  319_item_id  1_S101  17_S102   \n",
       "2     2021-10-03              91   0_S100  321_item_id  1_S101  17_S102   \n",
       "3     2021-10-03              91   0_S100  324_item_id  1_S101  17_S102   \n",
       "4     2021-10-03              91   0_S100  335_item_id  1_S101  17_S102   \n",
       "...          ...             ...      ...          ...     ...      ...   \n",
       "69116 2021-10-24              94  22_S100  251_item_id  0_S101   0_S102   \n",
       "69117 2021-11-07              96  22_S100  248_item_id  0_S101   0_S102   \n",
       "69118 2021-11-07              96  22_S100  251_item_id  0_S101   0_S102   \n",
       "69119 2021-10-17              93  22_S100   62_item_id  0_S101   0_S102   \n",
       "69120 2021-11-07              96  22_S100   62_item_id  0_S101   0_S102   \n",
       "\n",
       "          S103     I100    I101    I102  ... day_of_week day is_month_end  \\\n",
       "0      10_S103   1_I100  2_I101  1_I102  ...           6   3        False   \n",
       "1      10_S103   1_I100  2_I101  1_I102  ...           6   3        False   \n",
       "2      10_S103   1_I100  2_I101  1_I102  ...           6   3        False   \n",
       "3      10_S103   1_I100  2_I101  1_I102  ...           6   3        False   \n",
       "4      10_S103   1_I100  2_I101  1_I102  ...           6   3        False   \n",
       "...        ...      ...     ...     ...  ...         ...  ..          ...   \n",
       "69116  10_S103  18_I100  2_I101  1_I102  ...           6  24        False   \n",
       "69117  10_S103  18_I100  2_I101  1_I102  ...           6   7        False   \n",
       "69118  10_S103  18_I100  2_I101  1_I102  ...           6   7        False   \n",
       "69119  10_S103  12_I100  2_I101  1_I102  ...           6  17        False   \n",
       "69120  10_S103  12_I100  2_I101  1_I102  ...           6   7        False   \n",
       "\n",
       "       day_of_year  is_quarter_start  year  month  is_year_start  \\\n",
       "0              276             False  2021     10          False   \n",
       "1              276             False  2021     10          False   \n",
       "2              276             False  2021     10          False   \n",
       "3              276             False  2021     10          False   \n",
       "4              276             False  2021     10          False   \n",
       "...            ...               ...   ...    ...            ...   \n",
       "69116          297             False  2021     10          False   \n",
       "69117          311             False  2021     11          False   \n",
       "69118          311             False  2021     11          False   \n",
       "69119          290             False  2021     10          False   \n",
       "69120          311             False  2021     11          False   \n",
       "\n",
       "       is_month_start       QTT  \n",
       "0               False  1.991668  \n",
       "1               False  1.374382  \n",
       "2               False  4.574277  \n",
       "3               False  1.770678  \n",
       "4               False  1.276937  \n",
       "...               ...       ...  \n",
       "69116           False  1.762314  \n",
       "69117           False  1.412992  \n",
       "69118           False  1.696996  \n",
       "69119           False  2.767642  \n",
       "69120           False  1.882660  \n",
       "\n",
       "[69121 rows x 23 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdd43a",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6461e81e",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c5062",
   "metadata": {
    "gradient": {
     "id": "4a9307f1",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782a697c",
   "metadata": {
    "gradient": {
     "id": "be011eb4",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b2940",
   "metadata": {
    "gradient": {
     "id": "9c921cb4",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119229d",
   "metadata": {
    "gradient": {
     "id": "857b612c",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bf5b9df6",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "944665e0",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5072/1534675773.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_pred\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_validation_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_test_pred\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_submission_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_submission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gbm' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_pred      = gbm.predict(X_train, num_iteration=gbm.best_iteration_)\n",
    "X_validation_pred = gbm.predict(X_validation, num_iteration=gbm.best_iteration_)\n",
    "X_test_pred       = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "\n",
    "X_submission_pred = gbm.predict(X_submission, num_iteration=gbm.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044efa92",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "f6eb194a",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train_pred = np.maximum(X_train_pred, 0)\n",
    "X_validation_pred = np.maximum(X_validation_pred, 0)\n",
    "X_test_pred = np.maximum(X_test_pred, 0)\n",
    "X_submission_pred = np.maximum(X_submission_pred, 0)\n",
    "\n",
    "df_train_rmse = mean_squared_error(y_train,X_train_pred, squared=False)\n",
    "df_val_rmse   = mean_squared_error(y_validation,X_validation_pred, squared=False)\n",
    "df_test_rmse  = mean_squared_error(y_test,X_test_pred, squared=False)\n",
    "\n",
    "print('Final score mean_squared_error')\n",
    "print('Score train:',df_train_rmse)\n",
    "print('Score val  :',df_val_rmse)\n",
    "print('Score test :',df_test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e8957",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "64177d90",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#X_test_pred[0] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56096883",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "1e18dff9",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "plt.plot(X_test_pred,'b', alpha=0.7)\n",
    "plt.plot(y_test.values,'r', alpha=0.4)\n",
    "plt.legend([\"prediction\", \"real\"], loc =\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6f7c1",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "51c7fa0c",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_submission_sample.reset_index(drop=True,inplace=True)\n",
    "df_submission_sample['QTT'] = X_submission_pred\n",
    "df_submission_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf536d",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "b776c32f",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "filename_submission= 'submission_NOFILL_good_'+str(np.round(df_test_rmse,4))+'_local.csv'\n",
    "save = False\n",
    "if save:\n",
    "    print('saving..')\n",
    "    print(filename_submission)\n",
    "    df_submission_sample[['ID','QTT']].to_csv(os.path.join(PATH_RESULTS,'submissions','no_fill',filename_submission),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef5b09",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "8869587a",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "result = pd.read_csv(os.path.join(PATH_RESULTS,'submissions','submission_2.1046_local.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11277f0",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "c181b7a3",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_test['QTT_reference']= result['QTT'].copy()\n",
    "df_test[['QTT_reference','QTT']][-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269f6ef",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "143b8ba9",
     "kernelId": "",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,8))\n",
    "plt.plot(df_submission_sample['QTT'],'b', alpha=0.7)\n",
    "plt.plot(result['QTT'],'r', alpha=0.4)\n",
    "plt.legend([\"prediction\", \"real\"], loc =\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a98cd",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "06aeb3b3",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "difference = mean_squared_error(df_test['QTT'],result['QTT'], squared=False)\n",
    "\n",
    "print('Final score mean_squared_error')\n",
    "print('Score train:',difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee47065",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "baceff98",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f14468",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "822f2f95",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98669de",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6de6391a",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa65adc",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2d65bdaf",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f584a2",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "48d175fe",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c4e66",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2ad706b5",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ea05b",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4bc60043",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
